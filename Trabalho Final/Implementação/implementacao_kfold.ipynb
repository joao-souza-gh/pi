{
 "cells": [
  {
   "metadata": {},
   "cell_type": "raw",
   "outputs": [],
   "execution_count": null,
   "source": [
    "{\n",
    " \"cells\": [\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"id\": \"34db769b46dc074b\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"Autores: Alexandre Liermann, Gustavo Guerreiro e João Martinho.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"id\": \"be2e6c6ff29c0f12\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# Implementação de Classificação de Imagens de Ressonância Magnética para Diagnóstico de Alzheimer Usando CNN em TensorFlow\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"id\": \"aac8cbbfcc8dab30\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"Importações das bibliotecas necessárias\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"id\": \"initial_id\",\n",
    "   \"metadata\": {\n",
    "    \"collapsed\": true,\n",
    "    \"ExecuteTime\": {\n",
    "     \"end_time\": \"2025-11-21T01:30:40.347206Z\",\n",
    "     \"start_time\": \"2025-11-21T01:30:36.355237Z\"\n",
    "    }\n",
    "   },\n",
    "   \"source\": [\n",
    "    \"import os\\n\",\n",
    "    \"os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\\n\",\n",
    "    \"os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'\\n\",\n",
    "    \"os.environ['TF_DETERMINISTIC_OPS'] = '1'\\n\",\n",
    "    \"os.environ['TF_CUDNN_DETERMINISTIC'] = '1'\\n\",\n",
    "    \"os.environ['TF_CUDNN_BENCHMARK'] = 'false'\\n\",\n",
    "    \"\\n\",\n",
    "    \"import gc\\n\",\n",
    "    \"import glob\\n\",\n",
    "    \"import pathlib\\n\",\n",
    "    \"import numpy as np\\n\",\n",
    "    \"import tensorflow as tf\\n\",\n",
    "    \"\\n\",\n",
    "    \"from keras import regularizers\\n\",\n",
    "    \"from matplotlib import pyplot as plt\\n\",\n",
    "    \"from tensorflow.data import AUTOTUNE\\n\",\n",
    "    \"from sklearn.utils import class_weight\\n\",\n",
    "    \"from tensorflow.keras.models import load_model\\n\",\n",
    "    \"from sklearn.model_selection import train_test_split, StratifiedKFold\\n\",\n",
    "    \"from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\\n\",\n",
    "    \"from tensorflow.keras import models, layers, mixed_precision, optimizers\\n\",\n",
    "    \"from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report\\n\"\n",
    "   ],\n",
    "   \"outputs\": [],\n",
    "   \"execution_count\": 1\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": \"Definindo constantes a serem usadas\",\n",
    "   \"id\": \"386f7e8f62842b3d\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {\n",
    "    \"ExecuteTime\": {\n",
    "     \"end_time\": \"2025-11-21T01:30:40.355079Z\",\n",
    "     \"start_time\": \"2025-11-21T01:30:40.352451Z\"\n",
    "    }\n",
    "   },\n",
    "   \"cell_type\": \"code\",\n",
    "   \"source\": [\n",
    "    \"IMG_ALTURA    = 176\\n\",\n",
    "    \"IMG_LARGURA   = 208\\n\",\n",
    "    \"TAMANHO_BATCH = 128\\n\",\n",
    "    \"\\n\",\n",
    "    \"SEED = 2025\"\n",
    "   ],\n",
    "   \"id\": \"518d9f32ec72f2d9\",\n",
    "   \"outputs\": [],\n",
    "   \"execution_count\": 2\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {\n",
    "    \"ExecuteTime\": {\n",
    "     \"end_time\": \"2025-11-21T01:30:40.424767Z\",\n",
    "     \"start_time\": \"2025-11-21T01:30:40.421562Z\"\n",
    "    }\n",
    "   },\n",
    "   \"cell_type\": \"code\",\n",
    "   \"source\": [\n",
    "    \"os.environ['PYTHONHASHSEED'] = str(SEED)\\n\",\n",
    "    \"np.random.seed(SEED)\\n\",\n",
    "    \"tf.random.set_seed(SEED)\\n\",\n",
    "    \"tf.config.experimental.enable_op_determinism()\\n\",\n",
    "    \"\\n\",\n",
    "    \"print('Seed global definida:', SEED)\"\n",
    "   ],\n",
    "   \"id\": \"85df67e52d94296e\",\n",
    "   \"outputs\": [\n",
    "    {\n",
    "     \"name\": \"stdout\",\n",
    "     \"output_type\": \"stream\",\n",
    "     \"text\": [\n",
    "      \"Seed global definida: 2025\\n\"\n",
    "     ]\n",
    "    }\n",
    "   ],\n",
    "   \"execution_count\": 3\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {\n",
    "    \"ExecuteTime\": {\n",
    "     \"end_time\": \"2025-11-21T01:30:41.749513Z\",\n",
    "     \"start_time\": \"2025-11-21T01:30:40.474446Z\"\n",
    "    }\n",
    "   },\n",
    "   \"cell_type\": \"code\",\n",
    "   \"source\": [\n",
    "    \"def configurar_gpu():\\n\",\n",
    "    \"    try:\\n\",\n",
    "    \"        gpus = tf.config.list_physical_devices('GPU')\\n\",\n",
    "    \"        if gpus:\\n\",\n",
    "    \"            for gpu in gpus:\\n\",\n",
    "    \"                tf.config.experimental.set_memory_growth(gpu, True)\\n\",\n",
    "    \"    except RuntimeError as e:\\n\",\n",
    "    \"        print(f\\\"Erro ao configurar GPU: {e}\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"mixed_precision.set_global_policy('mixed_float16')\\n\",\n",
    "    \"configurar_gpu()\"\n",
    "   ],\n",
    "   \"id\": \"66a81025563811c4\",\n",
    "   \"outputs\": [],\n",
    "   \"execution_count\": 4\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"id\": \"600a10a0d0a5d882\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"Definindo os diretórios do dataset\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"id\": \"574b5f8cb5bbebda\",\n",
    "   \"metadata\": {\n",
    "    \"ExecuteTime\": {\n",
    "     \"end_time\": \"2025-11-21T01:30:41.870624Z\",\n",
    "     \"start_time\": \"2025-11-21T01:30:41.846772Z\"\n",
    "    }\n",
    "   },\n",
    "   \"source\": [\n",
    "    \"dir_dados = pathlib.Path('dataset')\\n\",\n",
    "    \"\\n\",\n",
    "    \"caminhos_arquivos = []\\n\",\n",
    "    \"rotulos = []\\n\",\n",
    "    \"nomes_classes = sorted([item.name for item in dir_dados.glob('*') if item.is_dir()])\\n\",\n",
    "    \"dict_classes = {nome: i for i, nome in enumerate(nomes_classes)}\\n\",\n",
    "    \"\\n\",\n",
    "    \"for nome_classe in nomes_classes:\\n\",\n",
    "    \"    padrao = str(dir_dados / nome_classe / '*')\\n\",\n",
    "    \"    arquivos = glob.glob(padrao)\\n\",\n",
    "    \"    caminhos_arquivos.extend(arquivos)\\n\",\n",
    "    \"    rotulos.extend([dict_classes[nome_classe]] * len(arquivos))\\n\",\n",
    "    \"\\n\",\n",
    "    \"caminhos_arquivos = np.array(caminhos_arquivos)\\n\",\n",
    "    \"rotulos = np.array(rotulos)\\n\",\n",
    "    \"\\n\",\n",
    "    \"X_restante, X_teste, y_restante, y_teste = train_test_split(\\n\",\n",
    "    \"    caminhos_arquivos, rotulos, test_size=0.15, stratify=rotulos, random_state=SEED\\n\",\n",
    "    \")\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"Total para K-Fold (Treino+Val): {len(X_restante)}\\\")\\n\",\n",
    "    \"print(f\\\"Reservado para Teste Final: {len(X_teste)}\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"def processar_arquivo(caminho, rotulo):\\n\",\n",
    "    \"    arquivo = tf.io.read_file(caminho)\\n\",\n",
    "    \"    img = tf.io.decode_image(arquivo, channels=3, expand_animations=False)\\n\",\n",
    "    \"    img = tf.image.resize(img, [IMG_ALTURA, IMG_LARGURA])\\n\",\n",
    "    \"    img = tf.cast(img, tf.float32)\\n\",\n",
    "    \"    return img, rotulo\\n\",\n",
    "    \"\\n\",\n",
    "    \"def criar_dataset_fold(caminhos, labels_fold, training=True):\\n\",\n",
    "    \"    ds = tf.data.Dataset.from_tensor_slices((caminhos, labels_fold))\\n\",\n",
    "    \"    ds = ds.map(processar_arquivo, num_parallel_calls=AUTOTUNE)\\n\",\n",
    "    \"    if training:\\n\",\n",
    "    \"        ds = ds.shuffle(len(caminhos), seed=SEED)\\n\",\n",
    "    \"    ds = ds.batch(TAMANHO_BATCH)\\n\",\n",
    "    \"    ds = ds.prefetch(AUTOTUNE)\\n\",\n",
    "    \"    return ds\"\n",
    "   ],\n",
    "   \"outputs\": [\n",
    "    {\n",
    "     \"name\": \"stdout\",\n",
    "     \"output_type\": \"stream\",\n",
    "     \"text\": [\n",
    "      \"Total para K-Fold (Treino+Val): 5440\\n\",\n",
    "      \"Reservado para Teste Final: 960\\n\"\n",
    "     ]\n",
    "    }\n",
    "   ],\n",
    "   \"execution_count\": 5\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"id\": \"c10f856f8906ca88\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"Iniciando a configuração do modelo.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"id\": \"f5ccf6c7ee895123\",\n",
    "   \"metadata\": {\n",
    "    \"ExecuteTime\": {\n",
    "     \"end_time\": \"2025-11-21T01:30:41.907188Z\",\n",
    "     \"start_time\": \"2025-11-21T01:30:41.903748Z\"\n",
    "    }\n",
    "   },\n",
    "   \"source\": [\n",
    "    \"@tf.keras.utils.register_keras_serializable()\\n\",\n",
    "    \"def converter_para_cinza_gpu(x):\\n\",\n",
    "    \"    return tf.image.rgb_to_grayscale(x)\\n\",\n",
    "    \"\\n\",\n",
    "    \"def construir_modelo():\\n\",\n",
    "    \"    tf.keras.backend.clear_session()\\n\",\n",
    "    \"    gc.collect()\\n\",\n",
    "    \"\\n\",\n",
    "    \"    modelo = models.Sequential([\\n\",\n",
    "    \"        layers.Input(shape=(IMG_ALTURA, IMG_LARGURA, 3)),\\n\",\n",
    "    \"        layers.Lambda(converter_para_cinza_gpu),\\n\",\n",
    "    \"        layers.Rescaling(1./255),\\n\",\n",
    "    \"\\n\",\n",
    "    \"        layers.Conv2D(32, (3, 3), activation='relu', padding='same'),\\n\",\n",
    "    \"        layers.MaxPooling2D(pool_size=(2, 2)),\\n\",\n",
    "    \"\\n\",\n",
    "    \"        layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\\n\",\n",
    "    \"        layers.MaxPooling2D(pool_size=(2, 2)),\\n\",\n",
    "    \"\\n\",\n",
    "    \"        layers.Conv2D(128, (3, 3), activation='relu', padding='same'),\\n\",\n",
    "    \"        layers.MaxPooling2D(pool_size=(2, 2)),\\n\",\n",
    "    \"\\n\",\n",
    "    \"        layers.Conv2D(256, (3, 3), activation='relu', padding='same'),\\n\",\n",
    "    \"        layers.MaxPooling2D(pool_size=(2, 2)),\\n\",\n",
    "    \"\\n\",\n",
    "    \"        layers.Flatten(),\\n\",\n",
    "    \"        layers.Dense(512, activation='relu'),\\n\",\n",
    "    \"        layers.Dropout(0.5),\\n\",\n",
    "    \"        layers.Dense(4, activation='softmax')\\n\",\n",
    "    \"    ])\\n\",\n",
    "    \"\\n\",\n",
    "    \"    opt = optimizers.Adam(learning_rate=1e-4, clipnorm=1.0)\\n\",\n",
    "    \"    modelo.compile(\\n\",\n",
    "    \"        optimizer=opt,\\n\",\n",
    "    \"        loss='sparse_categorical_crossentropy',\\n\",\n",
    "    \"        metrics=['accuracy']\\n\",\n",
    "    \"    )\\n\",\n",
    "    \"    return modelo\"\n",
    "   ],\n",
    "   \"outputs\": [],\n",
    "   \"execution_count\": 6\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"id\": \"65c22eef320f53\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"Definindo callback de EarlyStopping.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"id\": \"a3c2dcaa662703db\",\n",
    "   \"metadata\": {\n",
    "    \"ExecuteTime\": {\n",
    "     \"end_time\": \"2025-11-21T01:30:41.954644Z\",\n",
    "     \"start_time\": \"2025-11-21T01:30:41.952278Z\"\n",
    "    }\n",
    "   },\n",
    "   \"source\": [\n",
    "    \"def obter_callbacks():\\n\",\n",
    "    \"    early_stop = EarlyStopping(\\n\",\n",
    "    \"        monitor='val_loss',\\n\",\n",
    "    \"        patience=15,\\n\",\n",
    "    \"        restore_best_weights=True,\\n\",\n",
    "    \"        verbose=1\\n\",\n",
    "    \"    )\\n\",\n",
    "    \"\\n\",\n",
    "    \"    reduce_le = ReduceLROnPlateau(\\n\",\n",
    "    \"        monitor='val_loss',\\n\",\n",
    "    \"        factor=0.5,\\n\",\n",
    "    \"        patience=5,\\n\",\n",
    "    \"        min_lr=1e-7,\\n\",\n",
    "    \"        verbose=1\\n\",\n",
    "    \"    )\\n\",\n",
    "    \"\\n\",\n",
    "    \"    return [early_stop, reduce_le]\"\n",
    "   ],\n",
    "   \"outputs\": [],\n",
    "   \"execution_count\": 7\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": \"Colocando pesos nas classes a fim de diminuir falsos negativos (melhorar Recall).\",\n",
    "   \"id\": \"4eb1c1381c6dfde5\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {\n",
    "    \"ExecuteTime\": {\n",
    "     \"end_time\": \"2025-11-21T01:30:42.005143Z\",\n",
    "     \"start_time\": \"2025-11-21T01:30:42.002601Z\"\n",
    "    }\n",
    "   },\n",
    "   \"cell_type\": \"code\",\n",
    "   \"source\": [\n",
    "    \"def ajustar_pesos(rotulos_treino):\\n\",\n",
    "    \"    pesos_base = class_weight.compute_class_weight(\\n\",\n",
    "    \"        class_weight='balanced',\\n\",\n",
    "    \"        classes=np.unique(rotulos_treino),\\n\",\n",
    "    \"        y=rotulos_treino\\n\",\n",
    "    \"    )\\n\",\n",
    "    \"\\n\",\n",
    "    \"    pesos_dict = dict(enumerate(pesos_base))\\n\",\n",
    "    \"    fator_rigor = 2.5\\n\",\n",
    "    \"    pesos_dict[0] *= fator_rigor\\n\",\n",
    "    \"    pesos_dict[1] *= fator_rigor\\n\",\n",
    "    \"    pesos_dict[3] *= fator_rigor\\n\",\n",
    "    \"\\n\",\n",
    "    \"    print(\\\"Pesos das classes:\\\", pesos_dict)\\n\",\n",
    "    \"    return pesos_dict\"\n",
    "   ],\n",
    "   \"id\": \"93a46dcba63ffb05\",\n",
    "   \"outputs\": [],\n",
    "   \"execution_count\": 8\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {\n",
    "    \"ExecuteTime\": {\n",
    "     \"end_time\": \"2025-11-21T01:30:42.056341Z\",\n",
    "     \"start_time\": \"2025-11-21T01:30:42.053555Z\"\n",
    "    }\n",
    "   },\n",
    "   \"cell_type\": \"code\",\n",
    "   \"source\": [\n",
    "    \"def avaliar_fold(modelo, ds_val, melhor_acc_atual):\\n\",\n",
    "    \"    scores = modelo.evaluate(ds_val, verbose=0)\\n\",\n",
    "    \"    acuracia_fold = scores[1]\\n\",\n",
    "    \"    loss_fold = scores[0]\\n\",\n",
    "    \"    print(f\\\"   > Acurácia Validação: {acuracia_fold*100:.2f}% (Loss: {loss_fold:.4f})\\\")\\n\",\n",
    "    \"    nova_melhor_acc = melhor_acc_atual\\n\",\n",
    "    \"\\n\",\n",
    "    \"    if acuracia_fold > melhor_acc_atual:\\n\",\n",
    "    \"        nova_melhor_acc = acuracia_fold\\n\",\n",
    "    \"        print(f\\\"   > Novo recorde! (Anterior: {melhor_acc_atual*100:.2f}%) -> Salvando modelo...\\\")\\n\",\n",
    "    \"        modelo.save('melhor_modelo_kfold.keras')\\n\",\n",
    "    \"\\n\",\n",
    "    \"    return acuracia_fold, nova_melhor_acc\"\n",
    "   ],\n",
    "   \"id\": \"ac909483fa01608c\",\n",
    "   \"outputs\": [],\n",
    "   \"execution_count\": 9\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"id\": \"b33d08c37fe1c743\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"Treinando o modelo\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"id\": \"fc08b5bfb9113d51\",\n",
    "   \"metadata\": {\n",
    "    \"ExecuteTime\": {\n",
    "     \"end_time\": \"2025-11-21T02:23:32.575648Z\",\n",
    "     \"start_time\": \"2025-11-21T01:30:42.104418Z\"\n",
    "    }\n",
    "   },\n",
    "   \"source\": [\n",
    "    \"NUM_FOLDS = 6\\n\",\n",
    "    \"skf = StratifiedKFold(n_splits=NUM_FOLDS, shuffle=True, random_state=SEED)\\n\",\n",
    "    \"resultados_acuracia = []\\n\",\n",
    "    \"melhor_modelo = None\\n\",\n",
    "    \"melhor_acuracia = 0.0\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"Iniciando Treinamento com {NUM_FOLDS} Folds...\\\\n\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"\\n\",\n",
    "    \"fold_atual = 1\\n\",\n",
    "    \"for idx_treino, idx_val in skf.split(X_restante, y_restante):\\n\",\n",
    "    \"    print(f\\\"--- Rodando Fold {fold_atual}/{NUM_FOLDS} ---\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"    X_treino_f, X_val_f = X_restante[idx_treino], X_restante[idx_val]\\n\",\n",
    "    \"    y_treino_f, y_val_f = y_restante[idx_treino], y_restante[idx_val]\\n\",\n",
    "    \"\\n\",\n",
    "    \"    ds_treino = criar_dataset_fold(X_treino_f, y_treino_f, training=True)\\n\",\n",
    "    \"    ds_val = criar_dataset_fold(X_val_f, y_val_f, training=False)\\n\",\n",
    "    \"\\n\",\n",
    "    \"    pesos = ajustar_pesos(y_treino_f)\\n\",\n",
    "    \"\\n\",\n",
    "    \"    modelo_fold = construir_modelo()\\n\",\n",
    "    \"\\n\",\n",
    "    \"    history = modelo_fold.fit(\\n\",\n",
    "    \"        ds_treino,\\n\",\n",
    "    \"        validation_data=ds_val,\\n\",\n",
    "    \"        epochs=150,\\n\",\n",
    "    \"        callbacks=obter_callbacks(),\\n\",\n",
    "    \"        class_weight=pesos\\n\",\n",
    "    \"    )\\n\",\n",
    "    \"\\n\",\n",
    "    \"    acuracia_fold, melhor_acuracia = avaliar_fold(\\n\",\n",
    "    \"        modelo_fold,\\n\",\n",
    "    \"        ds_val,\\n\",\n",
    "    \"        melhor_acuracia\\n\",\n",
    "    \"    )\\n\",\n",
    "    \"\\n\",\n",
    "    \"    resultados_acuracia.append(acuracia_fold)\\n\",\n",
    "    \"\\n\",\n",
    "    \"    del ds_treino, ds_val, modelo_fold\\n\",\n",
    "    \"    tf.keras.backend.clear_session()\\n\",\n",
    "    \"    gc.collect()\\n\",\n",
    "    \"\\n\",\n",
    "    \"    fold_atual += 1\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"\\\\n\\\" + \\\"=\\\"*30)\\n\",\n",
    "    \"print(f\\\"Média Final de Acurácia: {np.mean(resultados_acuracia)*100:.2f}%\\\")\\n\",\n",
    "    \"print(\\\"O melhor modelo de todos os folds já está salvo como 'melhor_modelo_kfold.keras'\\\")\"\n",
    "   ],\n",
    "   \"outputs\": [\n",
    "    {\n",
    "     \"name\": \"stdout\",\n",
    "     \"output_type\": \"stream\",\n",
    "     \"text\": [\n",
    "      \"Iniciando Treinamento com 6 Folds...\\n\",\n",
    "      \"\\n\",\n",
    "      \"--- Rodando Fold 1/6 ---\\n\"\n",
    "     ]\n",
    "    },\n",
    "    {\n",
    "     \"name\": \"stderr\",\n",
    "     \"output_type\": \"stream\",\n",
    "     \"text\": [\n",
    "      \"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\\n\",\n",
    "      \"I0000 00:00:1763688642.472621  275822 gpu_device.cc:2020] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5563 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.9\\n\"\n",
    "     ]\n",
    "    },\n",
    "    {\n",
    "     \"name\": \"stdout\",\n",
    "     \"output_type\": \"stream\",\n",
    "     \"text\": [\n",
    "      \"Pesos das classes: {0: np.float64(4.461614173228346), 1: np.float64(62.958333333333336), 2: np.float64(0.5001103265666372), 3: np.float64(1.7852079395085065)}\\n\",\n",
    "      \"Epoch 1/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m18s\\u001B[0m 203ms/step - accuracy: 0.1540 - loss: 2.8767 - val_accuracy: 0.3495 - val_loss: 1.4575 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 2/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 143ms/step - accuracy: 0.2716 - loss: 2.8297 - val_accuracy: 0.1918 - val_loss: 1.6919 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 3/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 143ms/step - accuracy: 0.1604 - loss: 2.7939 - val_accuracy: 0.2646 - val_loss: 1.6277 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 4/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 144ms/step - accuracy: 0.2508 - loss: 2.7488 - val_accuracy: 0.1698 - val_loss: 1.6070 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 5/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 145ms/step - accuracy: 0.2585 - loss: 2.6332 - val_accuracy: 0.3484 - val_loss: 1.2860 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 6/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 144ms/step - accuracy: 0.2828 - loss: 2.6007 - val_accuracy: 0.3616 - val_loss: 1.2914 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 7/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 154ms/step - accuracy: 0.3148 - loss: 2.3409 - val_accuracy: 0.3385 - val_loss: 1.2731 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 8/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m10s\\u001B[0m 152ms/step - accuracy: 0.3836 - loss: 2.1672 - val_accuracy: 0.4234 - val_loss: 1.2282 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 9/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 145ms/step - accuracy: 0.4381 - loss: 1.9469 - val_accuracy: 0.3705 - val_loss: 1.5515 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 10/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 147ms/step - accuracy: 0.4522 - loss: 1.7545 - val_accuracy: 0.4818 - val_loss: 1.2878 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 11/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 146ms/step - accuracy: 0.5063 - loss: 1.6064 - val_accuracy: 0.5436 - val_loss: 1.1712 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 12/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 144ms/step - accuracy: 0.5330 - loss: 1.4514 - val_accuracy: 0.5391 - val_loss: 1.0482 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 13/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m5s\\u001B[0m 143ms/step - accuracy: 0.5429 - loss: 1.3386 - val_accuracy: 0.5006 - val_loss: 1.2722 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 14/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 166ms/step - accuracy: 0.5696 - loss: 1.2522 - val_accuracy: 0.5910 - val_loss: 0.9795 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 15/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 148ms/step - accuracy: 0.5872 - loss: 1.1514 - val_accuracy: 0.6251 - val_loss: 0.9583 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 16/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m5s\\u001B[0m 142ms/step - accuracy: 0.6113 - loss: 1.0662 - val_accuracy: 0.5777 - val_loss: 1.0299 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 17/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m5s\\u001B[0m 143ms/step - accuracy: 0.6283 - loss: 0.9651 - val_accuracy: 0.5645 - val_loss: 1.1037 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 18/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 146ms/step - accuracy: 0.6453 - loss: 0.8627 - val_accuracy: 0.7266 - val_loss: 0.7102 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 19/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m5s\\u001B[0m 143ms/step - accuracy: 0.6759 - loss: 0.8061 - val_accuracy: 0.7155 - val_loss: 0.7265 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 20/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m5s\\u001B[0m 142ms/step - accuracy: 0.6828 - loss: 0.7614 - val_accuracy: 0.5888 - val_loss: 0.9635 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 21/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 144ms/step - accuracy: 0.6951 - loss: 0.7287 - val_accuracy: 0.7078 - val_loss: 0.7409 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 22/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m5s\\u001B[0m 142ms/step - accuracy: 0.7192 - loss: 0.6386 - val_accuracy: 0.6384 - val_loss: 0.7878 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 23/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m0s\\u001B[0m 131ms/step - accuracy: 0.7223 - loss: 0.6296\\n\",\n",
    "      \"Epoch 23: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m5s\\u001B[0m 142ms/step - accuracy: 0.7351 - loss: 0.5989 - val_accuracy: 0.6626 - val_loss: 0.7664 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 24/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 145ms/step - accuracy: 0.7644 - loss: 0.5153 - val_accuracy: 0.7387 - val_loss: 0.6423 - learning_rate: 5.0000e-05\\n\",\n",
    "      \"Epoch 25/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 143ms/step - accuracy: 0.7803 - loss: 0.5032 - val_accuracy: 0.6681 - val_loss: 0.7909 - learning_rate: 5.0000e-05\\n\",\n",
    "      \"Epoch 26/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 146ms/step - accuracy: 0.7973 - loss: 0.4603 - val_accuracy: 0.7178 - val_loss: 0.6607 - learning_rate: 5.0000e-05\\n\",\n",
    "      \"Epoch 27/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 153ms/step - accuracy: 0.7955 - loss: 0.4306 - val_accuracy: 0.7938 - val_loss: 0.5072 - learning_rate: 5.0000e-05\\n\",\n",
    "      \"Epoch 28/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 147ms/step - accuracy: 0.8187 - loss: 0.4031 - val_accuracy: 0.7321 - val_loss: 0.5988 - learning_rate: 5.0000e-05\\n\",\n",
    "      \"Epoch 29/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 146ms/step - accuracy: 0.8229 - loss: 0.3822 - val_accuracy: 0.7938 - val_loss: 0.4736 - learning_rate: 5.0000e-05\\n\",\n",
    "      \"Epoch 30/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 145ms/step - accuracy: 0.8319 - loss: 0.3658 - val_accuracy: 0.8456 - val_loss: 0.4089 - learning_rate: 5.0000e-05\\n\",\n",
    "      \"Epoch 31/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m5s\\u001B[0m 143ms/step - accuracy: 0.8416 - loss: 0.3392 - val_accuracy: 0.7751 - val_loss: 0.5111 - learning_rate: 5.0000e-05\\n\",\n",
    "      \"Epoch 32/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 144ms/step - accuracy: 0.8597 - loss: 0.3173 - val_accuracy: 0.7806 - val_loss: 0.5191 - learning_rate: 5.0000e-05\\n\",\n",
    "      \"Epoch 33/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 149ms/step - accuracy: 0.8535 - loss: 0.3079 - val_accuracy: 0.8677 - val_loss: 0.3581 - learning_rate: 5.0000e-05\\n\",\n",
    "      \"Epoch 34/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 149ms/step - accuracy: 0.8727 - loss: 0.2878 - val_accuracy: 0.7905 - val_loss: 0.4789 - learning_rate: 5.0000e-05\\n\",\n",
    "      \"Epoch 35/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 151ms/step - accuracy: 0.8758 - loss: 0.2744 - val_accuracy: 0.8368 - val_loss: 0.3791 - learning_rate: 5.0000e-05\\n\",\n",
    "      \"Epoch 36/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 151ms/step - accuracy: 0.8820 - loss: 0.2618 - val_accuracy: 0.7993 - val_loss: 0.4928 - learning_rate: 5.0000e-05\\n\",\n",
    "      \"Epoch 37/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 149ms/step - accuracy: 0.8879 - loss: 0.2525 - val_accuracy: 0.8236 - val_loss: 0.4045 - learning_rate: 5.0000e-05\\n\",\n",
    "      \"Epoch 38/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 157ms/step - accuracy: 0.8965 - loss: 0.2348 - val_accuracy: 0.8699 - val_loss: 0.3290 - learning_rate: 5.0000e-05\\n\",\n",
    "      \"Epoch 39/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 149ms/step - accuracy: 0.9067 - loss: 0.2195 - val_accuracy: 0.8842 - val_loss: 0.2907 - learning_rate: 5.0000e-05\\n\",\n",
    "      \"Epoch 40/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 147ms/step - accuracy: 0.9073 - loss: 0.2056 - val_accuracy: 0.8831 - val_loss: 0.3258 - learning_rate: 5.0000e-05\\n\",\n",
    "      \"Epoch 41/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 154ms/step - accuracy: 0.9131 - loss: 0.2016 - val_accuracy: 0.8986 - val_loss: 0.2718 - learning_rate: 5.0000e-05\\n\",\n",
    "      \"Epoch 42/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 146ms/step - accuracy: 0.9226 - loss: 0.1873 - val_accuracy: 0.8853 - val_loss: 0.3084 - learning_rate: 5.0000e-05\\n\",\n",
    "      \"Epoch 43/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 147ms/step - accuracy: 0.9327 - loss: 0.1663 - val_accuracy: 0.8886 - val_loss: 0.2724 - learning_rate: 5.0000e-05\\n\",\n",
    "      \"Epoch 44/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 148ms/step - accuracy: 0.9254 - loss: 0.1714 - val_accuracy: 0.8986 - val_loss: 0.2658 - learning_rate: 5.0000e-05\\n\",\n",
    "      \"Epoch 45/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 147ms/step - accuracy: 0.9358 - loss: 0.1531 - val_accuracy: 0.8776 - val_loss: 0.3037 - learning_rate: 5.0000e-05\\n\",\n",
    "      \"Epoch 46/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 157ms/step - accuracy: 0.9429 - loss: 0.1415 - val_accuracy: 0.8997 - val_loss: 0.2534 - learning_rate: 5.0000e-05\\n\",\n",
    "      \"Epoch 47/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 147ms/step - accuracy: 0.9473 - loss: 0.1352 - val_accuracy: 0.9074 - val_loss: 0.2450 - learning_rate: 5.0000e-05\\n\",\n",
    "      \"Epoch 48/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 149ms/step - accuracy: 0.9526 - loss: 0.1225 - val_accuracy: 0.9019 - val_loss: 0.2355 - learning_rate: 5.0000e-05\\n\",\n",
    "      \"Epoch 49/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m10s\\u001B[0m 148ms/step - accuracy: 0.9475 - loss: 0.1280 - val_accuracy: 0.9151 - val_loss: 0.2098 - learning_rate: 5.0000e-05\\n\",\n",
    "      \"Epoch 50/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 148ms/step - accuracy: 0.9572 - loss: 0.1126 - val_accuracy: 0.9383 - val_loss: 0.1799 - learning_rate: 5.0000e-05\\n\",\n",
    "      \"Epoch 51/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 146ms/step - accuracy: 0.9599 - loss: 0.1058 - val_accuracy: 0.8931 - val_loss: 0.2655 - learning_rate: 5.0000e-05\\n\",\n",
    "      \"Epoch 52/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 147ms/step - accuracy: 0.9581 - loss: 0.1038 - val_accuracy: 0.9405 - val_loss: 0.1614 - learning_rate: 5.0000e-05\\n\",\n",
    "      \"Epoch 53/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 150ms/step - accuracy: 0.9656 - loss: 0.0924 - val_accuracy: 0.9449 - val_loss: 0.1532 - learning_rate: 5.0000e-05\\n\",\n",
    "      \"Epoch 54/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 149ms/step - accuracy: 0.9645 - loss: 0.0888 - val_accuracy: 0.9515 - val_loss: 0.1403 - learning_rate: 5.0000e-05\\n\",\n",
    "      \"Epoch 55/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 147ms/step - accuracy: 0.9627 - loss: 0.0860 - val_accuracy: 0.9305 - val_loss: 0.1838 - learning_rate: 5.0000e-05\\n\",\n",
    "      \"Epoch 56/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 147ms/step - accuracy: 0.9726 - loss: 0.0774 - val_accuracy: 0.9537 - val_loss: 0.1333 - learning_rate: 5.0000e-05\\n\",\n",
    "      \"Epoch 57/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 147ms/step - accuracy: 0.9702 - loss: 0.0810 - val_accuracy: 0.9206 - val_loss: 0.2013 - learning_rate: 5.0000e-05\\n\",\n",
    "      \"Epoch 58/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 146ms/step - accuracy: 0.9749 - loss: 0.0825 - val_accuracy: 0.9361 - val_loss: 0.1697 - learning_rate: 5.0000e-05\\n\",\n",
    "      \"Epoch 59/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 146ms/step - accuracy: 0.9784 - loss: 0.0661 - val_accuracy: 0.9338 - val_loss: 0.1794 - learning_rate: 5.0000e-05\\n\",\n",
    "      \"Epoch 60/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 148ms/step - accuracy: 0.9793 - loss: 0.0628 - val_accuracy: 0.9294 - val_loss: 0.1773 - learning_rate: 5.0000e-05\\n\",\n",
    "      \"Epoch 61/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 148ms/step - accuracy: 0.9830 - loss: 0.0563 - val_accuracy: 0.9614 - val_loss: 0.1204 - learning_rate: 5.0000e-05\\n\",\n",
    "      \"Epoch 62/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 146ms/step - accuracy: 0.9821 - loss: 0.0617 - val_accuracy: 0.9449 - val_loss: 0.1515 - learning_rate: 5.0000e-05\\n\",\n",
    "      \"Epoch 63/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 145ms/step - accuracy: 0.9832 - loss: 0.0567 - val_accuracy: 0.9559 - val_loss: 0.1209 - learning_rate: 5.0000e-05\\n\",\n",
    "      \"Epoch 64/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 148ms/step - accuracy: 0.9835 - loss: 0.0507 - val_accuracy: 0.9636 - val_loss: 0.1101 - learning_rate: 5.0000e-05\\n\",\n",
    "      \"Epoch 65/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 148ms/step - accuracy: 0.9830 - loss: 0.0485 - val_accuracy: 0.9636 - val_loss: 0.1059 - learning_rate: 5.0000e-05\\n\",\n",
    "      \"Epoch 66/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 147ms/step - accuracy: 0.9883 - loss: 0.0441 - val_accuracy: 0.9515 - val_loss: 0.1302 - learning_rate: 5.0000e-05\\n\",\n",
    "      \"Epoch 67/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 147ms/step - accuracy: 0.9872 - loss: 0.0460 - val_accuracy: 0.9625 - val_loss: 0.1110 - learning_rate: 5.0000e-05\\n\",\n",
    "      \"Epoch 68/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 147ms/step - accuracy: 0.9912 - loss: 0.0355 - val_accuracy: 0.9614 - val_loss: 0.1078 - learning_rate: 5.0000e-05\\n\",\n",
    "      \"Epoch 69/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 147ms/step - accuracy: 0.9896 - loss: 0.0386 - val_accuracy: 0.9614 - val_loss: 0.1098 - learning_rate: 5.0000e-05\\n\",\n",
    "      \"Epoch 70/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 151ms/step - accuracy: 0.9905 - loss: 0.0344 - val_accuracy: 0.9669 - val_loss: 0.1053 - learning_rate: 5.0000e-05\\n\",\n",
    "      \"Epoch 71/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 147ms/step - accuracy: 0.9934 - loss: 0.0289 - val_accuracy: 0.9647 - val_loss: 0.1076 - learning_rate: 5.0000e-05\\n\",\n",
    "      \"Epoch 72/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 147ms/step - accuracy: 0.9901 - loss: 0.0329 - val_accuracy: 0.9647 - val_loss: 0.1114 - learning_rate: 5.0000e-05\\n\",\n",
    "      \"Epoch 73/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 148ms/step - accuracy: 0.9903 - loss: 0.0347 - val_accuracy: 0.9735 - val_loss: 0.0874 - learning_rate: 5.0000e-05\\n\",\n",
    "      \"Epoch 74/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 147ms/step - accuracy: 0.9918 - loss: 0.0292 - val_accuracy: 0.9636 - val_loss: 0.1047 - learning_rate: 5.0000e-05\\n\",\n",
    "      \"Epoch 75/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 146ms/step - accuracy: 0.9938 - loss: 0.0259 - val_accuracy: 0.9570 - val_loss: 0.1294 - learning_rate: 5.0000e-05\\n\",\n",
    "      \"Epoch 76/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 146ms/step - accuracy: 0.9943 - loss: 0.0271 - val_accuracy: 0.9713 - val_loss: 0.0952 - learning_rate: 5.0000e-05\\n\",\n",
    "      \"Epoch 77/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 148ms/step - accuracy: 0.9947 - loss: 0.0243 - val_accuracy: 0.9735 - val_loss: 0.1001 - learning_rate: 5.0000e-05\\n\",\n",
    "      \"Epoch 78/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m0s\\u001B[0m 136ms/step - accuracy: 0.9939 - loss: 0.0220\\n\",\n",
    "      \"Epoch 78: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 147ms/step - accuracy: 0.9940 - loss: 0.0229 - val_accuracy: 0.9614 - val_loss: 0.1177 - learning_rate: 5.0000e-05\\n\",\n",
    "      \"Epoch 79/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 146ms/step - accuracy: 0.9971 - loss: 0.0174 - val_accuracy: 0.9680 - val_loss: 0.0954 - learning_rate: 2.5000e-05\\n\",\n",
    "      \"Epoch 80/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 147ms/step - accuracy: 0.9980 - loss: 0.0128 - val_accuracy: 0.9702 - val_loss: 0.0921 - learning_rate: 2.5000e-05\\n\",\n",
    "      \"Epoch 81/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 146ms/step - accuracy: 0.9982 - loss: 0.0147 - val_accuracy: 0.9713 - val_loss: 0.0956 - learning_rate: 2.5000e-05\\n\",\n",
    "      \"Epoch 82/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 153ms/step - accuracy: 0.9974 - loss: 0.0169 - val_accuracy: 0.9768 - val_loss: 0.0806 - learning_rate: 2.5000e-05\\n\",\n",
    "      \"Epoch 83/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m10s\\u001B[0m 147ms/step - accuracy: 0.9965 - loss: 0.0168 - val_accuracy: 0.9757 - val_loss: 0.0844 - learning_rate: 2.5000e-05\\n\",\n",
    "      \"Epoch 84/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 146ms/step - accuracy: 0.9982 - loss: 0.0137 - val_accuracy: 0.9680 - val_loss: 0.0967 - learning_rate: 2.5000e-05\\n\",\n",
    "      \"Epoch 85/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 154ms/step - accuracy: 0.9985 - loss: 0.0129 - val_accuracy: 0.9791 - val_loss: 0.0795 - learning_rate: 2.5000e-05\\n\",\n",
    "      \"Epoch 86/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m10s\\u001B[0m 150ms/step - accuracy: 0.9987 - loss: 0.0117 - val_accuracy: 0.9735 - val_loss: 0.0824 - learning_rate: 2.5000e-05\\n\",\n",
    "      \"Epoch 87/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 147ms/step - accuracy: 0.9982 - loss: 0.0112 - val_accuracy: 0.9702 - val_loss: 0.0984 - learning_rate: 2.5000e-05\\n\",\n",
    "      \"Epoch 88/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m10s\\u001B[0m 146ms/step - accuracy: 0.9982 - loss: 0.0133 - val_accuracy: 0.9713 - val_loss: 0.0871 - learning_rate: 2.5000e-05\\n\",\n",
    "      \"Epoch 89/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 146ms/step - accuracy: 0.9976 - loss: 0.0119 - val_accuracy: 0.9757 - val_loss: 0.0818 - learning_rate: 2.5000e-05\\n\",\n",
    "      \"Epoch 90/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m0s\\u001B[0m 136ms/step - accuracy: 0.9978 - loss: 0.0115\\n\",\n",
    "      \"Epoch 90: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 147ms/step - accuracy: 0.9971 - loss: 0.0127 - val_accuracy: 0.9768 - val_loss: 0.0817 - learning_rate: 2.5000e-05\\n\",\n",
    "      \"Epoch 91/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 146ms/step - accuracy: 0.9987 - loss: 0.0117 - val_accuracy: 0.9735 - val_loss: 0.0843 - learning_rate: 1.2500e-05\\n\",\n",
    "      \"Epoch 92/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 147ms/step - accuracy: 0.9991 - loss: 0.0099 - val_accuracy: 0.9757 - val_loss: 0.0804 - learning_rate: 1.2500e-05\\n\",\n",
    "      \"Epoch 93/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 149ms/step - accuracy: 0.9985 - loss: 0.0107 - val_accuracy: 0.9757 - val_loss: 0.0792 - learning_rate: 1.2500e-05\\n\",\n",
    "      \"Epoch 94/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m10s\\u001B[0m 148ms/step - accuracy: 0.9998 - loss: 0.0093 - val_accuracy: 0.9768 - val_loss: 0.0776 - learning_rate: 1.2500e-05\\n\",\n",
    "      \"Epoch 95/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 146ms/step - accuracy: 0.9989 - loss: 0.0098 - val_accuracy: 0.9768 - val_loss: 0.0805 - learning_rate: 1.2500e-05\\n\",\n",
    "      \"Epoch 96/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 146ms/step - accuracy: 0.9996 - loss: 0.0076 - val_accuracy: 0.9757 - val_loss: 0.0820 - learning_rate: 1.2500e-05\\n\",\n",
    "      \"Epoch 97/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 147ms/step - accuracy: 0.9985 - loss: 0.0099 - val_accuracy: 0.9768 - val_loss: 0.0846 - learning_rate: 1.2500e-05\\n\",\n",
    "      \"Epoch 98/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 149ms/step - accuracy: 0.9985 - loss: 0.0112 - val_accuracy: 0.9746 - val_loss: 0.0779 - learning_rate: 1.2500e-05\\n\",\n",
    "      \"Epoch 99/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m0s\\u001B[0m 136ms/step - accuracy: 0.9993 - loss: 0.0117\\n\",\n",
    "      \"Epoch 99: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 146ms/step - accuracy: 0.9989 - loss: 0.0108 - val_accuracy: 0.9768 - val_loss: 0.0807 - learning_rate: 1.2500e-05\\n\",\n",
    "      \"Epoch 100/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 147ms/step - accuracy: 0.9991 - loss: 0.0083 - val_accuracy: 0.9757 - val_loss: 0.0825 - learning_rate: 6.2500e-06\\n\",\n",
    "      \"Epoch 101/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 146ms/step - accuracy: 0.9989 - loss: 0.0076 - val_accuracy: 0.9791 - val_loss: 0.0805 - learning_rate: 6.2500e-06\\n\",\n",
    "      \"Epoch 102/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 147ms/step - accuracy: 0.9996 - loss: 0.0080 - val_accuracy: 0.9779 - val_loss: 0.0862 - learning_rate: 6.2500e-06\\n\",\n",
    "      \"Epoch 103/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m10s\\u001B[0m 146ms/step - accuracy: 0.9993 - loss: 0.0081 - val_accuracy: 0.9768 - val_loss: 0.0825 - learning_rate: 6.2500e-06\\n\",\n",
    "      \"Epoch 104/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m0s\\u001B[0m 135ms/step - accuracy: 0.9988 - loss: 0.0090\\n\",\n",
    "      \"Epoch 104: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 146ms/step - accuracy: 0.9989 - loss: 0.0093 - val_accuracy: 0.9779 - val_loss: 0.0813 - learning_rate: 6.2500e-06\\n\",\n",
    "      \"Epoch 105/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 148ms/step - accuracy: 0.9991 - loss: 0.0129 - val_accuracy: 0.9791 - val_loss: 0.0776 - learning_rate: 3.1250e-06\\n\",\n",
    "      \"Epoch 106/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 147ms/step - accuracy: 0.9991 - loss: 0.0072 - val_accuracy: 0.9824 - val_loss: 0.0785 - learning_rate: 3.1250e-06\\n\",\n",
    "      \"Epoch 107/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 148ms/step - accuracy: 0.9991 - loss: 0.0089 - val_accuracy: 0.9813 - val_loss: 0.0786 - learning_rate: 3.1250e-06\\n\",\n",
    "      \"Epoch 108/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 148ms/step - accuracy: 0.9996 - loss: 0.0069 - val_accuracy: 0.9768 - val_loss: 0.0796 - learning_rate: 3.1250e-06\\n\",\n",
    "      \"Epoch 109/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m0s\\u001B[0m 136ms/step - accuracy: 0.9993 - loss: 0.0074\\n\",\n",
    "      \"Epoch 109: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 147ms/step - accuracy: 0.9993 - loss: 0.0075 - val_accuracy: 0.9791 - val_loss: 0.0800 - learning_rate: 3.1250e-06\\n\",\n",
    "      \"Epoch 109: early stopping\\n\",\n",
    "      \"Restoring model weights from the end of the best epoch: 94.\\n\",\n",
    "      \"   > Acurácia Validação: 97.68% (Loss: 0.0776)\\n\",\n",
    "      \"   > Novo recorde! (Anterior: 0.00%) -> Salvando modelo...\\n\",\n",
    "      \"--- Rodando Fold 2/6 ---\\n\",\n",
    "      \"Pesos das classes: {0: np.float64(4.461614173228346), 1: np.float64(62.958333333333336), 2: np.float64(0.5001103265666372), 3: np.float64(1.7852079395085065)}\\n\",\n",
    "      \"Epoch 1/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m8s\\u001B[0m 183ms/step - accuracy: 0.3055 - loss: 2.8862 - val_accuracy: 0.1400 - val_loss: 1.6166 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 2/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 147ms/step - accuracy: 0.1840 - loss: 2.8407 - val_accuracy: 0.0706 - val_loss: 1.6980 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 3/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 145ms/step - accuracy: 0.1950 - loss: 2.7981 - val_accuracy: 0.1400 - val_loss: 1.6277 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 4/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 150ms/step - accuracy: 0.2444 - loss: 2.7561 - val_accuracy: 0.3506 - val_loss: 1.5002 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 5/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 150ms/step - accuracy: 0.2837 - loss: 2.6339 - val_accuracy: 0.2481 - val_loss: 1.4174 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 6/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 146ms/step - accuracy: 0.3371 - loss: 2.4932 - val_accuracy: 0.2911 - val_loss: 1.6064 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 7/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 157ms/step - accuracy: 0.3971 - loss: 2.2761 - val_accuracy: 0.5645 - val_loss: 1.1170 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 8/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 147ms/step - accuracy: 0.4319 - loss: 2.0885 - val_accuracy: 0.3991 - val_loss: 1.4464 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 9/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 154ms/step - accuracy: 0.4399 - loss: 1.8860 - val_accuracy: 0.5182 - val_loss: 1.0850 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 10/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 146ms/step - accuracy: 0.4831 - loss: 1.6128 - val_accuracy: 0.5072 - val_loss: 1.1127 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 11/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 146ms/step - accuracy: 0.5100 - loss: 1.4995 - val_accuracy: 0.4950 - val_loss: 1.1657 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 12/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 162ms/step - accuracy: 0.5292 - loss: 1.3446 - val_accuracy: 0.5921 - val_loss: 0.9161 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 13/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 146ms/step - accuracy: 0.5709 - loss: 1.2223 - val_accuracy: 0.5821 - val_loss: 0.9389 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 14/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 150ms/step - accuracy: 0.5537 - loss: 1.1738 - val_accuracy: 0.5965 - val_loss: 0.9101 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 15/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 145ms/step - accuracy: 0.5844 - loss: 1.1166 - val_accuracy: 0.6053 - val_loss: 0.9232 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 16/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 169ms/step - accuracy: 0.6000 - loss: 1.0560 - val_accuracy: 0.6262 - val_loss: 0.8374 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 17/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 159ms/step - accuracy: 0.6298 - loss: 0.9566 - val_accuracy: 0.6373 - val_loss: 0.8089 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 18/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 145ms/step - accuracy: 0.6378 - loss: 0.8891 - val_accuracy: 0.6384 - val_loss: 0.8402 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 19/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 151ms/step - accuracy: 0.6592 - loss: 0.8296 - val_accuracy: 0.6759 - val_loss: 0.7242 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 20/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 152ms/step - accuracy: 0.6777 - loss: 0.7542 - val_accuracy: 0.6725 - val_loss: 0.7209 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 21/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 157ms/step - accuracy: 0.7033 - loss: 0.6868 - val_accuracy: 0.7398 - val_loss: 0.5961 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 22/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 146ms/step - accuracy: 0.7194 - loss: 0.6735 - val_accuracy: 0.6670 - val_loss: 0.7707 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 23/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 159ms/step - accuracy: 0.7159 - loss: 0.6326 - val_accuracy: 0.7806 - val_loss: 0.5242 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 24/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 150ms/step - accuracy: 0.7450 - loss: 0.5435 - val_accuracy: 0.8004 - val_loss: 0.4794 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 25/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 146ms/step - accuracy: 0.7617 - loss: 0.5205 - val_accuracy: 0.7630 - val_loss: 0.5285 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 26/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 146ms/step - accuracy: 0.7871 - loss: 0.4707 - val_accuracy: 0.7894 - val_loss: 0.4846 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 27/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 145ms/step - accuracy: 0.7988 - loss: 0.4309 - val_accuracy: 0.7585 - val_loss: 0.5221 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 28/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 146ms/step - accuracy: 0.8200 - loss: 0.3748 - val_accuracy: 0.7806 - val_loss: 0.4800 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 29/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 151ms/step - accuracy: 0.8462 - loss: 0.3586 - val_accuracy: 0.7982 - val_loss: 0.4498 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 30/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 156ms/step - accuracy: 0.8449 - loss: 0.3265 - val_accuracy: 0.8886 - val_loss: 0.3009 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 31/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 147ms/step - accuracy: 0.8566 - loss: 0.2959 - val_accuracy: 0.7762 - val_loss: 0.4836 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 32/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 146ms/step - accuracy: 0.8809 - loss: 0.2597 - val_accuracy: 0.8049 - val_loss: 0.4314 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 33/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 153ms/step - accuracy: 0.8855 - loss: 0.2454 - val_accuracy: 0.8721 - val_loss: 0.2974 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 34/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 145ms/step - accuracy: 0.9003 - loss: 0.2261 - val_accuracy: 0.8633 - val_loss: 0.3115 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 35/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 153ms/step - accuracy: 0.9076 - loss: 0.2038 - val_accuracy: 0.8831 - val_loss: 0.2893 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 36/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 154ms/step - accuracy: 0.9144 - loss: 0.1822 - val_accuracy: 0.9195 - val_loss: 0.2307 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 37/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 147ms/step - accuracy: 0.9327 - loss: 0.1545 - val_accuracy: 0.8953 - val_loss: 0.2502 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 38/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 148ms/step - accuracy: 0.9360 - loss: 0.1448 - val_accuracy: 0.9438 - val_loss: 0.1867 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 39/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 147ms/step - accuracy: 0.9466 - loss: 0.1304 - val_accuracy: 0.9294 - val_loss: 0.2080 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 40/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 152ms/step - accuracy: 0.9482 - loss: 0.1248 - val_accuracy: 0.9636 - val_loss: 0.1411 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 41/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 146ms/step - accuracy: 0.9574 - loss: 0.1056 - val_accuracy: 0.8864 - val_loss: 0.2862 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 42/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 147ms/step - accuracy: 0.9674 - loss: 0.0925 - val_accuracy: 0.9316 - val_loss: 0.1825 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 43/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 146ms/step - accuracy: 0.9640 - loss: 0.0963 - val_accuracy: 0.8688 - val_loss: 0.3211 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 44/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 152ms/step - accuracy: 0.9696 - loss: 0.0783 - val_accuracy: 0.9658 - val_loss: 0.1214 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 45/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 152ms/step - accuracy: 0.9773 - loss: 0.0696 - val_accuracy: 0.9724 - val_loss: 0.1073 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 46/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 158ms/step - accuracy: 0.9737 - loss: 0.0705 - val_accuracy: 0.9713 - val_loss: 0.1029 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 47/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 147ms/step - accuracy: 0.9812 - loss: 0.0522 - val_accuracy: 0.9724 - val_loss: 0.1062 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 48/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 147ms/step - accuracy: 0.9755 - loss: 0.0640 - val_accuracy: 0.9460 - val_loss: 0.1696 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 49/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 155ms/step - accuracy: 0.9786 - loss: 0.0589 - val_accuracy: 0.9735 - val_loss: 0.0945 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 50/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 146ms/step - accuracy: 0.9854 - loss: 0.0470 - val_accuracy: 0.9658 - val_loss: 0.1070 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 51/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 150ms/step - accuracy: 0.9795 - loss: 0.0702 - val_accuracy: 0.9791 - val_loss: 0.0866 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 52/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 146ms/step - accuracy: 0.9892 - loss: 0.0409 - val_accuracy: 0.9724 - val_loss: 0.1012 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 53/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 147ms/step - accuracy: 0.9879 - loss: 0.0425 - val_accuracy: 0.9658 - val_loss: 0.1047 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 54/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 146ms/step - accuracy: 0.9872 - loss: 0.0368 - val_accuracy: 0.9735 - val_loss: 0.0947 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 55/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 146ms/step - accuracy: 0.9896 - loss: 0.0377 - val_accuracy: 0.9658 - val_loss: 0.1264 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 56/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m0s\\u001B[0m 135ms/step - accuracy: 0.9935 - loss: 0.0294\\n\",\n",
    "      \"Epoch 56: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 145ms/step - accuracy: 0.9921 - loss: 0.0287 - val_accuracy: 0.9746 - val_loss: 0.0888 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 57/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 153ms/step - accuracy: 0.9949 - loss: 0.0235 - val_accuracy: 0.9813 - val_loss: 0.0763 - learning_rate: 5.0000e-05\\n\",\n",
    "      \"Epoch 58/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 146ms/step - accuracy: 0.9954 - loss: 0.0194 - val_accuracy: 0.9768 - val_loss: 0.0835 - learning_rate: 5.0000e-05\\n\",\n",
    "      \"Epoch 59/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 147ms/step - accuracy: 0.9976 - loss: 0.0149 - val_accuracy: 0.9779 - val_loss: 0.0878 - learning_rate: 5.0000e-05\\n\",\n",
    "      \"Epoch 60/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 146ms/step - accuracy: 0.9971 - loss: 0.0168 - val_accuracy: 0.9791 - val_loss: 0.0773 - learning_rate: 5.0000e-05\\n\",\n",
    "      \"Epoch 61/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 148ms/step - accuracy: 0.9976 - loss: 0.0132 - val_accuracy: 0.9857 - val_loss: 0.0678 - learning_rate: 5.0000e-05\\n\",\n",
    "      \"Epoch 62/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 146ms/step - accuracy: 0.9978 - loss: 0.0138 - val_accuracy: 0.9824 - val_loss: 0.0778 - learning_rate: 5.0000e-05\\n\",\n",
    "      \"Epoch 63/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 146ms/step - accuracy: 0.9989 - loss: 0.0106 - val_accuracy: 0.9791 - val_loss: 0.0899 - learning_rate: 5.0000e-05\\n\",\n",
    "      \"Epoch 64/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 146ms/step - accuracy: 0.9978 - loss: 0.0121 - val_accuracy: 0.9824 - val_loss: 0.0717 - learning_rate: 5.0000e-05\\n\",\n",
    "      \"Epoch 65/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 146ms/step - accuracy: 0.9971 - loss: 0.0119 - val_accuracy: 0.9846 - val_loss: 0.0707 - learning_rate: 5.0000e-05\\n\",\n",
    "      \"Epoch 66/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m0s\\u001B[0m 135ms/step - accuracy: 0.9988 - loss: 0.0115\\n\",\n",
    "      \"Epoch 66: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 146ms/step - accuracy: 0.9982 - loss: 0.0121 - val_accuracy: 0.9746 - val_loss: 0.1017 - learning_rate: 5.0000e-05\\n\",\n",
    "      \"Epoch 67/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 145ms/step - accuracy: 0.9982 - loss: 0.0092 - val_accuracy: 0.9835 - val_loss: 0.0767 - learning_rate: 2.5000e-05\\n\",\n",
    "      \"Epoch 68/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 145ms/step - accuracy: 0.9987 - loss: 0.0092 - val_accuracy: 0.9802 - val_loss: 0.0765 - learning_rate: 2.5000e-05\\n\",\n",
    "      \"Epoch 69/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 145ms/step - accuracy: 0.9978 - loss: 0.0093 - val_accuracy: 0.9802 - val_loss: 0.0845 - learning_rate: 2.5000e-05\\n\",\n",
    "      \"Epoch 70/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 147ms/step - accuracy: 0.9993 - loss: 0.0074 - val_accuracy: 0.9802 - val_loss: 0.0806 - learning_rate: 2.5000e-05\\n\",\n",
    "      \"Epoch 71/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m0s\\u001B[0m 135ms/step - accuracy: 0.9985 - loss: 0.0080\\n\",\n",
    "      \"Epoch 71: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 146ms/step - accuracy: 0.9989 - loss: 0.0074 - val_accuracy: 0.9802 - val_loss: 0.0832 - learning_rate: 2.5000e-05\\n\",\n",
    "      \"Epoch 72/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 145ms/step - accuracy: 0.9996 - loss: 0.0060 - val_accuracy: 0.9813 - val_loss: 0.0775 - learning_rate: 1.2500e-05\\n\",\n",
    "      \"Epoch 73/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 145ms/step - accuracy: 0.9987 - loss: 0.0065 - val_accuracy: 0.9813 - val_loss: 0.0801 - learning_rate: 1.2500e-05\\n\",\n",
    "      \"Epoch 74/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 146ms/step - accuracy: 0.9996 - loss: 0.0066 - val_accuracy: 0.9835 - val_loss: 0.0778 - learning_rate: 1.2500e-05\\n\",\n",
    "      \"Epoch 75/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 146ms/step - accuracy: 0.9989 - loss: 0.0057 - val_accuracy: 0.9824 - val_loss: 0.0784 - learning_rate: 1.2500e-05\\n\",\n",
    "      \"Epoch 76/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m0s\\u001B[0m 136ms/step - accuracy: 0.9982 - loss: 0.0069\\n\",\n",
    "      \"Epoch 76: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 146ms/step - accuracy: 0.9982 - loss: 0.0076 - val_accuracy: 0.9824 - val_loss: 0.0784 - learning_rate: 1.2500e-05\\n\",\n",
    "      \"Epoch 76: early stopping\\n\",\n",
    "      \"Restoring model weights from the end of the best epoch: 61.\\n\",\n",
    "      \"   > Acurácia Validação: 98.57% (Loss: 0.0678)\\n\",\n",
    "      \"   > Novo recorde! (Anterior: 97.68%) -> Salvando modelo...\\n\",\n",
    "      \"--- Rodando Fold 3/6 ---\\n\",\n",
    "      \"Pesos das classes: {0: np.float64(4.461614173228346), 1: np.float64(62.958333333333336), 2: np.float64(0.49988972209969124), 3: np.float64(1.7863335435056746)}\\n\",\n",
    "      \"Epoch 1/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m8s\\u001B[0m 161ms/step - accuracy: 0.2213 - loss: 2.8678 - val_accuracy: 0.3506 - val_loss: 1.5917 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 2/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 146ms/step - accuracy: 0.2226 - loss: 2.8214 - val_accuracy: 0.1610 - val_loss: 1.6395 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 3/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 147ms/step - accuracy: 0.2305 - loss: 2.7685 - val_accuracy: 0.2492 - val_loss: 1.5630 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 4/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 152ms/step - accuracy: 0.2857 - loss: 2.7078 - val_accuracy: 0.3462 - val_loss: 1.3654 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 5/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m10s\\u001B[0m 145ms/step - accuracy: 0.2861 - loss: 2.5211 - val_accuracy: 0.3098 - val_loss: 1.5258 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 6/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 148ms/step - accuracy: 0.3369 - loss: 2.3823 - val_accuracy: 0.3738 - val_loss: 1.2926 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 7/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 147ms/step - accuracy: 0.3594 - loss: 2.2921 - val_accuracy: 0.2889 - val_loss: 1.5016 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 8/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 148ms/step - accuracy: 0.3977 - loss: 1.9516 - val_accuracy: 0.4763 - val_loss: 1.0974 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 9/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 145ms/step - accuracy: 0.4584 - loss: 1.8682 - val_accuracy: 0.4068 - val_loss: 1.3162 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 10/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 148ms/step - accuracy: 0.4705 - loss: 1.6213 - val_accuracy: 0.5050 - val_loss: 1.0342 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 11/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 146ms/step - accuracy: 0.4931 - loss: 1.4961 - val_accuracy: 0.4972 - val_loss: 1.1100 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 12/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 147ms/step - accuracy: 0.5160 - loss: 1.3803 - val_accuracy: 0.5557 - val_loss: 0.9893 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 13/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 147ms/step - accuracy: 0.5297 - loss: 1.2578 - val_accuracy: 0.5976 - val_loss: 0.9060 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 14/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 146ms/step - accuracy: 0.5831 - loss: 1.1164 - val_accuracy: 0.5634 - val_loss: 0.9699 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 15/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 161ms/step - accuracy: 0.5912 - loss: 1.0700 - val_accuracy: 0.6086 - val_loss: 0.8951 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 16/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 147ms/step - accuracy: 0.6053 - loss: 0.9828 - val_accuracy: 0.5755 - val_loss: 0.9181 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 17/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 149ms/step - accuracy: 0.6228 - loss: 0.9164 - val_accuracy: 0.6725 - val_loss: 0.7504 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 18/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 145ms/step - accuracy: 0.6598 - loss: 0.8218 - val_accuracy: 0.6318 - val_loss: 0.8356 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 19/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 146ms/step - accuracy: 0.6715 - loss: 0.7590 - val_accuracy: 0.6461 - val_loss: 0.8259 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 20/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 158ms/step - accuracy: 0.6795 - loss: 0.7262 - val_accuracy: 0.7464 - val_loss: 0.5866 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 21/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 149ms/step - accuracy: 0.6940 - loss: 0.6809 - val_accuracy: 0.7365 - val_loss: 0.5758 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 22/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 146ms/step - accuracy: 0.7364 - loss: 0.6009 - val_accuracy: 0.6990 - val_loss: 0.6770 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 23/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 151ms/step - accuracy: 0.7362 - loss: 0.5497 - val_accuracy: 0.7883 - val_loss: 0.5296 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 24/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 148ms/step - accuracy: 0.7686 - loss: 0.4896 - val_accuracy: 0.7718 - val_loss: 0.5082 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 25/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 146ms/step - accuracy: 0.7893 - loss: 0.4568 - val_accuracy: 0.7045 - val_loss: 0.6540 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 26/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 158ms/step - accuracy: 0.8012 - loss: 0.4091 - val_accuracy: 0.7971 - val_loss: 0.4724 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 27/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 148ms/step - accuracy: 0.8083 - loss: 0.3913 - val_accuracy: 0.8335 - val_loss: 0.3995 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 28/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 146ms/step - accuracy: 0.8167 - loss: 0.3534 - val_accuracy: 0.8093 - val_loss: 0.4242 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 29/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 146ms/step - accuracy: 0.8542 - loss: 0.2972 - val_accuracy: 0.8071 - val_loss: 0.4284 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 30/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 153ms/step - accuracy: 0.8601 - loss: 0.2832 - val_accuracy: 0.8512 - val_loss: 0.3575 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 31/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 152ms/step - accuracy: 0.8908 - loss: 0.2359 - val_accuracy: 0.8953 - val_loss: 0.2878 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 32/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 146ms/step - accuracy: 0.8939 - loss: 0.2259 - val_accuracy: 0.8644 - val_loss: 0.3275 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 33/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 146ms/step - accuracy: 0.9051 - loss: 0.2019 - val_accuracy: 0.8082 - val_loss: 0.4306 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 34/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 146ms/step - accuracy: 0.9054 - loss: 0.2027 - val_accuracy: 0.9361 - val_loss: 0.2050 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 35/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m5s\\u001B[0m 142ms/step - accuracy: 0.9168 - loss: 0.1790 - val_accuracy: 0.9107 - val_loss: 0.2353 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 36/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m5s\\u001B[0m 143ms/step - accuracy: 0.9316 - loss: 0.1589 - val_accuracy: 0.9118 - val_loss: 0.2427 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 37/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 163ms/step - accuracy: 0.9354 - loss: 0.1510 - val_accuracy: 0.8699 - val_loss: 0.3027 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 38/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 158ms/step - accuracy: 0.9402 - loss: 0.1394 - val_accuracy: 0.9383 - val_loss: 0.1872 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 39/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 154ms/step - accuracy: 0.9506 - loss: 0.1170 - val_accuracy: 0.9228 - val_loss: 0.1922 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 40/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 154ms/step - accuracy: 0.9519 - loss: 0.1107 - val_accuracy: 0.9338 - val_loss: 0.1885 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 41/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 163ms/step - accuracy: 0.9572 - loss: 0.1009 - val_accuracy: 0.9526 - val_loss: 0.1278 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 42/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 144ms/step - accuracy: 0.9607 - loss: 0.0914 - val_accuracy: 0.8942 - val_loss: 0.2509 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 43/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 145ms/step - accuracy: 0.9607 - loss: 0.0991 - val_accuracy: 0.9416 - val_loss: 0.1480 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 44/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 147ms/step - accuracy: 0.9729 - loss: 0.0685 - val_accuracy: 0.9603 - val_loss: 0.0999 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 45/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 145ms/step - accuracy: 0.9735 - loss: 0.0650 - val_accuracy: 0.9493 - val_loss: 0.1330 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 46/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 148ms/step - accuracy: 0.9654 - loss: 0.0838 - val_accuracy: 0.9592 - val_loss: 0.0940 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 47/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 143ms/step - accuracy: 0.9790 - loss: 0.0605 - val_accuracy: 0.9603 - val_loss: 0.1055 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 48/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m5s\\u001B[0m 143ms/step - accuracy: 0.9764 - loss: 0.0652 - val_accuracy: 0.9614 - val_loss: 0.1069 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 49/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 159ms/step - accuracy: 0.9795 - loss: 0.0534 - val_accuracy: 0.9658 - val_loss: 0.0813 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 50/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 156ms/step - accuracy: 0.9808 - loss: 0.0493 - val_accuracy: 0.9768 - val_loss: 0.0675 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 51/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 143ms/step - accuracy: 0.9835 - loss: 0.0461 - val_accuracy: 0.9757 - val_loss: 0.0696 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 52/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m5s\\u001B[0m 143ms/step - accuracy: 0.9859 - loss: 0.0467 - val_accuracy: 0.9427 - val_loss: 0.1527 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 53/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 144ms/step - accuracy: 0.9837 - loss: 0.0422 - val_accuracy: 0.9757 - val_loss: 0.0710 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 54/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 150ms/step - accuracy: 0.9868 - loss: 0.0402 - val_accuracy: 0.9757 - val_loss: 0.0632 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 55/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 145ms/step - accuracy: 0.9892 - loss: 0.0321 - val_accuracy: 0.9647 - val_loss: 0.1032 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 56/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m5s\\u001B[0m 143ms/step - accuracy: 0.9881 - loss: 0.0384 - val_accuracy: 0.9548 - val_loss: 0.1009 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 57/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m5s\\u001B[0m 144ms/step - accuracy: 0.9907 - loss: 0.0294 - val_accuracy: 0.9724 - val_loss: 0.0686 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 58/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 147ms/step - accuracy: 0.9938 - loss: 0.0266 - val_accuracy: 0.9757 - val_loss: 0.0598 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 59/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 145ms/step - accuracy: 0.9954 - loss: 0.0217 - val_accuracy: 0.9724 - val_loss: 0.0843 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 60/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 145ms/step - accuracy: 0.9927 - loss: 0.0251 - val_accuracy: 0.9625 - val_loss: 0.1076 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 61/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 144ms/step - accuracy: 0.9907 - loss: 0.0278 - val_accuracy: 0.9735 - val_loss: 0.0657 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 62/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 145ms/step - accuracy: 0.9927 - loss: 0.0223 - val_accuracy: 0.9757 - val_loss: 0.0763 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 63/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m0s\\u001B[0m 133ms/step - accuracy: 0.9954 - loss: 0.0176\\n\",\n",
    "      \"Epoch 63: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 144ms/step - accuracy: 0.9956 - loss: 0.0178 - val_accuracy: 0.9757 - val_loss: 0.0625 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 64/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m5s\\u001B[0m 143ms/step - accuracy: 0.9956 - loss: 0.0159 - val_accuracy: 0.9746 - val_loss: 0.0749 - learning_rate: 5.0000e-05\\n\",\n",
    "      \"Epoch 65/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 145ms/step - accuracy: 0.9971 - loss: 0.0105 - val_accuracy: 0.9857 - val_loss: 0.0429 - learning_rate: 5.0000e-05\\n\",\n",
    "      \"Epoch 66/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 151ms/step - accuracy: 0.9991 - loss: 0.0073 - val_accuracy: 0.9857 - val_loss: 0.0408 - learning_rate: 5.0000e-05\\n\",\n",
    "      \"Epoch 67/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 144ms/step - accuracy: 0.9985 - loss: 0.0083 - val_accuracy: 0.9846 - val_loss: 0.0473 - learning_rate: 5.0000e-05\\n\",\n",
    "      \"Epoch 68/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 144ms/step - accuracy: 0.9993 - loss: 0.0076 - val_accuracy: 0.9835 - val_loss: 0.0417 - learning_rate: 5.0000e-05\\n\",\n",
    "      \"Epoch 69/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 146ms/step - accuracy: 0.9985 - loss: 0.0068 - val_accuracy: 0.9846 - val_loss: 0.0406 - learning_rate: 5.0000e-05\\n\",\n",
    "      \"Epoch 70/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m5s\\u001B[0m 143ms/step - accuracy: 0.9985 - loss: 0.0106 - val_accuracy: 0.9846 - val_loss: 0.0407 - learning_rate: 5.0000e-05\\n\",\n",
    "      \"Epoch 71/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m5s\\u001B[0m 143ms/step - accuracy: 0.9991 - loss: 0.0063 - val_accuracy: 0.9813 - val_loss: 0.0634 - learning_rate: 5.0000e-05\\n\",\n",
    "      \"Epoch 72/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 145ms/step - accuracy: 0.9985 - loss: 0.0077 - val_accuracy: 0.9835 - val_loss: 0.0534 - learning_rate: 5.0000e-05\\n\",\n",
    "      \"Epoch 73/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m5s\\u001B[0m 144ms/step - accuracy: 0.9991 - loss: 0.0062 - val_accuracy: 0.9846 - val_loss: 0.0466 - learning_rate: 5.0000e-05\\n\",\n",
    "      \"Epoch 74/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m0s\\u001B[0m 133ms/step - accuracy: 0.9985 - loss: 0.0068\\n\",\n",
    "      \"Epoch 74: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m5s\\u001B[0m 144ms/step - accuracy: 0.9982 - loss: 0.0077 - val_accuracy: 0.9835 - val_loss: 0.0591 - learning_rate: 5.0000e-05\\n\",\n",
    "      \"Epoch 75/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 151ms/step - accuracy: 0.9987 - loss: 0.0094 - val_accuracy: 0.9857 - val_loss: 0.0368 - learning_rate: 2.5000e-05\\n\",\n",
    "      \"Epoch 76/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 149ms/step - accuracy: 0.9993 - loss: 0.0045 - val_accuracy: 0.9879 - val_loss: 0.0343 - learning_rate: 2.5000e-05\\n\",\n",
    "      \"Epoch 77/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m5s\\u001B[0m 143ms/step - accuracy: 1.0000 - loss: 0.0030 - val_accuracy: 0.9846 - val_loss: 0.0419 - learning_rate: 2.5000e-05\\n\",\n",
    "      \"Epoch 78/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 145ms/step - accuracy: 0.9991 - loss: 0.0053 - val_accuracy: 0.9857 - val_loss: 0.0356 - learning_rate: 2.5000e-05\\n\",\n",
    "      \"Epoch 79/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m5s\\u001B[0m 144ms/step - accuracy: 0.9996 - loss: 0.0037 - val_accuracy: 0.9846 - val_loss: 0.0433 - learning_rate: 2.5000e-05\\n\",\n",
    "      \"Epoch 80/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m5s\\u001B[0m 143ms/step - accuracy: 0.9998 - loss: 0.0039 - val_accuracy: 0.9857 - val_loss: 0.0397 - learning_rate: 2.5000e-05\\n\",\n",
    "      \"Epoch 81/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m0s\\u001B[0m 133ms/step - accuracy: 0.9997 - loss: 0.0030\\n\",\n",
    "      \"Epoch 81: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m5s\\u001B[0m 144ms/step - accuracy: 0.9993 - loss: 0.0033 - val_accuracy: 0.9868 - val_loss: 0.0379 - learning_rate: 2.5000e-05\\n\",\n",
    "      \"Epoch 82/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m5s\\u001B[0m 143ms/step - accuracy: 0.9998 - loss: 0.0034 - val_accuracy: 0.9835 - val_loss: 0.0388 - learning_rate: 1.2500e-05\\n\",\n",
    "      \"Epoch 83/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m5s\\u001B[0m 143ms/step - accuracy: 0.9993 - loss: 0.0033 - val_accuracy: 0.9879 - val_loss: 0.0385 - learning_rate: 1.2500e-05\\n\",\n",
    "      \"Epoch 84/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 145ms/step - accuracy: 0.9989 - loss: 0.0079 - val_accuracy: 0.9868 - val_loss: 0.0440 - learning_rate: 1.2500e-05\\n\",\n",
    "      \"Epoch 85/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m5s\\u001B[0m 144ms/step - accuracy: 0.9996 - loss: 0.0037 - val_accuracy: 0.9857 - val_loss: 0.0411 - learning_rate: 1.2500e-05\\n\",\n",
    "      \"Epoch 86/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m0s\\u001B[0m 133ms/step - accuracy: 0.9993 - loss: 0.0035\\n\",\n",
    "      \"Epoch 86: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m5s\\u001B[0m 144ms/step - accuracy: 0.9993 - loss: 0.0030 - val_accuracy: 0.9868 - val_loss: 0.0372 - learning_rate: 1.2500e-05\\n\",\n",
    "      \"Epoch 87/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 144ms/step - accuracy: 0.9996 - loss: 0.0040 - val_accuracy: 0.9857 - val_loss: 0.0431 - learning_rate: 6.2500e-06\\n\",\n",
    "      \"Epoch 88/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 143ms/step - accuracy: 0.9993 - loss: 0.0034 - val_accuracy: 0.9857 - val_loss: 0.0344 - learning_rate: 6.2500e-06\\n\",\n",
    "      \"Epoch 89/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 144ms/step - accuracy: 0.9998 - loss: 0.0024 - val_accuracy: 0.9868 - val_loss: 0.0362 - learning_rate: 6.2500e-06\\n\",\n",
    "      \"Epoch 90/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 145ms/step - accuracy: 0.9998 - loss: 0.0032 - val_accuracy: 0.9857 - val_loss: 0.0365 - learning_rate: 6.2500e-06\\n\",\n",
    "      \"Epoch 91/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m0s\\u001B[0m 134ms/step - accuracy: 0.9995 - loss: 0.0022\\n\",\n",
    "      \"Epoch 91: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 145ms/step - accuracy: 0.9998 - loss: 0.0023 - val_accuracy: 0.9879 - val_loss: 0.0360 - learning_rate: 6.2500e-06\\n\",\n",
    "      \"Epoch 91: early stopping\\n\",\n",
    "      \"Restoring model weights from the end of the best epoch: 76.\\n\",\n",
    "      \"   > Acurácia Validação: 98.79% (Loss: 0.0343)\\n\",\n",
    "      \"   > Novo recorde! (Anterior: 98.57%) -> Salvando modelo...\\n\",\n",
    "      \"--- Rodando Fold 4/6 ---\\n\",\n",
    "      \"Pesos das classes: {0: np.float64(4.461614173228346), 1: np.float64(62.958333333333336), 2: np.float64(0.49988972209969124), 3: np.float64(1.7863335435056746)}\\n\",\n",
    "      \"Epoch 1/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m7s\\u001B[0m 149ms/step - accuracy: 0.2683 - loss: 2.8942 - val_accuracy: 0.1455 - val_loss: 1.5448 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 2/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 143ms/step - accuracy: 0.2199 - loss: 2.8355 - val_accuracy: 0.3649 - val_loss: 1.6300 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 3/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m5s\\u001B[0m 143ms/step - accuracy: 0.2563 - loss: 2.8106 - val_accuracy: 0.1841 - val_loss: 1.6811 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 4/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 145ms/step - accuracy: 0.2535 - loss: 2.7592 - val_accuracy: 0.2018 - val_loss: 1.6015 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 5/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 146ms/step - accuracy: 0.2910 - loss: 2.6840 - val_accuracy: 0.3484 - val_loss: 1.5005 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 6/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 145ms/step - accuracy: 0.3042 - loss: 2.6366 - val_accuracy: 0.3297 - val_loss: 1.4084 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 7/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m5s\\u001B[0m 143ms/step - accuracy: 0.3492 - loss: 2.4121 - val_accuracy: 0.2712 - val_loss: 1.6833 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 8/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m5s\\u001B[0m 143ms/step - accuracy: 0.3920 - loss: 2.2433 - val_accuracy: 0.3484 - val_loss: 1.5391 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 9/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 145ms/step - accuracy: 0.4079 - loss: 2.1023 - val_accuracy: 0.5182 - val_loss: 1.1328 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 10/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 145ms/step - accuracy: 0.4677 - loss: 1.8019 - val_accuracy: 0.5634 - val_loss: 0.9884 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 11/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m5s\\u001B[0m 143ms/step - accuracy: 0.4994 - loss: 1.6258 - val_accuracy: 0.5204 - val_loss: 1.1558 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 12/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m5s\\u001B[0m 144ms/step - accuracy: 0.5014 - loss: 1.5270 - val_accuracy: 0.5987 - val_loss: 0.9727 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 13/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 143ms/step - accuracy: 0.5458 - loss: 1.3484 - val_accuracy: 0.4774 - val_loss: 1.3074 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 14/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m5s\\u001B[0m 143ms/step - accuracy: 0.5577 - loss: 1.2654 - val_accuracy: 0.5436 - val_loss: 1.1086 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 15/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 145ms/step - accuracy: 0.5698 - loss: 1.1714 - val_accuracy: 0.6174 - val_loss: 0.8926 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 16/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 145ms/step - accuracy: 0.5959 - loss: 1.0461 - val_accuracy: 0.6516 - val_loss: 0.8526 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 17/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 145ms/step - accuracy: 0.6036 - loss: 0.9961 - val_accuracy: 0.6582 - val_loss: 0.7675 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 18/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 145ms/step - accuracy: 0.6391 - loss: 0.9047 - val_accuracy: 0.7189 - val_loss: 0.6729 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 19/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m5s\\u001B[0m 143ms/step - accuracy: 0.6711 - loss: 0.8151 - val_accuracy: 0.6042 - val_loss: 0.9090 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 20/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 144ms/step - accuracy: 0.6684 - loss: 0.7836 - val_accuracy: 0.7012 - val_loss: 0.6702 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 21/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 149ms/step - accuracy: 0.6872 - loss: 0.7257 - val_accuracy: 0.7420 - val_loss: 0.6388 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 22/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 145ms/step - accuracy: 0.7236 - loss: 0.6187 - val_accuracy: 0.7960 - val_loss: 0.4843 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 23/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m5s\\u001B[0m 143ms/step - accuracy: 0.7351 - loss: 0.5934 - val_accuracy: 0.7861 - val_loss: 0.5178 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 24/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 144ms/step - accuracy: 0.7501 - loss: 0.5378 - val_accuracy: 0.8148 - val_loss: 0.4776 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 25/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 144ms/step - accuracy: 0.7712 - loss: 0.4848 - val_accuracy: 0.8203 - val_loss: 0.4409 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 26/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 144ms/step - accuracy: 0.7920 - loss: 0.4536 - val_accuracy: 0.8688 - val_loss: 0.3926 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 27/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 144ms/step - accuracy: 0.8050 - loss: 0.4058 - val_accuracy: 0.7277 - val_loss: 0.5791 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 28/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 144ms/step - accuracy: 0.8103 - loss: 0.3712 - val_accuracy: 0.8501 - val_loss: 0.3951 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 29/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m5s\\u001B[0m 143ms/step - accuracy: 0.8423 - loss: 0.3318 - val_accuracy: 0.8192 - val_loss: 0.4644 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 30/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m5s\\u001B[0m 144ms/step - accuracy: 0.8515 - loss: 0.3080 - val_accuracy: 0.8600 - val_loss: 0.3745 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 31/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m5s\\u001B[0m 144ms/step - accuracy: 0.8681 - loss: 0.2751 - val_accuracy: 0.9228 - val_loss: 0.2610 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 32/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 152ms/step - accuracy: 0.8740 - loss: 0.2626 - val_accuracy: 0.7541 - val_loss: 0.5255 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 33/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 147ms/step - accuracy: 0.8868 - loss: 0.2317 - val_accuracy: 0.8908 - val_loss: 0.3040 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 34/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 144ms/step - accuracy: 0.8981 - loss: 0.2127 - val_accuracy: 0.8523 - val_loss: 0.3733 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 35/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 143ms/step - accuracy: 0.9148 - loss: 0.1910 - val_accuracy: 0.9063 - val_loss: 0.2801 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 36/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 165ms/step - accuracy: 0.9217 - loss: 0.1769 - val_accuracy: 0.9107 - val_loss: 0.2293 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 37/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 145ms/step - accuracy: 0.9340 - loss: 0.1597 - val_accuracy: 0.9239 - val_loss: 0.2276 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 38/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m7s\\u001B[0m 182ms/step - accuracy: 0.9367 - loss: 0.1469 - val_accuracy: 0.9239 - val_loss: 0.2058 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 39/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 146ms/step - accuracy: 0.9367 - loss: 0.1422 - val_accuracy: 0.9383 - val_loss: 0.1994 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 40/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 149ms/step - accuracy: 0.9519 - loss: 0.1222 - val_accuracy: 0.9570 - val_loss: 0.1447 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 41/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 145ms/step - accuracy: 0.9515 - loss: 0.1174 - val_accuracy: 0.9636 - val_loss: 0.1410 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 42/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 145ms/step - accuracy: 0.9568 - loss: 0.0998 - val_accuracy: 0.9691 - val_loss: 0.1164 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 43/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m10s\\u001B[0m 144ms/step - accuracy: 0.9647 - loss: 0.0917 - val_accuracy: 0.9438 - val_loss: 0.1812 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 44/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m5s\\u001B[0m 144ms/step - accuracy: 0.9678 - loss: 0.0816 - val_accuracy: 0.9614 - val_loss: 0.1476 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 45/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 144ms/step - accuracy: 0.9674 - loss: 0.0835 - val_accuracy: 0.9559 - val_loss: 0.1371 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 46/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m5s\\u001B[0m 144ms/step - accuracy: 0.9685 - loss: 0.0808 - val_accuracy: 0.9713 - val_loss: 0.1199 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 47/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 144ms/step - accuracy: 0.9786 - loss: 0.0589 - val_accuracy: 0.9647 - val_loss: 0.1116 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 48/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m7s\\u001B[0m 188ms/step - accuracy: 0.9757 - loss: 0.0626 - val_accuracy: 0.9713 - val_loss: 0.0897 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 49/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 146ms/step - accuracy: 0.9819 - loss: 0.0508 - val_accuracy: 0.9702 - val_loss: 0.0935 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 50/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m5s\\u001B[0m 144ms/step - accuracy: 0.9801 - loss: 0.0527 - val_accuracy: 0.9669 - val_loss: 0.1151 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 51/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m5s\\u001B[0m 144ms/step - accuracy: 0.9894 - loss: 0.0367 - val_accuracy: 0.9691 - val_loss: 0.0998 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 52/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m5s\\u001B[0m 143ms/step - accuracy: 0.9874 - loss: 0.0412 - val_accuracy: 0.9449 - val_loss: 0.1590 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 53/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m5s\\u001B[0m 144ms/step - accuracy: 0.9815 - loss: 0.0540 - val_accuracy: 0.9746 - val_loss: 0.0850 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 54/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 145ms/step - accuracy: 0.9892 - loss: 0.0379 - val_accuracy: 0.9768 - val_loss: 0.0829 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 55/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m5s\\u001B[0m 144ms/step - accuracy: 0.9874 - loss: 0.0452 - val_accuracy: 0.9691 - val_loss: 0.1035 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 56/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 143ms/step - accuracy: 0.9890 - loss: 0.0363 - val_accuracy: 0.9713 - val_loss: 0.1135 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 57/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 145ms/step - accuracy: 0.9927 - loss: 0.0327 - val_accuracy: 0.9791 - val_loss: 0.0778 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 58/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m5s\\u001B[0m 143ms/step - accuracy: 0.9916 - loss: 0.0314 - val_accuracy: 0.9813 - val_loss: 0.0783 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 59/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m5s\\u001B[0m 142ms/step - accuracy: 0.9899 - loss: 0.0360 - val_accuracy: 0.9713 - val_loss: 0.1001 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 60/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 143ms/step - accuracy: 0.9870 - loss: 0.0368 - val_accuracy: 0.9691 - val_loss: 0.1183 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 61/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m7s\\u001B[0m 179ms/step - accuracy: 0.9929 - loss: 0.0257 - val_accuracy: 0.9835 - val_loss: 0.0635 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 62/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m5s\\u001B[0m 143ms/step - accuracy: 0.9940 - loss: 0.0234 - val_accuracy: 0.9802 - val_loss: 0.0794 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 63/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m5s\\u001B[0m 143ms/step - accuracy: 0.9929 - loss: 0.0473 - val_accuracy: 0.9636 - val_loss: 0.1434 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 64/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 143ms/step - accuracy: 0.9916 - loss: 0.0285 - val_accuracy: 0.9813 - val_loss: 0.0620 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 65/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m5s\\u001B[0m 142ms/step - accuracy: 0.9949 - loss: 0.0224 - val_accuracy: 0.9735 - val_loss: 0.0970 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 66/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m5s\\u001B[0m 144ms/step - accuracy: 0.9936 - loss: 0.0212 - val_accuracy: 0.9735 - val_loss: 0.0980 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 67/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m5s\\u001B[0m 143ms/step - accuracy: 0.9925 - loss: 0.0287 - val_accuracy: 0.9724 - val_loss: 0.0892 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 68/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m5s\\u001B[0m 143ms/step - accuracy: 0.9938 - loss: 0.0203 - val_accuracy: 0.9802 - val_loss: 0.0661 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 69/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 165ms/step - accuracy: 0.9960 - loss: 0.0157 - val_accuracy: 0.9835 - val_loss: 0.0599 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 70/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 142ms/step - accuracy: 0.9916 - loss: 0.0271 - val_accuracy: 0.9768 - val_loss: 0.0880 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 71/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m5s\\u001B[0m 143ms/step - accuracy: 0.9956 - loss: 0.0225 - val_accuracy: 0.9868 - val_loss: 0.0597 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 72/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 145ms/step - accuracy: 0.9947 - loss: 0.0191 - val_accuracy: 0.9835 - val_loss: 0.0566 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 73/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m5s\\u001B[0m 143ms/step - accuracy: 0.9980 - loss: 0.0113 - val_accuracy: 0.9779 - val_loss: 0.0997 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 74/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 152ms/step - accuracy: 0.9960 - loss: 0.0149 - val_accuracy: 0.9846 - val_loss: 0.0744 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 75/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 155ms/step - accuracy: 0.9956 - loss: 0.0190 - val_accuracy: 0.9824 - val_loss: 0.0739 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 76/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 151ms/step - accuracy: 0.9982 - loss: 0.0097 - val_accuracy: 0.9846 - val_loss: 0.0685 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 77/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m0s\\u001B[0m 137ms/step - accuracy: 0.9980 - loss: 0.0178\\n\",\n",
    "      \"Epoch 77: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 155ms/step - accuracy: 0.9980 - loss: 0.0175 - val_accuracy: 0.9791 - val_loss: 0.0691 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 78/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 150ms/step - accuracy: 0.9974 - loss: 0.0123 - val_accuracy: 0.9868 - val_loss: 0.0609 - learning_rate: 5.0000e-05\\n\",\n",
    "      \"Epoch 79/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 156ms/step - accuracy: 0.9985 - loss: 0.0087 - val_accuracy: 0.9879 - val_loss: 0.0552 - learning_rate: 5.0000e-05\\n\",\n",
    "      \"Epoch 80/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m10s\\u001B[0m 146ms/step - accuracy: 0.9989 - loss: 0.0062 - val_accuracy: 0.9813 - val_loss: 0.0865 - learning_rate: 5.0000e-05\\n\",\n",
    "      \"Epoch 81/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 152ms/step - accuracy: 0.9996 - loss: 0.0043 - val_accuracy: 0.9879 - val_loss: 0.0615 - learning_rate: 5.0000e-05\\n\",\n",
    "      \"Epoch 82/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 151ms/step - accuracy: 0.9998 - loss: 0.0053 - val_accuracy: 0.9890 - val_loss: 0.0558 - learning_rate: 5.0000e-05\\n\",\n",
    "      \"Epoch 83/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 146ms/step - accuracy: 1.0000 - loss: 0.0045 - val_accuracy: 0.9779 - val_loss: 0.0990 - learning_rate: 5.0000e-05\\n\",\n",
    "      \"Epoch 84/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m0s\\u001B[0m 133ms/step - accuracy: 0.9988 - loss: 0.0048\\n\",\n",
    "      \"Epoch 84: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m5s\\u001B[0m 143ms/step - accuracy: 0.9993 - loss: 0.0049 - val_accuracy: 0.9868 - val_loss: 0.0715 - learning_rate: 5.0000e-05\\n\",\n",
    "      \"Epoch 85/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m5s\\u001B[0m 143ms/step - accuracy: 0.9996 - loss: 0.0035 - val_accuracy: 0.9846 - val_loss: 0.0769 - learning_rate: 2.5000e-05\\n\",\n",
    "      \"Epoch 86/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m5s\\u001B[0m 143ms/step - accuracy: 0.9993 - loss: 0.0047 - val_accuracy: 0.9901 - val_loss: 0.0651 - learning_rate: 2.5000e-05\\n\",\n",
    "      \"Epoch 87/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m5s\\u001B[0m 143ms/step - accuracy: 0.9991 - loss: 0.0034 - val_accuracy: 0.9890 - val_loss: 0.0595 - learning_rate: 2.5000e-05\\n\",\n",
    "      \"Epoch 88/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 145ms/step - accuracy: 0.9991 - loss: 0.0042 - val_accuracy: 0.9879 - val_loss: 0.0711 - learning_rate: 2.5000e-05\\n\",\n",
    "      \"Epoch 89/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m0s\\u001B[0m 134ms/step - accuracy: 1.0000 - loss: 0.0035\\n\",\n",
    "      \"Epoch 89: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 144ms/step - accuracy: 1.0000 - loss: 0.0028 - val_accuracy: 0.9901 - val_loss: 0.0649 - learning_rate: 2.5000e-05\\n\",\n",
    "      \"Epoch 90/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 144ms/step - accuracy: 0.9998 - loss: 0.0021 - val_accuracy: 0.9857 - val_loss: 0.0741 - learning_rate: 1.2500e-05\\n\",\n",
    "      \"Epoch 91/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m5s\\u001B[0m 144ms/step - accuracy: 0.9998 - loss: 0.0026 - val_accuracy: 0.9868 - val_loss: 0.0749 - learning_rate: 1.2500e-05\\n\",\n",
    "      \"Epoch 92/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m5s\\u001B[0m 143ms/step - accuracy: 1.0000 - loss: 0.0021 - val_accuracy: 0.9890 - val_loss: 0.0622 - learning_rate: 1.2500e-05\\n\",\n",
    "      \"Epoch 93/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m5s\\u001B[0m 143ms/step - accuracy: 1.0000 - loss: 0.0030 - val_accuracy: 0.9868 - val_loss: 0.0689 - learning_rate: 1.2500e-05\\n\",\n",
    "      \"Epoch 94/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m0s\\u001B[0m 134ms/step - accuracy: 1.0000 - loss: 0.0021\\n\",\n",
    "      \"Epoch 94: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m5s\\u001B[0m 144ms/step - accuracy: 1.0000 - loss: 0.0018 - val_accuracy: 0.9890 - val_loss: 0.0672 - learning_rate: 1.2500e-05\\n\",\n",
    "      \"Epoch 94: early stopping\\n\",\n",
    "      \"Restoring model weights from the end of the best epoch: 79.\\n\",\n",
    "      \"   > Acurácia Validação: 98.79% (Loss: 0.0552)\\n\",\n",
    "      \"--- Rodando Fold 5/6 ---\\n\",\n",
    "      \"Pesos das classes: {0: np.float64(4.46259842519685), 1: np.float64(62.97222222222223), 2: np.float64(0.5), 3: np.float64(1.7856017643352238)}\\n\",\n",
    "      \"Epoch 1/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m9s\\u001B[0m 200ms/step - accuracy: 0.1795 - loss: 2.8600 - val_accuracy: 0.3499 - val_loss: 1.4264 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 2/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 144ms/step - accuracy: 0.2378 - loss: 2.9242 - val_accuracy: 0.3499 - val_loss: 1.5865 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 3/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m5s\\u001B[0m 143ms/step - accuracy: 0.2693 - loss: 2.8207 - val_accuracy: 0.2594 - val_loss: 1.5904 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 4/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m5s\\u001B[0m 143ms/step - accuracy: 0.2395 - loss: 2.7402 - val_accuracy: 0.3554 - val_loss: 1.5170 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 5/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 145ms/step - accuracy: 0.2861 - loss: 2.6495 - val_accuracy: 0.3532 - val_loss: 1.3695 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 6/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m5s\\u001B[0m 144ms/step - accuracy: 0.3081 - loss: 2.4922 - val_accuracy: 0.2351 - val_loss: 1.7725 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 7/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 146ms/step - accuracy: 0.3520 - loss: 2.3009 - val_accuracy: 0.3631 - val_loss: 1.2626 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 8/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m5s\\u001B[0m 144ms/step - accuracy: 0.4063 - loss: 2.1213 - val_accuracy: 0.4779 - val_loss: 1.1837 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 9/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 152ms/step - accuracy: 0.4416 - loss: 1.8884 - val_accuracy: 0.5000 - val_loss: 1.1561 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 10/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m5s\\u001B[0m 143ms/step - accuracy: 0.4627 - loss: 1.6791 - val_accuracy: 0.4746 - val_loss: 1.1914 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 11/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 145ms/step - accuracy: 0.4896 - loss: 1.4960 - val_accuracy: 0.5706 - val_loss: 1.0273 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 12/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 144ms/step - accuracy: 0.5187 - loss: 1.3345 - val_accuracy: 0.5375 - val_loss: 1.0712 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 13/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 144ms/step - accuracy: 0.5357 - loss: 1.2764 - val_accuracy: 0.4779 - val_loss: 1.1361 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 14/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 151ms/step - accuracy: 0.5646 - loss: 1.1387 - val_accuracy: 0.6457 - val_loss: 0.8049 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 15/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m5s\\u001B[0m 143ms/step - accuracy: 0.5849 - loss: 1.0845 - val_accuracy: 0.5784 - val_loss: 0.9608 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 16/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 144ms/step - accuracy: 0.6037 - loss: 0.9766 - val_accuracy: 0.6302 - val_loss: 0.8429 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 17/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 145ms/step - accuracy: 0.6334 - loss: 0.8760 - val_accuracy: 0.7263 - val_loss: 0.6716 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 18/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m5s\\u001B[0m 143ms/step - accuracy: 0.6654 - loss: 0.8137 - val_accuracy: 0.7152 - val_loss: 0.6944 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 19/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 145ms/step - accuracy: 0.6718 - loss: 0.7648 - val_accuracy: 0.6391 - val_loss: 0.7876 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 20/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 151ms/step - accuracy: 0.6974 - loss: 0.6904 - val_accuracy: 0.7351 - val_loss: 0.6058 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 21/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 144ms/step - accuracy: 0.7159 - loss: 0.6270 - val_accuracy: 0.8113 - val_loss: 0.5118 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 22/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 144ms/step - accuracy: 0.7378 - loss: 0.5784 - val_accuracy: 0.7583 - val_loss: 0.5738 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 23/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m5s\\u001B[0m 144ms/step - accuracy: 0.7501 - loss: 0.5230 - val_accuracy: 0.7296 - val_loss: 0.6216 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 24/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 154ms/step - accuracy: 0.7675 - loss: 0.4844 - val_accuracy: 0.8168 - val_loss: 0.4670 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 25/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m10s\\u001B[0m 145ms/step - accuracy: 0.7770 - loss: 0.4494 - val_accuracy: 0.8079 - val_loss: 0.4670 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 26/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 161ms/step - accuracy: 0.8019 - loss: 0.4186 - val_accuracy: 0.8455 - val_loss: 0.3693 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 27/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 145ms/step - accuracy: 0.8037 - loss: 0.3929 - val_accuracy: 0.6932 - val_loss: 0.6023 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 28/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m5s\\u001B[0m 144ms/step - accuracy: 0.8229 - loss: 0.3637 - val_accuracy: 0.8389 - val_loss: 0.3844 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 29/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 145ms/step - accuracy: 0.8405 - loss: 0.3124 - val_accuracy: 0.8907 - val_loss: 0.3089 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 30/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m5s\\u001B[0m 143ms/step - accuracy: 0.8692 - loss: 0.2728 - val_accuracy: 0.8775 - val_loss: 0.3321 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 31/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m5s\\u001B[0m 143ms/step - accuracy: 0.8730 - loss: 0.2628 - val_accuracy: 0.8499 - val_loss: 0.3541 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 32/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 145ms/step - accuracy: 0.8833 - loss: 0.2349 - val_accuracy: 0.8499 - val_loss: 0.3432 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 33/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 146ms/step - accuracy: 0.8921 - loss: 0.2108 - val_accuracy: 0.9029 - val_loss: 0.2522 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 34/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 144ms/step - accuracy: 0.9025 - loss: 0.1961 - val_accuracy: 0.8830 - val_loss: 0.2942 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 35/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 145ms/step - accuracy: 0.9180 - loss: 0.1771 - val_accuracy: 0.9305 - val_loss: 0.1930 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 36/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m5s\\u001B[0m 144ms/step - accuracy: 0.9371 - loss: 0.1474 - val_accuracy: 0.8962 - val_loss: 0.2587 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 37/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m7s\\u001B[0m 180ms/step - accuracy: 0.9393 - loss: 0.1328 - val_accuracy: 0.9415 - val_loss: 0.1716 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 38/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 144ms/step - accuracy: 0.9409 - loss: 0.1315 - val_accuracy: 0.9349 - val_loss: 0.1940 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 39/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 146ms/step - accuracy: 0.9433 - loss: 0.1375 - val_accuracy: 0.9570 - val_loss: 0.1398 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 40/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 144ms/step - accuracy: 0.9579 - loss: 0.1095 - val_accuracy: 0.9040 - val_loss: 0.2331 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 41/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 145ms/step - accuracy: 0.9634 - loss: 0.1001 - val_accuracy: 0.9316 - val_loss: 0.1729 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 42/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m5s\\u001B[0m 143ms/step - accuracy: 0.9682 - loss: 0.0823 - val_accuracy: 0.9492 - val_loss: 0.1414 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 43/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m5s\\u001B[0m 143ms/step - accuracy: 0.9678 - loss: 0.0773 - val_accuracy: 0.9128 - val_loss: 0.1948 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 44/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 159ms/step - accuracy: 0.9658 - loss: 0.0865 - val_accuracy: 0.9592 - val_loss: 0.1316 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 45/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 146ms/step - accuracy: 0.9740 - loss: 0.0710 - val_accuracy: 0.9680 - val_loss: 0.1011 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 46/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m5s\\u001B[0m 143ms/step - accuracy: 0.9784 - loss: 0.0600 - val_accuracy: 0.9393 - val_loss: 0.1612 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 47/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 145ms/step - accuracy: 0.9749 - loss: 0.0668 - val_accuracy: 0.9525 - val_loss: 0.1326 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 48/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m5s\\u001B[0m 143ms/step - accuracy: 0.9762 - loss: 0.0668 - val_accuracy: 0.9592 - val_loss: 0.1124 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 49/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m7s\\u001B[0m 188ms/step - accuracy: 0.9795 - loss: 0.0510 - val_accuracy: 0.9757 - val_loss: 0.0737 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 50/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 148ms/step - accuracy: 0.9865 - loss: 0.0391 - val_accuracy: 0.9779 - val_loss: 0.0705 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 51/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 145ms/step - accuracy: 0.9896 - loss: 0.0310 - val_accuracy: 0.9823 - val_loss: 0.0608 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 52/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 144ms/step - accuracy: 0.9903 - loss: 0.0333 - val_accuracy: 0.9812 - val_loss: 0.0771 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 53/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m5s\\u001B[0m 143ms/step - accuracy: 0.9896 - loss: 0.0332 - val_accuracy: 0.9823 - val_loss: 0.0638 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 54/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 144ms/step - accuracy: 0.9865 - loss: 0.0386 - val_accuracy: 0.9757 - val_loss: 0.0744 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 55/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m5s\\u001B[0m 143ms/step - accuracy: 0.9896 - loss: 0.0313 - val_accuracy: 0.9702 - val_loss: 0.0816 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 56/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m0s\\u001B[0m 133ms/step - accuracy: 0.9912 - loss: 0.0252\\n\",\n",
    "      \"Epoch 56: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m5s\\u001B[0m 143ms/step - accuracy: 0.9925 - loss: 0.0245 - val_accuracy: 0.9702 - val_loss: 0.0745 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 57/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 144ms/step - accuracy: 0.9976 - loss: 0.0160 - val_accuracy: 0.9857 - val_loss: 0.0536 - learning_rate: 5.0000e-05\\n\",\n",
    "      \"Epoch 58/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m5s\\u001B[0m 143ms/step - accuracy: 0.9965 - loss: 0.0133 - val_accuracy: 0.9801 - val_loss: 0.0612 - learning_rate: 5.0000e-05\\n\",\n",
    "      \"Epoch 59/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 169ms/step - accuracy: 0.9974 - loss: 0.0121 - val_accuracy: 0.9845 - val_loss: 0.0493 - learning_rate: 5.0000e-05\\n\",\n",
    "      \"Epoch 60/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 144ms/step - accuracy: 0.9976 - loss: 0.0138 - val_accuracy: 0.9834 - val_loss: 0.0496 - learning_rate: 5.0000e-05\\n\",\n",
    "      \"Epoch 61/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m5s\\u001B[0m 144ms/step - accuracy: 0.9989 - loss: 0.0097 - val_accuracy: 0.9746 - val_loss: 0.0721 - learning_rate: 5.0000e-05\\n\",\n",
    "      \"Epoch 62/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m5s\\u001B[0m 144ms/step - accuracy: 0.9982 - loss: 0.0100 - val_accuracy: 0.9823 - val_loss: 0.0544 - learning_rate: 5.0000e-05\\n\",\n",
    "      \"Epoch 63/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m5s\\u001B[0m 144ms/step - accuracy: 0.9982 - loss: 0.0109 - val_accuracy: 0.9879 - val_loss: 0.0449 - learning_rate: 5.0000e-05\\n\",\n",
    "      \"Epoch 64/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m5s\\u001B[0m 143ms/step - accuracy: 0.9982 - loss: 0.0099 - val_accuracy: 0.9857 - val_loss: 0.0499 - learning_rate: 5.0000e-05\\n\",\n",
    "      \"Epoch 65/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m5s\\u001B[0m 143ms/step - accuracy: 0.9985 - loss: 0.0095 - val_accuracy: 0.9801 - val_loss: 0.0630 - learning_rate: 5.0000e-05\\n\",\n",
    "      \"Epoch 66/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m5s\\u001B[0m 143ms/step - accuracy: 0.9971 - loss: 0.0119 - val_accuracy: 0.9868 - val_loss: 0.0503 - learning_rate: 5.0000e-05\\n\",\n",
    "      \"Epoch 67/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 144ms/step - accuracy: 0.9987 - loss: 0.0125 - val_accuracy: 0.9845 - val_loss: 0.0473 - learning_rate: 5.0000e-05\\n\",\n",
    "      \"Epoch 68/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m0s\\u001B[0m 134ms/step - accuracy: 0.9980 - loss: 0.0099\\n\",\n",
    "      \"Epoch 68: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m5s\\u001B[0m 144ms/step - accuracy: 0.9985 - loss: 0.0093 - val_accuracy: 0.9834 - val_loss: 0.0478 - learning_rate: 5.0000e-05\\n\",\n",
    "      \"Epoch 69/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m5s\\u001B[0m 144ms/step - accuracy: 0.9987 - loss: 0.0073 - val_accuracy: 0.9868 - val_loss: 0.0465 - learning_rate: 2.5000e-05\\n\",\n",
    "      \"Epoch 70/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 144ms/step - accuracy: 0.9993 - loss: 0.0063 - val_accuracy: 0.9845 - val_loss: 0.0473 - learning_rate: 2.5000e-05\\n\",\n",
    "      \"Epoch 71/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 144ms/step - accuracy: 0.9993 - loss: 0.0049 - val_accuracy: 0.9812 - val_loss: 0.0582 - learning_rate: 2.5000e-05\\n\",\n",
    "      \"Epoch 72/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 165ms/step - accuracy: 0.9987 - loss: 0.0050 - val_accuracy: 0.9879 - val_loss: 0.0433 - learning_rate: 2.5000e-05\\n\",\n",
    "      \"Epoch 73/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 145ms/step - accuracy: 0.9993 - loss: 0.0053 - val_accuracy: 0.9868 - val_loss: 0.0506 - learning_rate: 2.5000e-05\\n\",\n",
    "      \"Epoch 74/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m5s\\u001B[0m 143ms/step - accuracy: 0.9991 - loss: 0.0062 - val_accuracy: 0.9823 - val_loss: 0.0518 - learning_rate: 2.5000e-05\\n\",\n",
    "      \"Epoch 75/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m5s\\u001B[0m 143ms/step - accuracy: 0.9989 - loss: 0.0058 - val_accuracy: 0.9790 - val_loss: 0.0593 - learning_rate: 2.5000e-05\\n\",\n",
    "      \"Epoch 76/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m5s\\u001B[0m 143ms/step - accuracy: 0.9996 - loss: 0.0059 - val_accuracy: 0.9834 - val_loss: 0.0497 - learning_rate: 2.5000e-05\\n\",\n",
    "      \"Epoch 77/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m0s\\u001B[0m 133ms/step - accuracy: 0.9990 - loss: 0.0070\\n\",\n",
    "      \"Epoch 77: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m5s\\u001B[0m 143ms/step - accuracy: 0.9991 - loss: 0.0058 - val_accuracy: 0.9868 - val_loss: 0.0490 - learning_rate: 2.5000e-05\\n\",\n",
    "      \"Epoch 78/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m5s\\u001B[0m 144ms/step - accuracy: 0.9993 - loss: 0.0048 - val_accuracy: 0.9857 - val_loss: 0.0463 - learning_rate: 1.2500e-05\\n\",\n",
    "      \"Epoch 79/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 145ms/step - accuracy: 0.9987 - loss: 0.0055 - val_accuracy: 0.9890 - val_loss: 0.0472 - learning_rate: 1.2500e-05\\n\",\n",
    "      \"Epoch 80/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m5s\\u001B[0m 144ms/step - accuracy: 0.9991 - loss: 0.0057 - val_accuracy: 0.9845 - val_loss: 0.0463 - learning_rate: 1.2500e-05\\n\",\n",
    "      \"Epoch 81/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m5s\\u001B[0m 144ms/step - accuracy: 0.9993 - loss: 0.0048 - val_accuracy: 0.9890 - val_loss: 0.0457 - learning_rate: 1.2500e-05\\n\",\n",
    "      \"Epoch 82/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m0s\\u001B[0m 133ms/step - accuracy: 0.9994 - loss: 0.0048\\n\",\n",
    "      \"Epoch 82: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m5s\\u001B[0m 143ms/step - accuracy: 0.9989 - loss: 0.0051 - val_accuracy: 0.9834 - val_loss: 0.0508 - learning_rate: 1.2500e-05\\n\",\n",
    "      \"Epoch 83/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m5s\\u001B[0m 143ms/step - accuracy: 0.9998 - loss: 0.0040 - val_accuracy: 0.9912 - val_loss: 0.0443 - learning_rate: 6.2500e-06\\n\",\n",
    "      \"Epoch 84/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m11s\\u001B[0m 144ms/step - accuracy: 0.9998 - loss: 0.0046 - val_accuracy: 0.9834 - val_loss: 0.0501 - learning_rate: 6.2500e-06\\n\",\n",
    "      \"Epoch 85/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m5s\\u001B[0m 143ms/step - accuracy: 0.9998 - loss: 0.0034 - val_accuracy: 0.9868 - val_loss: 0.0463 - learning_rate: 6.2500e-06\\n\",\n",
    "      \"Epoch 86/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m5s\\u001B[0m 143ms/step - accuracy: 0.9996 - loss: 0.0042 - val_accuracy: 0.9857 - val_loss: 0.0473 - learning_rate: 6.2500e-06\\n\",\n",
    "      \"Epoch 87/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m0s\\u001B[0m 132ms/step - accuracy: 0.9993 - loss: 0.0033\\n\",\n",
    "      \"Epoch 87: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m5s\\u001B[0m 142ms/step - accuracy: 0.9998 - loss: 0.0031 - val_accuracy: 0.9868 - val_loss: 0.0461 - learning_rate: 6.2500e-06\\n\",\n",
    "      \"Epoch 87: early stopping\\n\",\n",
    "      \"Restoring model weights from the end of the best epoch: 72.\\n\",\n",
    "      \"   > Acurácia Validação: 98.79% (Loss: 0.0433)\\n\",\n",
    "      \"--- Rodando Fold 6/6 ---\\n\",\n",
    "      \"Pesos das classes: {0: np.float64(4.46259842519685), 1: np.float64(62.97222222222223), 2: np.float64(0.5), 3: np.float64(1.7856017643352238)}\\n\",\n",
    "      \"Epoch 1/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m7s\\u001B[0m 151ms/step - accuracy: 0.2594 - loss: 2.9663 - val_accuracy: 0.1402 - val_loss: 1.6966 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 2/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 145ms/step - accuracy: 0.2038 - loss: 2.8259 - val_accuracy: 0.3653 - val_loss: 1.6543 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 3/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 145ms/step - accuracy: 0.2466 - loss: 2.8024 - val_accuracy: 0.3554 - val_loss: 1.6029 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 4/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 144ms/step - accuracy: 0.2869 - loss: 2.7716 - val_accuracy: 0.2163 - val_loss: 1.5435 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 5/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m5s\\u001B[0m 143ms/step - accuracy: 0.2843 - loss: 2.6879 - val_accuracy: 0.3344 - val_loss: 1.5787 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 6/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m5s\\u001B[0m 144ms/step - accuracy: 0.3079 - loss: 2.5083 - val_accuracy: 0.3113 - val_loss: 1.3743 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 7/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 144ms/step - accuracy: 0.3207 - loss: 2.4113 - val_accuracy: 0.2704 - val_loss: 1.4605 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 8/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 146ms/step - accuracy: 0.3575 - loss: 2.1945 - val_accuracy: 0.3135 - val_loss: 1.3547 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 9/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 145ms/step - accuracy: 0.4016 - loss: 1.9553 - val_accuracy: 0.4294 - val_loss: 1.1760 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 10/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 144ms/step - accuracy: 0.4376 - loss: 1.8301 - val_accuracy: 0.4547 - val_loss: 1.1523 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 11/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m5s\\u001B[0m 143ms/step - accuracy: 0.4718 - loss: 1.5665 - val_accuracy: 0.4338 - val_loss: 1.2612 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 12/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m5s\\u001B[0m 144ms/step - accuracy: 0.4857 - loss: 1.4434 - val_accuracy: 0.5353 - val_loss: 1.0487 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 13/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 144ms/step - accuracy: 0.5157 - loss: 1.3128 - val_accuracy: 0.5740 - val_loss: 0.9453 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 14/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 144ms/step - accuracy: 0.5375 - loss: 1.1764 - val_accuracy: 0.5453 - val_loss: 0.9581 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 15/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 144ms/step - accuracy: 0.5496 - loss: 1.1613 - val_accuracy: 0.6049 - val_loss: 0.9080 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 16/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m5s\\u001B[0m 143ms/step - accuracy: 0.5876 - loss: 1.0135 - val_accuracy: 0.5629 - val_loss: 0.9324 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 17/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m5s\\u001B[0m 144ms/step - accuracy: 0.6092 - loss: 0.9444 - val_accuracy: 0.6181 - val_loss: 0.8603 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 18/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m5s\\u001B[0m 144ms/step - accuracy: 0.6195 - loss: 0.8644 - val_accuracy: 0.7108 - val_loss: 0.6815 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 19/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m10s\\u001B[0m 144ms/step - accuracy: 0.6321 - loss: 0.7951 - val_accuracy: 0.6589 - val_loss: 0.7604 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 20/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 143ms/step - accuracy: 0.6471 - loss: 0.7435 - val_accuracy: 0.6799 - val_loss: 0.7413 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 21/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m5s\\u001B[0m 144ms/step - accuracy: 0.6687 - loss: 0.6850 - val_accuracy: 0.7318 - val_loss: 0.6295 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 22/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 159ms/step - accuracy: 0.7042 - loss: 0.5987 - val_accuracy: 0.7406 - val_loss: 0.5913 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 23/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m5s\\u001B[0m 144ms/step - accuracy: 0.6967 - loss: 0.5972 - val_accuracy: 0.7859 - val_loss: 0.5408 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 24/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m5s\\u001B[0m 144ms/step - accuracy: 0.7236 - loss: 0.5348 - val_accuracy: 0.7417 - val_loss: 0.6134 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 25/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 146ms/step - accuracy: 0.7367 - loss: 0.4923 - val_accuracy: 0.7914 - val_loss: 0.5044 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 26/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 145ms/step - accuracy: 0.7649 - loss: 0.4636 - val_accuracy: 0.8157 - val_loss: 0.4455 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 27/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 144ms/step - accuracy: 0.7647 - loss: 0.4420 - val_accuracy: 0.8366 - val_loss: 0.4084 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 28/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 143ms/step - accuracy: 0.7660 - loss: 0.4175 - val_accuracy: 0.7539 - val_loss: 0.5381 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 29/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m5s\\u001B[0m 143ms/step - accuracy: 0.7922 - loss: 0.3939 - val_accuracy: 0.7141 - val_loss: 0.6290 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 30/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m5s\\u001B[0m 144ms/step - accuracy: 0.8088 - loss: 0.3518 - val_accuracy: 0.8057 - val_loss: 0.4334 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 31/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 144ms/step - accuracy: 0.8183 - loss: 0.3246 - val_accuracy: 0.8797 - val_loss: 0.3303 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 32/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m5s\\u001B[0m 144ms/step - accuracy: 0.8326 - loss: 0.3206 - val_accuracy: 0.8245 - val_loss: 0.4288 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 33/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m5s\\u001B[0m 143ms/step - accuracy: 0.8419 - loss: 0.3062 - val_accuracy: 0.8102 - val_loss: 0.4163 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 34/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m5s\\u001B[0m 144ms/step - accuracy: 0.8544 - loss: 0.2599 - val_accuracy: 0.8940 - val_loss: 0.2824 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 35/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m5s\\u001B[0m 143ms/step - accuracy: 0.8752 - loss: 0.2476 - val_accuracy: 0.8079 - val_loss: 0.4439 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 36/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m5s\\u001B[0m 144ms/step - accuracy: 0.8858 - loss: 0.2237 - val_accuracy: 0.8201 - val_loss: 0.4089 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 37/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m5s\\u001B[0m 143ms/step - accuracy: 0.8946 - loss: 0.2015 - val_accuracy: 0.7980 - val_loss: 0.4732 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 38/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 144ms/step - accuracy: 0.8895 - loss: 0.2095 - val_accuracy: 0.9139 - val_loss: 0.2388 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 39/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 145ms/step - accuracy: 0.9199 - loss: 0.1657 - val_accuracy: 0.9249 - val_loss: 0.2328 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 40/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m5s\\u001B[0m 143ms/step - accuracy: 0.9261 - loss: 0.1533 - val_accuracy: 0.8731 - val_loss: 0.3130 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 41/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m5s\\u001B[0m 144ms/step - accuracy: 0.9332 - loss: 0.1543 - val_accuracy: 0.9316 - val_loss: 0.2003 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 42/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 145ms/step - accuracy: 0.9349 - loss: 0.1362 - val_accuracy: 0.9382 - val_loss: 0.1902 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 43/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m5s\\u001B[0m 143ms/step - accuracy: 0.9398 - loss: 0.1331 - val_accuracy: 0.9371 - val_loss: 0.1935 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 44/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m5s\\u001B[0m 143ms/step - accuracy: 0.9431 - loss: 0.1250 - val_accuracy: 0.9073 - val_loss: 0.2357 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 45/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m5s\\u001B[0m 144ms/step - accuracy: 0.9438 - loss: 0.1231 - val_accuracy: 0.9536 - val_loss: 0.1518 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 46/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m5s\\u001B[0m 143ms/step - accuracy: 0.9502 - loss: 0.1126 - val_accuracy: 0.9503 - val_loss: 0.1540 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 47/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m5s\\u001B[0m 143ms/step - accuracy: 0.9521 - loss: 0.0967 - val_accuracy: 0.9183 - val_loss: 0.2213 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 48/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 144ms/step - accuracy: 0.9616 - loss: 0.0906 - val_accuracy: 0.9227 - val_loss: 0.2120 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 49/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 144ms/step - accuracy: 0.9612 - loss: 0.0899 - val_accuracy: 0.9547 - val_loss: 0.1500 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 50/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m5s\\u001B[0m 144ms/step - accuracy: 0.9654 - loss: 0.0867 - val_accuracy: 0.9570 - val_loss: 0.1468 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 51/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m5s\\u001B[0m 143ms/step - accuracy: 0.9667 - loss: 0.0843 - val_accuracy: 0.9349 - val_loss: 0.1897 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 52/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m5s\\u001B[0m 143ms/step - accuracy: 0.9742 - loss: 0.0695 - val_accuracy: 0.9316 - val_loss: 0.2168 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 53/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 144ms/step - accuracy: 0.9718 - loss: 0.0663 - val_accuracy: 0.9625 - val_loss: 0.1381 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 54/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m5s\\u001B[0m 143ms/step - accuracy: 0.9740 - loss: 0.0676 - val_accuracy: 0.9503 - val_loss: 0.1666 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 55/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m5s\\u001B[0m 144ms/step - accuracy: 0.9784 - loss: 0.0593 - val_accuracy: 0.9614 - val_loss: 0.1265 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 56/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m5s\\u001B[0m 142ms/step - accuracy: 0.9810 - loss: 0.0568 - val_accuracy: 0.9360 - val_loss: 0.1995 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 57/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m5s\\u001B[0m 143ms/step - accuracy: 0.9700 - loss: 0.0698 - val_accuracy: 0.9636 - val_loss: 0.1278 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 58/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 144ms/step - accuracy: 0.9735 - loss: 0.0915 - val_accuracy: 0.9647 - val_loss: 0.1118 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 59/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m5s\\u001B[0m 143ms/step - accuracy: 0.9872 - loss: 0.0413 - val_accuracy: 0.9603 - val_loss: 0.1349 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 60/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 145ms/step - accuracy: 0.9826 - loss: 0.0468 - val_accuracy: 0.9746 - val_loss: 0.1104 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 61/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m5s\\u001B[0m 143ms/step - accuracy: 0.9861 - loss: 0.0417 - val_accuracy: 0.9702 - val_loss: 0.1216 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 62/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m5s\\u001B[0m 143ms/step - accuracy: 0.9821 - loss: 0.0478 - val_accuracy: 0.9614 - val_loss: 0.1471 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 63/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m5s\\u001B[0m 144ms/step - accuracy: 0.9854 - loss: 0.0413 - val_accuracy: 0.9746 - val_loss: 0.0987 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 64/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m5s\\u001B[0m 143ms/step - accuracy: 0.9861 - loss: 0.0408 - val_accuracy: 0.9525 - val_loss: 0.1600 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 65/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m5s\\u001B[0m 144ms/step - accuracy: 0.9839 - loss: 0.0440 - val_accuracy: 0.9680 - val_loss: 0.1125 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 66/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m5s\\u001B[0m 144ms/step - accuracy: 0.9896 - loss: 0.0320 - val_accuracy: 0.9194 - val_loss: 0.2609 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 67/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m5s\\u001B[0m 144ms/step - accuracy: 0.9863 - loss: 0.0383 - val_accuracy: 0.9735 - val_loss: 0.1097 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 68/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m0s\\u001B[0m 133ms/step - accuracy: 0.9878 - loss: 0.0373\\n\",\n",
    "      \"Epoch 68: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m5s\\u001B[0m 143ms/step - accuracy: 0.9874 - loss: 0.0350 - val_accuracy: 0.9669 - val_loss: 0.1390 - learning_rate: 1.0000e-04\\n\",\n",
    "      \"Epoch 69/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m5s\\u001B[0m 144ms/step - accuracy: 0.9951 - loss: 0.0220 - val_accuracy: 0.9757 - val_loss: 0.1109 - learning_rate: 5.0000e-05\\n\",\n",
    "      \"Epoch 70/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m5s\\u001B[0m 143ms/step - accuracy: 0.9954 - loss: 0.0205 - val_accuracy: 0.9768 - val_loss: 0.1036 - learning_rate: 5.0000e-05\\n\",\n",
    "      \"Epoch 71/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m5s\\u001B[0m 143ms/step - accuracy: 0.9940 - loss: 0.0201 - val_accuracy: 0.9768 - val_loss: 0.1008 - learning_rate: 5.0000e-05\\n\",\n",
    "      \"Epoch 72/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m5s\\u001B[0m 144ms/step - accuracy: 0.9969 - loss: 0.0152 - val_accuracy: 0.9768 - val_loss: 0.1021 - learning_rate: 5.0000e-05\\n\",\n",
    "      \"Epoch 73/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m10s\\u001B[0m 144ms/step - accuracy: 0.9969 - loss: 0.0152 - val_accuracy: 0.9790 - val_loss: 0.0886 - learning_rate: 5.0000e-05\\n\",\n",
    "      \"Epoch 74/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 151ms/step - accuracy: 0.9978 - loss: 0.0123 - val_accuracy: 0.9801 - val_loss: 0.1040 - learning_rate: 5.0000e-05\\n\",\n",
    "      \"Epoch 75/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 149ms/step - accuracy: 0.9956 - loss: 0.0167 - val_accuracy: 0.9801 - val_loss: 0.1034 - learning_rate: 5.0000e-05\\n\",\n",
    "      \"Epoch 76/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 150ms/step - accuracy: 0.9954 - loss: 0.0192 - val_accuracy: 0.9768 - val_loss: 0.1101 - learning_rate: 5.0000e-05\\n\",\n",
    "      \"Epoch 77/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 152ms/step - accuracy: 0.9965 - loss: 0.0139 - val_accuracy: 0.9691 - val_loss: 0.1208 - learning_rate: 5.0000e-05\\n\",\n",
    "      \"Epoch 78/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m0s\\u001B[0m 135ms/step - accuracy: 0.9936 - loss: 0.0141\\n\",\n",
    "      \"Epoch 78: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 146ms/step - accuracy: 0.9947 - loss: 0.0147 - val_accuracy: 0.9724 - val_loss: 0.1162 - learning_rate: 5.0000e-05\\n\",\n",
    "      \"Epoch 79/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 147ms/step - accuracy: 0.9967 - loss: 0.0136 - val_accuracy: 0.9768 - val_loss: 0.0986 - learning_rate: 2.5000e-05\\n\",\n",
    "      \"Epoch 80/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 146ms/step - accuracy: 0.9985 - loss: 0.0076 - val_accuracy: 0.9801 - val_loss: 0.1003 - learning_rate: 2.5000e-05\\n\",\n",
    "      \"Epoch 81/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 145ms/step - accuracy: 0.9976 - loss: 0.0113 - val_accuracy: 0.9768 - val_loss: 0.1044 - learning_rate: 2.5000e-05\\n\",\n",
    "      \"Epoch 82/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 147ms/step - accuracy: 0.9987 - loss: 0.0087 - val_accuracy: 0.9801 - val_loss: 0.1117 - learning_rate: 2.5000e-05\\n\",\n",
    "      \"Epoch 83/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m0s\\u001B[0m 136ms/step - accuracy: 0.9988 - loss: 0.0091\\n\",\n",
    "      \"Epoch 83: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 147ms/step - accuracy: 0.9980 - loss: 0.0102 - val_accuracy: 0.9779 - val_loss: 0.1086 - learning_rate: 2.5000e-05\\n\",\n",
    "      \"Epoch 84/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 147ms/step - accuracy: 0.9978 - loss: 0.0080 - val_accuracy: 0.9779 - val_loss: 0.1067 - learning_rate: 1.2500e-05\\n\",\n",
    "      \"Epoch 85/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 146ms/step - accuracy: 0.9991 - loss: 0.0072 - val_accuracy: 0.9768 - val_loss: 0.1147 - learning_rate: 1.2500e-05\\n\",\n",
    "      \"Epoch 86/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 146ms/step - accuracy: 0.9985 - loss: 0.0062 - val_accuracy: 0.9812 - val_loss: 0.1063 - learning_rate: 1.2500e-05\\n\",\n",
    "      \"Epoch 87/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 146ms/step - accuracy: 0.9993 - loss: 0.0055 - val_accuracy: 0.9812 - val_loss: 0.1067 - learning_rate: 1.2500e-05\\n\",\n",
    "      \"Epoch 88/150\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m0s\\u001B[0m 136ms/step - accuracy: 0.9989 - loss: 0.0068\\n\",\n",
    "      \"Epoch 88: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\\n\",\n",
    "      \"\\u001B[1m36/36\\u001B[0m \\u001B[32m━━━━━━━━━━━━━━━━━━━━\\u001B[0m\\u001B[37m\\u001B[0m \\u001B[1m6s\\u001B[0m 147ms/step - accuracy: 0.9985 - loss: 0.0081 - val_accuracy: 0.9790 - val_loss: 0.1116 - learning_rate: 1.2500e-05\\n\",\n",
    "      \"Epoch 88: early stopping\\n\",\n",
    "      \"Restoring model weights from the end of the best epoch: 73.\\n\",\n",
    "      \"   > Acurácia Validação: 97.90% (Loss: 0.0886)\\n\",\n",
    "      \"\\n\",\n",
    "      \"==============================\\n\",\n",
    "      \"Média Final de Acurácia: 98.42%\\n\",\n",
    "      \"O melhor modelo de todos os folds já está salvo como 'melhor_modelo_kfold.keras'\\n\"\n",
    "     ]\n",
    "    }\n",
    "   ],\n",
    "   \"execution_count\": 10\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"id\": \"244066648064edf9\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"Métricas mais avançadas com sklearn\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"id\": \"d07ced0d0e92e238\",\n",
    "   \"metadata\": {\n",
    "    \"ExecuteTime\": {\n",
    "     \"end_time\": \"2025-11-21T02:23:41.737472Z\",\n",
    "     \"start_time\": \"2025-11-21T02:23:32.717954Z\"\n",
    "    }\n",
    "   },\n",
    "   \"source\": [\n",
    "    \"ds_teste_final = criar_dataset_fold(X_teste, y_teste, training=False)\\n\",\n",
    "    \"\\n\",\n",
    "    \"y_verdadeiro = []\\n\",\n",
    "    \"y_previsto_ajustado = []\\n\",\n",
    "    \"INDICE_NON = 2\\n\",\n",
    "    \"LIMIAR = 0.85\\n\",\n",
    "    \"\\n\",\n",
    "    \"try:\\n\",\n",
    "    \"    melhor_modelo = load_model('melhor_modelo_kfold.keras', safe_mode=False)\\n\",\n",
    "    \"    print(\\\"Modelo carregado com sucesso do disco.\\\")\\n\",\n",
    "    \"except OSError:\\n\",\n",
    "    \"    print(\\\"Erro: Arquivo 'melhor_modelo_kfold.keras' não encontrado.\\\")\\n\",\n",
    "    \"    raise\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"Gerando previsões...\\\")\\n\",\n",
    "    \"for imagens, rotulos in ds_teste_final:\\n\",\n",
    "    \"    previsoes = melhor_modelo.predict(imagens, verbose=0)\\n\",\n",
    "    \"    y_verdadeiro.extend(rotulos.numpy())\\n\",\n",
    "    \"\\n\",\n",
    "    \"    for i in range(len(previsoes)):\\n\",\n",
    "    \"        probs = previsoes[i]\\n\",\n",
    "    \"        classe_max = np.argmax(probs)\\n\",\n",
    "    \"\\n\",\n",
    "    \"        if classe_max == INDICE_NON and probs[INDICE_NON] < LIMIAR:\\n\",\n",
    "    \"            probs[INDICE_NON] = -1\\n\",\n",
    "    \"            y_previsto_ajustado.append(np.argmax(probs))\\n\",\n",
    "    \"        else:\\n\",\n",
    "    \"            y_previsto_ajustado.append(classe_max)\\n\",\n",
    "    \"\\n\",\n",
    "    \"classes = ['Mild', 'Mod', 'Non', 'VMild']\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"\\\\nRelatório de Classificação Final:\\\\n\\\")\\n\",\n",
    "    \"print(classification_report(y_verdadeiro, y_previsto_ajustado, target_names=classes))\\n\",\n",
    "    \"\\n\",\n",
    "    \"cm = confusion_matrix(y_verdadeiro, y_previsto_ajustado)\\n\",\n",
    "    \"disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=classes)\\n\",\n",
    "    \"\\n\",\n",
    "    \"fig, ax = plt.subplots(figsize=(6, 6))\\n\",\n",
    "    \"disp.plot(xticks_rotation=45, cmap='Blues', ax=ax)\\n\",\n",
    "    \"plt.title(\\\"Matriz de Confusão (Melhor Modelo K-Fold)\\\")\\n\",\n",
    "    \"plt.show()\"\n",
    "   ],\n",
    "   \"outputs\": [\n",
    "    {\n",
    "     \"name\": \"stdout\",\n",
    "     \"output_type\": \"stream\",\n",
    "     \"text\": [\n",
    "      \"Modelo carregado com sucesso do disco.\\n\",\n",
    "      \"Gerando previsões...\\n\",\n",
    "      \"\\n\",\n",
    "      \"Relatório de Classificação Final:\\n\",\n",
    "      \"\\n\",\n",
    "      \"              precision    recall  f1-score   support\\n\",\n",
    "      \"\\n\",\n",
    "      \"        Mild       0.96      0.99      0.97       134\\n\",\n",
    "      \"         Mod       1.00      1.00      1.00        10\\n\",\n",
    "      \"         Non       1.00      0.97      0.98       480\\n\",\n",
    "      \"       VMild       0.97      0.99      0.98       336\\n\",\n",
    "      \"\\n\",\n",
    "      \"    accuracy                           0.98       960\\n\",\n",
    "      \"   macro avg       0.98      0.99      0.98       960\\n\",\n",
    "      \"weighted avg       0.98      0.98      0.98       960\\n\",\n",
    "      \"\\n\"\n",
    "     ]\n",
    "    },\n",
    "    {\n",
    "     \"data\": {\n",
    "      \"text/plain\": [\n",
    "       \"<Figure size 600x600 with 2 Axes>\"\n",
    "      ],\n",
    "      \"image/png\": \"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\"\n",
    "     },\n",
    "     \"metadata\": {},\n",
    "     \"output_type\": \"display_data\",\n",
    "     \"jetTransient\": {\n",
    "      \"display_id\": null\n",
    "     }\n",
    "    }\n",
    "   ],\n",
    "   \"execution_count\": 11\n",
    "  }\n",
    " ],\n",
    " \"metadata\": {\n",
    "  \"kernelspec\": {\n",
    "   \"display_name\": \"Python 3\",\n",
    "   \"language\": \"python\",\n",
    "   \"name\": \"python3\"\n",
    "  },\n",
    "  \"language_info\": {\n",
    "   \"codemirror_mode\": {\n",
    "    \"name\": \"ipython\",\n",
    "    \"version\": 3\n",
    "   },\n",
    "   \"file_extension\": \".py\",\n",
    "   \"mimetype\": \"text/x-python\",\n",
    "   \"name\": \"python\",\n",
    "   \"nbconvert_exporter\": \"python\",\n",
    "   \"pygments_lexer\": \"ipython3\",\n",
    "   \"version\": \"3.13.7\"\n",
    "  }\n",
    " },\n",
    " \"nbformat\": 4,\n",
    " \"nbformat_minor\": 5\n",
    "}\n"
   ],
   "id": "d1e3e19cb22ea767"
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
