{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34db769b46dc074b",
   "metadata": {},
   "source": [
    "Autores: Alexandre Liermann, Gustavo Guerreiro e João Martinho."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be2e6c6ff29c0f12",
   "metadata": {},
   "source": [
    "# Implementação de Classificação de Imagens de Ressonância Magnética para Diagnóstico de Alzheimer Usando CNN em TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac8cbbfcc8dab30",
   "metadata": {},
   "source": [
    "Importações das bibliotecas necessárias"
   ]
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-11-23T01:05:54.492491Z",
     "start_time": "2025-11-23T01:05:50.591617Z"
    }
   },
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'\n",
    "os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
    "os.environ['TF_CUDNN_DETERMINISTIC'] = '1'\n",
    "os.environ['TF_CUDNN_BENCHMARK'] = 'false'\n",
    "\n",
    "import gc\n",
    "import glob\n",
    "import pathlib\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from tensorflow.data import AUTOTUNE\n",
    "from sklearn.utils import class_weight\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from tensorflow.keras import models, layers, mixed_precision, optimizers\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report\n"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Definindo constantes a serem usadas",
   "id": "386f7e8f62842b3d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-23T01:05:54.499409Z",
     "start_time": "2025-11-23T01:05:54.496281Z"
    }
   },
   "cell_type": "code",
   "source": [
    "IMG_ALTURA    = 176\n",
    "IMG_LARGURA   = 208\n",
    "TAMANHO_BATCH = 64\n",
    "\n",
    "SEED = 2025"
   ],
   "id": "518d9f32ec72f2d9",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-23T01:05:54.562312Z",
     "start_time": "2025-11-23T01:05:54.558605Z"
    }
   },
   "cell_type": "code",
   "source": [
    "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "tf.config.experimental.enable_op_determinism()\n",
    "\n",
    "print('Seed global definida:', SEED)"
   ],
   "id": "85df67e52d94296e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed global definida: 2025\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-23T01:05:55.398147Z",
     "start_time": "2025-11-23T01:05:54.612651Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def configurar_gpu():\n",
    "    try:\n",
    "        gpus = tf.config.list_physical_devices('GPU')\n",
    "        if gpus:\n",
    "            for gpu in gpus:\n",
    "                tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(f\"Erro ao configurar GPU: {e}\")\n",
    "\n",
    "mixed_precision.set_global_policy('mixed_float16')\n",
    "configurar_gpu()"
   ],
   "id": "66a81025563811c4",
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "id": "600a10a0d0a5d882",
   "metadata": {},
   "source": [
    "Definindo os diretórios do dataset"
   ]
  },
  {
   "cell_type": "code",
   "id": "574b5f8cb5bbebda",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-23T01:05:55.528768Z",
     "start_time": "2025-11-23T01:05:55.512993Z"
    }
   },
   "source": [
    "dir_dados = pathlib.Path('dataset')\n",
    "\n",
    "caminhos_arquivos = []\n",
    "rotulos = []\n",
    "nomes_classes = sorted([item.name for item in dir_dados.glob('*') if item.is_dir()])\n",
    "dict_classes = {nome: i for i, nome in enumerate(nomes_classes)}\n",
    "\n",
    "for nome_classe in nomes_classes:\n",
    "    padrao = str(dir_dados / nome_classe / '*')\n",
    "    arquivos = glob.glob(padrao)\n",
    "    caminhos_arquivos.extend(arquivos)\n",
    "    rotulos.extend([dict_classes[nome_classe]] * len(arquivos))\n",
    "\n",
    "caminhos_arquivos = np.array(caminhos_arquivos)\n",
    "rotulos = np.array(rotulos)\n",
    "\n",
    "X_restante, X_teste, y_restante, y_teste = train_test_split(\n",
    "    caminhos_arquivos, rotulos, test_size=0.15, stratify=rotulos, random_state=SEED\n",
    ")\n",
    "\n",
    "print(f\"Total para K-Fold (Treino+Val): {len(X_restante)}\")\n",
    "print(f\"Reservado para Teste Final: {len(X_teste)}\")\n",
    "\n",
    "def processar_arquivo(caminho, rotulo):\n",
    "    arquivo = tf.io.read_file(caminho)\n",
    "    img = tf.io.decode_image(arquivo, channels=1, expand_animations=False)\n",
    "    img = tf.image.resize(img, [IMG_ALTURA, IMG_LARGURA])\n",
    "    img = tf.cast(img, tf.float32)\n",
    "    return img, rotulo\n",
    "\n",
    "def criar_dataset_fold(caminhos, labels_fold, training=True):\n",
    "    ds = tf.data.Dataset.from_tensor_slices((caminhos, labels_fold))\n",
    "    ds = ds.map(processar_arquivo, num_parallel_calls=AUTOTUNE)\n",
    "    if training:\n",
    "        ds = ds.shuffle(len(caminhos), seed=SEED)\n",
    "    ds = ds.batch(TAMANHO_BATCH)\n",
    "    ds = ds.prefetch(AUTOTUNE)\n",
    "    return ds"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total para K-Fold (Treino+Val): 5440\n",
      "Reservado para Teste Final: 960\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "id": "c10f856f8906ca88",
   "metadata": {},
   "source": [
    "Iniciando a configuração do modelo."
   ]
  },
  {
   "cell_type": "code",
   "id": "f5ccf6c7ee895123",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-23T01:05:55.575559Z",
     "start_time": "2025-11-23T01:05:55.571775Z"
    }
   },
   "source": [
    "@tf.keras.utils.register_keras_serializable()\n",
    "def converter_para_cinza_gpu(x):\n",
    "    return tf.image.rgb_to_grayscale(x)\n",
    "\n",
    "def construir_modelo():\n",
    "    tf.keras.backend.clear_session()\n",
    "    gc.collect()\n",
    "\n",
    "    modelo = models.Sequential([\n",
    "        layers.Input(shape=(IMG_ALTURA, IMG_LARGURA, 1)),\n",
    "\n",
    "        layers.Conv2D(32, (3, 3), padding='same', use_bias=False),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Activation('relu'),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "        layers.Conv2D(64, (3, 3), padding='same', use_bias=False),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Activation('relu'),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "        layers.Conv2D(128, (3, 3), padding='same', use_bias=False),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Activation('relu'),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "        layers.Conv2D(256, (3, 3), padding='same', use_bias=False),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Activation('relu'),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(512, use_bias=False),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Activation('relu'),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(4, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    opt = optimizers.Adam(learning_rate=1e-4, clipnorm=1.0)\n",
    "    modelo.compile(\n",
    "        optimizer=opt,\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return modelo"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "id": "65c22eef320f53",
   "metadata": {},
   "source": [
    "Definindo callback de EarlyStopping."
   ]
  },
  {
   "cell_type": "code",
   "id": "a3c2dcaa662703db",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-23T01:05:55.622938Z",
     "start_time": "2025-11-23T01:05:55.620375Z"
    }
   },
   "source": [
    "def obter_callbacks(caminho_modelo):\n",
    "    early_stop = EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=15,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    reduce_le = ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.5,\n",
    "        patience=5,\n",
    "        min_lr=1e-7,\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    checkpoint = ModelCheckpoint(\n",
    "        caminho_modelo,\n",
    "        monitor='val_loss',\n",
    "        save_best_only=True,\n",
    "        mode='min',\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    return [early_stop, reduce_le, checkpoint]"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Colocando pesos nas classes a fim de diminuir falsos negativos (melhorar Recall).",
   "id": "4eb1c1381c6dfde5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-23T01:05:55.683069Z",
     "start_time": "2025-11-23T01:05:55.680420Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def ajustar_pesos(rotulos_treino):\n",
    "    pesos_base = class_weight.compute_class_weight(\n",
    "        class_weight='balanced',\n",
    "        classes=np.unique(rotulos_treino),\n",
    "        y=rotulos_treino\n",
    "    )\n",
    "\n",
    "    pesos_dict = dict(enumerate(pesos_base))\n",
    "    fator_rigor = 2.5\n",
    "    indice_saudavel = 2\n",
    "    for classe, peso in pesos_dict.items():\n",
    "        if classe != indice_saudavel:\n",
    "            pesos_dict[classe] = peso * fator_rigor\n",
    "            if classe == 1:\n",
    "                 pesos_dict[classe] *= 1.5\n",
    "\n",
    "    print(\"Pesos das classes:\", pesos_dict)\n",
    "    return pesos_dict"
   ],
   "id": "93a46dcba63ffb05",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-23T01:05:55.734541Z",
     "start_time": "2025-11-23T01:05:55.731729Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def avaliar_fold(modelo, ds_val, melhor_acc_atual):\n",
    "    scores = modelo.evaluate(ds_val, verbose=0)\n",
    "    acuracia_fold = scores[1]\n",
    "    loss_fold = scores[0]\n",
    "    print(f\"   > Acurácia Validação: {acuracia_fold*100:.2f}% (Loss: {loss_fold:.4f})\")\n",
    "    nova_melhor_acc = melhor_acc_atual\n",
    "\n",
    "    if acuracia_fold > melhor_acc_atual:\n",
    "        nova_melhor_acc = acuracia_fold\n",
    "        print(f\"   > Novo recorde! (Anterior: {melhor_acc_atual*100:.2f}%) -> Salvando modelo...\")\n",
    "        modelo.save('melhor_modelo_kfold.keras')\n",
    "\n",
    "    return acuracia_fold, nova_melhor_acc"
   ],
   "id": "ac909483fa01608c",
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "id": "b33d08c37fe1c743",
   "metadata": {},
   "source": [
    "Treinando o modelo"
   ]
  },
  {
   "cell_type": "code",
   "id": "fc08b5bfb9113d51",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-23T01:56:05.616980Z",
     "start_time": "2025-11-23T01:05:55.783164Z"
    }
   },
   "source": [
    "PASTA_FOLDS = \"Folds\"\n",
    "os.makedirs(PASTA_FOLDS, exist_ok=True)\n",
    "\n",
    "NUM_FOLDS = 6\n",
    "skf = StratifiedKFold(n_splits=NUM_FOLDS, shuffle=True, random_state=SEED)\n",
    "resultados_acuracia = []\n",
    "\n",
    "print(f\"Iniciando Treinamento com {NUM_FOLDS} Folds...\\n\")\n",
    "\n",
    "fold_atual = 1\n",
    "for idx_treino, idx_val in skf.split(X_restante, y_restante):\n",
    "    print(f\"--- Rodando Fold {fold_atual}/{NUM_FOLDS} ---\")\n",
    "\n",
    "    X_treino_f, X_val_f = X_restante[idx_treino], X_restante[idx_val]\n",
    "    y_treino_f, y_val_f = y_restante[idx_treino], y_restante[idx_val]\n",
    "\n",
    "    ds_treino = criar_dataset_fold(X_treino_f, y_treino_f, training=True)\n",
    "    ds_val = criar_dataset_fold(X_val_f, y_val_f, training=False)\n",
    "\n",
    "    pesos = ajustar_pesos(y_treino_f)\n",
    "    modelo_fold = construir_modelo()\n",
    "\n",
    "    nome_arquivo = f'modelo_fold_{fold_atual}.keras'\n",
    "    caminho_modelo = os.path.join(PASTA_FOLDS, nome_arquivo)\n",
    "\n",
    "    callbacks_list = obter_callbacks(caminho_modelo)\n",
    "\n",
    "    history = modelo_fold.fit(\n",
    "        ds_treino,\n",
    "        validation_data=ds_val,\n",
    "        epochs=150,\n",
    "        callbacks=callbacks_list,\n",
    "        class_weight=pesos\n",
    "    )\n",
    "\n",
    "    modelo_fold.load_weights(caminho_modelo)\n",
    "    scores = modelo_fold.evaluate(ds_val, verbose=0)\n",
    "    print(f\"   > Acurácia Final Fold {fold_atual}: {scores[1]*100:.2f}%\")\n",
    "    resultados_acuracia.append(scores[1])\n",
    "\n",
    "    del ds_treino, ds_val, modelo_fold\n",
    "    tf.keras.backend.clear_session()\n",
    "    gc.collect()\n",
    "\n",
    "    fold_atual += 1\n",
    "\n",
    "print(\"\\n\" + \"=\"*30)\n",
    "print(f\"Média Final de Acurácia: {np.mean(resultados_acuracia)*100:.2f}%\")\n",
    "print(\"O melhor modelo de todos os folds já está salvo como 'melhor_modelo_kfold.keras'\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando Treinamento com 6 Folds...\n",
      "\n",
      "--- Rodando Fold 1/6 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1763859955.976989   15925 gpu_device.cc:2020] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5563 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pesos das classes: {0: np.float64(4.461614173228346), 1: np.float64(94.4375), 2: np.float64(0.5001103265666372), 3: np.float64(1.7852079395085065)}\n",
      "Epoch 1/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m18s\u001B[0m 196ms/step - accuracy: 0.5306 - loss: 2.1687 - val_accuracy: 0.6119 - val_loss: 1.1071 - learning_rate: 1.0000e-04\n",
      "Epoch 2/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 192ms/step - accuracy: 0.8350 - loss: 0.4228 - val_accuracy: 0.7233 - val_loss: 0.7155 - learning_rate: 1.0000e-04\n",
      "Epoch 3/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 184ms/step - accuracy: 0.9552 - loss: 0.1383 - val_accuracy: 0.8291 - val_loss: 0.4351 - learning_rate: 1.0000e-04\n",
      "Epoch 4/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 184ms/step - accuracy: 0.9899 - loss: 0.0465 - val_accuracy: 0.9416 - val_loss: 0.1965 - learning_rate: 1.0000e-04\n",
      "Epoch 5/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 180ms/step - accuracy: 0.9940 - loss: 0.0240 - val_accuracy: 0.9184 - val_loss: 0.2182 - learning_rate: 1.0000e-04\n",
      "Epoch 6/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 178ms/step - accuracy: 0.9998 - loss: 0.0090 - val_accuracy: 0.8412 - val_loss: 0.4876 - learning_rate: 1.0000e-04\n",
      "Epoch 7/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 186ms/step - accuracy: 1.0000 - loss: 0.0051 - val_accuracy: 0.9768 - val_loss: 0.0733 - learning_rate: 1.0000e-04\n",
      "Epoch 8/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 186ms/step - accuracy: 1.0000 - loss: 0.0043 - val_accuracy: 0.9813 - val_loss: 0.0572 - learning_rate: 1.0000e-04\n",
      "Epoch 9/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 175ms/step - accuracy: 0.9993 - loss: 0.0044 - val_accuracy: 0.9735 - val_loss: 0.0870 - learning_rate: 1.0000e-04\n",
      "Epoch 10/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 178ms/step - accuracy: 0.9998 - loss: 0.0025 - val_accuracy: 0.9835 - val_loss: 0.0601 - learning_rate: 1.0000e-04\n",
      "Epoch 11/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 178ms/step - accuracy: 1.0000 - loss: 0.0019 - val_accuracy: 0.9680 - val_loss: 0.1143 - learning_rate: 1.0000e-04\n",
      "Epoch 12/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 186ms/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 0.9779 - val_loss: 0.0594 - learning_rate: 1.0000e-04\n",
      "Epoch 13/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 176ms/step - accuracy: 1.0000 - loss: 9.4260e-04\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 182ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.9813 - val_loss: 0.0620 - learning_rate: 1.0000e-04\n",
      "Epoch 14/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 197ms/step - accuracy: 1.0000 - loss: 9.7764e-04 - val_accuracy: 0.9824 - val_loss: 0.0507 - learning_rate: 5.0000e-05\n",
      "Epoch 15/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 184ms/step - accuracy: 1.0000 - loss: 7.6460e-04 - val_accuracy: 0.9813 - val_loss: 0.0540 - learning_rate: 5.0000e-05\n",
      "Epoch 16/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 183ms/step - accuracy: 1.0000 - loss: 6.5565e-04 - val_accuracy: 0.9813 - val_loss: 0.0511 - learning_rate: 5.0000e-05\n",
      "Epoch 17/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 194ms/step - accuracy: 1.0000 - loss: 5.9796e-04 - val_accuracy: 0.9813 - val_loss: 0.0489 - learning_rate: 5.0000e-05\n",
      "Epoch 18/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 193ms/step - accuracy: 1.0000 - loss: 6.5063e-04 - val_accuracy: 0.9846 - val_loss: 0.0444 - learning_rate: 5.0000e-05\n",
      "Epoch 19/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 182ms/step - accuracy: 1.0000 - loss: 4.2312e-04 - val_accuracy: 0.9824 - val_loss: 0.0454 - learning_rate: 5.0000e-05\n",
      "Epoch 20/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 182ms/step - accuracy: 1.0000 - loss: 4.5278e-04 - val_accuracy: 0.9835 - val_loss: 0.0456 - learning_rate: 5.0000e-05\n",
      "Epoch 21/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 183ms/step - accuracy: 1.0000 - loss: 4.5796e-04 - val_accuracy: 0.9813 - val_loss: 0.0454 - learning_rate: 5.0000e-05\n",
      "Epoch 22/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 188ms/step - accuracy: 1.0000 - loss: 5.2719e-04 - val_accuracy: 0.9813 - val_loss: 0.0486 - learning_rate: 5.0000e-05\n",
      "Epoch 23/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 175ms/step - accuracy: 1.0000 - loss: 3.2141e-04\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 181ms/step - accuracy: 1.0000 - loss: 3.7428e-04 - val_accuracy: 0.9835 - val_loss: 0.0465 - learning_rate: 5.0000e-05\n",
      "Epoch 24/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 183ms/step - accuracy: 1.0000 - loss: 4.0056e-04 - val_accuracy: 0.9835 - val_loss: 0.0456 - learning_rate: 2.5000e-05\n",
      "Epoch 25/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 181ms/step - accuracy: 1.0000 - loss: 4.5310e-04 - val_accuracy: 0.9824 - val_loss: 0.0463 - learning_rate: 2.5000e-05\n",
      "Epoch 26/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 181ms/step - accuracy: 1.0000 - loss: 3.1386e-04 - val_accuracy: 0.9835 - val_loss: 0.0465 - learning_rate: 2.5000e-05\n",
      "Epoch 27/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 186ms/step - accuracy: 1.0000 - loss: 3.9357e-04 - val_accuracy: 0.9824 - val_loss: 0.0462 - learning_rate: 2.5000e-05\n",
      "Epoch 28/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 177ms/step - accuracy: 1.0000 - loss: 3.4635e-04\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 183ms/step - accuracy: 1.0000 - loss: 3.0045e-04 - val_accuracy: 0.9835 - val_loss: 0.0455 - learning_rate: 2.5000e-05\n",
      "Epoch 29/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 180ms/step - accuracy: 1.0000 - loss: 3.1523e-04 - val_accuracy: 0.9835 - val_loss: 0.0456 - learning_rate: 1.2500e-05\n",
      "Epoch 30/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 179ms/step - accuracy: 1.0000 - loss: 3.4505e-04 - val_accuracy: 0.9835 - val_loss: 0.0462 - learning_rate: 1.2500e-05\n",
      "Epoch 31/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 182ms/step - accuracy: 1.0000 - loss: 3.2316e-04 - val_accuracy: 0.9835 - val_loss: 0.0460 - learning_rate: 1.2500e-05\n",
      "Epoch 32/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m21s\u001B[0m 183ms/step - accuracy: 1.0000 - loss: 3.3107e-04 - val_accuracy: 0.9835 - val_loss: 0.0463 - learning_rate: 1.2500e-05\n",
      "Epoch 33/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 182ms/step - accuracy: 1.0000 - loss: 2.9235e-04\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 188ms/step - accuracy: 1.0000 - loss: 3.3533e-04 - val_accuracy: 0.9813 - val_loss: 0.0465 - learning_rate: 1.2500e-05\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "   > Acurácia Final Fold 1: 98.46%\n",
      "--- Rodando Fold 2/6 ---\n",
      "Pesos das classes: {0: np.float64(4.461614173228346), 1: np.float64(94.4375), 2: np.float64(0.5001103265666372), 3: np.float64(1.7852079395085065)}\n",
      "Epoch 1/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m16s\u001B[0m 196ms/step - accuracy: 0.5321 - loss: 2.3219 - val_accuracy: 0.5810 - val_loss: 0.9560 - learning_rate: 1.0000e-04\n",
      "Epoch 2/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m15s\u001B[0m 202ms/step - accuracy: 0.8405 - loss: 0.4306 - val_accuracy: 0.7166 - val_loss: 0.7036 - learning_rate: 1.0000e-04\n",
      "Epoch 3/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 189ms/step - accuracy: 0.9579 - loss: 0.1392 - val_accuracy: 0.9041 - val_loss: 0.3387 - learning_rate: 1.0000e-04\n",
      "Epoch 4/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 189ms/step - accuracy: 0.9879 - loss: 0.0458 - val_accuracy: 0.9603 - val_loss: 0.1673 - learning_rate: 1.0000e-04\n",
      "Epoch 5/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 179ms/step - accuracy: 0.9967 - loss: 0.0182 - val_accuracy: 0.8699 - val_loss: 0.3364 - learning_rate: 1.0000e-04\n",
      "Epoch 6/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 181ms/step - accuracy: 0.9989 - loss: 0.0086 - val_accuracy: 0.9372 - val_loss: 0.1939 - learning_rate: 1.0000e-04\n",
      "Epoch 7/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 199ms/step - accuracy: 0.9998 - loss: 0.0049 - val_accuracy: 0.9779 - val_loss: 0.0785 - learning_rate: 1.0000e-04\n",
      "Epoch 8/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 187ms/step - accuracy: 0.9998 - loss: 0.0045 - val_accuracy: 0.9548 - val_loss: 0.1542 - learning_rate: 1.0000e-04\n",
      "Epoch 9/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 183ms/step - accuracy: 0.9996 - loss: 0.0030 - val_accuracy: 0.9669 - val_loss: 0.0972 - learning_rate: 1.0000e-04\n",
      "Epoch 10/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 185ms/step - accuracy: 1.0000 - loss: 0.0020 - val_accuracy: 0.9338 - val_loss: 0.1897 - learning_rate: 1.0000e-04\n",
      "Epoch 11/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 194ms/step - accuracy: 0.9998 - loss: 0.0020 - val_accuracy: 0.9868 - val_loss: 0.0638 - learning_rate: 1.0000e-04\n",
      "Epoch 12/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 195ms/step - accuracy: 1.0000 - loss: 0.0015 - val_accuracy: 0.9868 - val_loss: 0.0577 - learning_rate: 1.0000e-04\n",
      "Epoch 13/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m15s\u001B[0m 204ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.9879 - val_loss: 0.0518 - learning_rate: 1.0000e-04\n",
      "Epoch 14/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m15s\u001B[0m 194ms/step - accuracy: 1.0000 - loss: 9.7814e-04 - val_accuracy: 0.9868 - val_loss: 0.0502 - learning_rate: 1.0000e-04\n",
      "Epoch 15/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m15s\u001B[0m 201ms/step - accuracy: 1.0000 - loss: 8.1031e-04 - val_accuracy: 0.9857 - val_loss: 0.0489 - learning_rate: 1.0000e-04\n",
      "Epoch 16/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 185ms/step - accuracy: 1.0000 - loss: 6.5262e-04 - val_accuracy: 0.9879 - val_loss: 0.0561 - learning_rate: 1.0000e-04\n",
      "Epoch 17/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 183ms/step - accuracy: 1.0000 - loss: 8.2142e-04 - val_accuracy: 0.9879 - val_loss: 0.0520 - learning_rate: 1.0000e-04\n",
      "Epoch 18/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 193ms/step - accuracy: 1.0000 - loss: 5.3719e-04 - val_accuracy: 0.9912 - val_loss: 0.0419 - learning_rate: 1.0000e-04\n",
      "Epoch 19/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 183ms/step - accuracy: 1.0000 - loss: 4.7993e-04 - val_accuracy: 0.9890 - val_loss: 0.0456 - learning_rate: 1.0000e-04\n",
      "Epoch 20/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 182ms/step - accuracy: 1.0000 - loss: 3.6927e-04 - val_accuracy: 0.9890 - val_loss: 0.0440 - learning_rate: 1.0000e-04\n",
      "Epoch 21/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 184ms/step - accuracy: 1.0000 - loss: 4.0329e-04 - val_accuracy: 0.9890 - val_loss: 0.0438 - learning_rate: 1.0000e-04\n",
      "Epoch 22/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 189ms/step - accuracy: 1.0000 - loss: 3.2467e-04 - val_accuracy: 0.9890 - val_loss: 0.0426 - learning_rate: 1.0000e-04\n",
      "Epoch 23/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 185ms/step - accuracy: 1.0000 - loss: 3.2822e-04\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m21s\u001B[0m 191ms/step - accuracy: 1.0000 - loss: 2.9302e-04 - val_accuracy: 0.9890 - val_loss: 0.0464 - learning_rate: 1.0000e-04\n",
      "Epoch 24/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 190ms/step - accuracy: 1.0000 - loss: 3.4043e-04 - val_accuracy: 0.9857 - val_loss: 0.0651 - learning_rate: 5.0000e-05\n",
      "Epoch 25/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 185ms/step - accuracy: 1.0000 - loss: 2.5221e-04 - val_accuracy: 0.9890 - val_loss: 0.0517 - learning_rate: 5.0000e-05\n",
      "Epoch 26/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 188ms/step - accuracy: 1.0000 - loss: 2.9014e-04 - val_accuracy: 0.9890 - val_loss: 0.0427 - learning_rate: 5.0000e-05\n",
      "Epoch 27/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 181ms/step - accuracy: 1.0000 - loss: 2.8713e-04 - val_accuracy: 0.9890 - val_loss: 0.0434 - learning_rate: 5.0000e-05\n",
      "Epoch 28/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 179ms/step - accuracy: 1.0000 - loss: 2.3086e-04\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 186ms/step - accuracy: 1.0000 - loss: 2.7592e-04 - val_accuracy: 0.9890 - val_loss: 0.0454 - learning_rate: 5.0000e-05\n",
      "Epoch 29/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 182ms/step - accuracy: 1.0000 - loss: 2.3046e-04 - val_accuracy: 0.9890 - val_loss: 0.0444 - learning_rate: 2.5000e-05\n",
      "Epoch 30/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 183ms/step - accuracy: 1.0000 - loss: 2.4870e-04 - val_accuracy: 0.9890 - val_loss: 0.0459 - learning_rate: 2.5000e-05\n",
      "Epoch 31/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 183ms/step - accuracy: 1.0000 - loss: 2.3082e-04 - val_accuracy: 0.9890 - val_loss: 0.0434 - learning_rate: 2.5000e-05\n",
      "Epoch 32/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 189ms/step - accuracy: 1.0000 - loss: 1.9369e-04 - val_accuracy: 0.9890 - val_loss: 0.0465 - learning_rate: 2.5000e-05\n",
      "Epoch 33/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 182ms/step - accuracy: 1.0000 - loss: 1.9820e-04\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 188ms/step - accuracy: 1.0000 - loss: 2.0251e-04 - val_accuracy: 0.9890 - val_loss: 0.0454 - learning_rate: 2.5000e-05\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "   > Acurácia Final Fold 2: 99.12%\n",
      "--- Rodando Fold 3/6 ---\n",
      "Pesos das classes: {0: np.float64(4.461614173228346), 1: np.float64(94.4375), 2: np.float64(0.49988972209969124), 3: np.float64(1.7863335435056746)}\n",
      "Epoch 1/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m17s\u001B[0m 207ms/step - accuracy: 0.5204 - loss: 2.0447 - val_accuracy: 0.5094 - val_loss: 1.5445 - learning_rate: 1.0000e-04\n",
      "Epoch 2/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 189ms/step - accuracy: 0.8458 - loss: 0.3854 - val_accuracy: 0.5380 - val_loss: 1.0169 - learning_rate: 1.0000e-04\n",
      "Epoch 3/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 195ms/step - accuracy: 0.9680 - loss: 0.1148 - val_accuracy: 0.7905 - val_loss: 0.4847 - learning_rate: 1.0000e-04\n",
      "Epoch 4/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 198ms/step - accuracy: 0.9881 - loss: 0.0515 - val_accuracy: 0.8159 - val_loss: 0.4374 - learning_rate: 1.0000e-04\n",
      "Epoch 5/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 195ms/step - accuracy: 0.9971 - loss: 0.0191 - val_accuracy: 0.8964 - val_loss: 0.2928 - learning_rate: 1.0000e-04\n",
      "Epoch 6/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 188ms/step - accuracy: 0.9985 - loss: 0.0104 - val_accuracy: 0.9614 - val_loss: 0.1241 - learning_rate: 1.0000e-04\n",
      "Epoch 7/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 188ms/step - accuracy: 0.9985 - loss: 0.0075 - val_accuracy: 0.9868 - val_loss: 0.0502 - learning_rate: 1.0000e-04\n",
      "Epoch 8/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 183ms/step - accuracy: 0.9998 - loss: 0.0046 - val_accuracy: 0.9791 - val_loss: 0.0834 - learning_rate: 1.0000e-04\n",
      "Epoch 9/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 187ms/step - accuracy: 1.0000 - loss: 0.0026 - val_accuracy: 0.9846 - val_loss: 0.0492 - learning_rate: 1.0000e-04\n",
      "Epoch 10/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 181ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 0.9813 - val_loss: 0.0499 - learning_rate: 1.0000e-04\n",
      "Epoch 11/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 188ms/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 0.9868 - val_loss: 0.0416 - learning_rate: 1.0000e-04\n",
      "Epoch 12/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 180ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 0.9868 - val_loss: 0.0515 - learning_rate: 1.0000e-04\n",
      "Epoch 13/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 190ms/step - accuracy: 1.0000 - loss: 8.6566e-04 - val_accuracy: 0.9890 - val_loss: 0.0406 - learning_rate: 1.0000e-04\n",
      "Epoch 14/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 189ms/step - accuracy: 1.0000 - loss: 7.5381e-04 - val_accuracy: 0.9901 - val_loss: 0.0375 - learning_rate: 1.0000e-04\n",
      "Epoch 15/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 190ms/step - accuracy: 1.0000 - loss: 6.0139e-04 - val_accuracy: 0.9912 - val_loss: 0.0362 - learning_rate: 1.0000e-04\n",
      "Epoch 16/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 183ms/step - accuracy: 1.0000 - loss: 5.6421e-04 - val_accuracy: 0.9890 - val_loss: 0.0376 - learning_rate: 1.0000e-04\n",
      "Epoch 17/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 190ms/step - accuracy: 1.0000 - loss: 5.8256e-04 - val_accuracy: 0.9901 - val_loss: 0.0344 - learning_rate: 1.0000e-04\n",
      "Epoch 18/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 199ms/step - accuracy: 1.0000 - loss: 4.0989e-04 - val_accuracy: 0.9868 - val_loss: 0.0340 - learning_rate: 1.0000e-04\n",
      "Epoch 19/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 180ms/step - accuracy: 1.0000 - loss: 4.1853e-04 - val_accuracy: 0.9868 - val_loss: 0.0358 - learning_rate: 1.0000e-04\n",
      "Epoch 20/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 182ms/step - accuracy: 1.0000 - loss: 4.7062e-04 - val_accuracy: 0.9868 - val_loss: 0.0372 - learning_rate: 1.0000e-04\n",
      "Epoch 21/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 180ms/step - accuracy: 1.0000 - loss: 3.3747e-04 - val_accuracy: 0.9879 - val_loss: 0.0363 - learning_rate: 1.0000e-04\n",
      "Epoch 22/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 182ms/step - accuracy: 1.0000 - loss: 3.3295e-04 - val_accuracy: 0.9901 - val_loss: 0.0386 - learning_rate: 1.0000e-04\n",
      "Epoch 23/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 175ms/step - accuracy: 1.0000 - loss: 3.9042e-04\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 181ms/step - accuracy: 1.0000 - loss: 3.4506e-04 - val_accuracy: 0.9912 - val_loss: 0.0348 - learning_rate: 1.0000e-04\n",
      "Epoch 24/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 180ms/step - accuracy: 1.0000 - loss: 2.6017e-04 - val_accuracy: 0.9901 - val_loss: 0.0353 - learning_rate: 5.0000e-05\n",
      "Epoch 25/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 182ms/step - accuracy: 1.0000 - loss: 2.4988e-04 - val_accuracy: 0.9890 - val_loss: 0.0350 - learning_rate: 5.0000e-05\n",
      "Epoch 26/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 186ms/step - accuracy: 1.0000 - loss: 2.5054e-04 - val_accuracy: 0.9901 - val_loss: 0.0331 - learning_rate: 5.0000e-05\n",
      "Epoch 27/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 182ms/step - accuracy: 1.0000 - loss: 2.5095e-04 - val_accuracy: 0.9912 - val_loss: 0.0331 - learning_rate: 5.0000e-05\n",
      "Epoch 28/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 180ms/step - accuracy: 1.0000 - loss: 2.3367e-04 - val_accuracy: 0.9912 - val_loss: 0.0332 - learning_rate: 5.0000e-05\n",
      "Epoch 29/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 180ms/step - accuracy: 1.0000 - loss: 2.5271e-04 - val_accuracy: 0.9901 - val_loss: 0.0392 - learning_rate: 5.0000e-05\n",
      "Epoch 30/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 188ms/step - accuracy: 1.0000 - loss: 2.3545e-04 - val_accuracy: 0.9912 - val_loss: 0.0328 - learning_rate: 5.0000e-05\n",
      "Epoch 31/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 180ms/step - accuracy: 1.0000 - loss: 2.4346e-04 - val_accuracy: 0.9912 - val_loss: 0.0344 - learning_rate: 5.0000e-05\n",
      "Epoch 32/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 183ms/step - accuracy: 1.0000 - loss: 2.5297e-04 - val_accuracy: 0.9912 - val_loss: 0.0337 - learning_rate: 5.0000e-05\n",
      "Epoch 33/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 188ms/step - accuracy: 1.0000 - loss: 2.2831e-04 - val_accuracy: 0.9912 - val_loss: 0.0311 - learning_rate: 5.0000e-05\n",
      "Epoch 34/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 179ms/step - accuracy: 1.0000 - loss: 1.8976e-04 - val_accuracy: 0.9901 - val_loss: 0.0317 - learning_rate: 5.0000e-05\n",
      "Epoch 35/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 179ms/step - accuracy: 1.0000 - loss: 1.7750e-04 - val_accuracy: 0.9901 - val_loss: 0.0339 - learning_rate: 5.0000e-05\n",
      "Epoch 36/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 178ms/step - accuracy: 1.0000 - loss: 1.7391e-04 - val_accuracy: 0.9912 - val_loss: 0.0318 - learning_rate: 5.0000e-05\n",
      "Epoch 37/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 181ms/step - accuracy: 1.0000 - loss: 1.7285e-04 - val_accuracy: 0.9890 - val_loss: 0.0329 - learning_rate: 5.0000e-05\n",
      "Epoch 38/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 172ms/step - accuracy: 1.0000 - loss: 2.0662e-04\n",
      "Epoch 38: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 178ms/step - accuracy: 1.0000 - loss: 1.9533e-04 - val_accuracy: 0.9901 - val_loss: 0.0339 - learning_rate: 5.0000e-05\n",
      "Epoch 39/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 180ms/step - accuracy: 1.0000 - loss: 1.3236e-04 - val_accuracy: 0.9901 - val_loss: 0.0328 - learning_rate: 2.5000e-05\n",
      "Epoch 40/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 179ms/step - accuracy: 1.0000 - loss: 1.7398e-04 - val_accuracy: 0.9901 - val_loss: 0.0312 - learning_rate: 2.5000e-05\n",
      "Epoch 41/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 178ms/step - accuracy: 1.0000 - loss: 1.3269e-04 - val_accuracy: 0.9901 - val_loss: 0.0314 - learning_rate: 2.5000e-05\n",
      "Epoch 42/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 181ms/step - accuracy: 1.0000 - loss: 1.4565e-04 - val_accuracy: 0.9912 - val_loss: 0.0328 - learning_rate: 2.5000e-05\n",
      "Epoch 43/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 173ms/step - accuracy: 1.0000 - loss: 1.4539e-04\n",
      "Epoch 43: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 179ms/step - accuracy: 1.0000 - loss: 1.5094e-04 - val_accuracy: 0.9901 - val_loss: 0.0324 - learning_rate: 2.5000e-05\n",
      "Epoch 44/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 180ms/step - accuracy: 1.0000 - loss: 1.4250e-04 - val_accuracy: 0.9901 - val_loss: 0.0334 - learning_rate: 1.2500e-05\n",
      "Epoch 45/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 180ms/step - accuracy: 1.0000 - loss: 1.7668e-04 - val_accuracy: 0.9901 - val_loss: 0.0346 - learning_rate: 1.2500e-05\n",
      "Epoch 46/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 178ms/step - accuracy: 1.0000 - loss: 1.4010e-04 - val_accuracy: 0.9912 - val_loss: 0.0346 - learning_rate: 1.2500e-05\n",
      "Epoch 47/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m21s\u001B[0m 179ms/step - accuracy: 1.0000 - loss: 1.2732e-04 - val_accuracy: 0.9912 - val_loss: 0.0338 - learning_rate: 1.2500e-05\n",
      "Epoch 48/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 172ms/step - accuracy: 1.0000 - loss: 1.6297e-04\n",
      "Epoch 48: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 178ms/step - accuracy: 1.0000 - loss: 1.6265e-04 - val_accuracy: 0.9912 - val_loss: 0.0332 - learning_rate: 1.2500e-05\n",
      "Epoch 48: early stopping\n",
      "Restoring model weights from the end of the best epoch: 33.\n",
      "   > Acurácia Final Fold 3: 99.12%\n",
      "--- Rodando Fold 4/6 ---\n",
      "Pesos das classes: {0: np.float64(4.461614173228346), 1: np.float64(94.4375), 2: np.float64(0.49988972209969124), 3: np.float64(1.7863335435056746)}\n",
      "Epoch 1/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m16s\u001B[0m 190ms/step - accuracy: 0.4394 - loss: 2.5219 - val_accuracy: 0.3727 - val_loss: 1.9527 - learning_rate: 1.0000e-04\n",
      "Epoch 2/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 181ms/step - accuracy: 0.8202 - loss: 0.4733 - val_accuracy: 0.6571 - val_loss: 0.9255 - learning_rate: 1.0000e-04\n",
      "Epoch 3/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 184ms/step - accuracy: 0.9603 - loss: 0.1206 - val_accuracy: 0.6913 - val_loss: 0.6431 - learning_rate: 1.0000e-04\n",
      "Epoch 4/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 181ms/step - accuracy: 0.9914 - loss: 0.0430 - val_accuracy: 0.9438 - val_loss: 0.1975 - learning_rate: 1.0000e-04\n",
      "Epoch 5/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 183ms/step - accuracy: 0.9974 - loss: 0.0212 - val_accuracy: 0.9691 - val_loss: 0.1019 - learning_rate: 1.0000e-04\n",
      "Epoch 6/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 183ms/step - accuracy: 0.9991 - loss: 0.0098 - val_accuracy: 0.9779 - val_loss: 0.0721 - learning_rate: 1.0000e-04\n",
      "Epoch 7/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 175ms/step - accuracy: 0.9998 - loss: 0.0057 - val_accuracy: 0.8931 - val_loss: 0.2834 - learning_rate: 1.0000e-04\n",
      "Epoch 8/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 177ms/step - accuracy: 0.9996 - loss: 0.0044 - val_accuracy: 0.9779 - val_loss: 0.0839 - learning_rate: 1.0000e-04\n",
      "Epoch 9/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 181ms/step - accuracy: 0.9998 - loss: 0.0033 - val_accuracy: 0.9912 - val_loss: 0.0529 - learning_rate: 1.0000e-04\n",
      "Epoch 10/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 197ms/step - accuracy: 0.9998 - loss: 0.0019 - val_accuracy: 0.9923 - val_loss: 0.0474 - learning_rate: 1.0000e-04\n",
      "Epoch 11/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 175ms/step - accuracy: 1.0000 - loss: 0.0019 - val_accuracy: 0.9802 - val_loss: 0.0881 - learning_rate: 1.0000e-04\n",
      "Epoch 12/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 176ms/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 0.9879 - val_loss: 0.0558 - learning_rate: 1.0000e-04\n",
      "Epoch 13/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m21s\u001B[0m 182ms/step - accuracy: 1.0000 - loss: 8.7873e-04 - val_accuracy: 0.9901 - val_loss: 0.0473 - learning_rate: 1.0000e-04\n",
      "Epoch 14/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 184ms/step - accuracy: 1.0000 - loss: 7.8987e-04 - val_accuracy: 0.9912 - val_loss: 0.0459 - learning_rate: 1.0000e-04\n",
      "Epoch 15/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 176ms/step - accuracy: 1.0000 - loss: 7.6088e-04 - val_accuracy: 0.9923 - val_loss: 0.0489 - learning_rate: 1.0000e-04\n",
      "Epoch 16/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 174ms/step - accuracy: 1.0000 - loss: 6.8255e-04 - val_accuracy: 0.9923 - val_loss: 0.0466 - learning_rate: 1.0000e-04\n",
      "Epoch 17/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 186ms/step - accuracy: 1.0000 - loss: 5.5706e-04 - val_accuracy: 0.9901 - val_loss: 0.0422 - learning_rate: 1.0000e-04\n",
      "Epoch 18/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 174ms/step - accuracy: 1.0000 - loss: 4.9017e-04 - val_accuracy: 0.9901 - val_loss: 0.0432 - learning_rate: 1.0000e-04\n",
      "Epoch 19/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 176ms/step - accuracy: 1.0000 - loss: 4.3533e-04 - val_accuracy: 0.9890 - val_loss: 0.0461 - learning_rate: 1.0000e-04\n",
      "Epoch 20/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 175ms/step - accuracy: 1.0000 - loss: 4.2890e-04 - val_accuracy: 0.9890 - val_loss: 0.0523 - learning_rate: 1.0000e-04\n",
      "Epoch 21/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 174ms/step - accuracy: 1.0000 - loss: 3.5134e-04 - val_accuracy: 0.9912 - val_loss: 0.0480 - learning_rate: 1.0000e-04\n",
      "Epoch 22/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 171ms/step - accuracy: 1.0000 - loss: 3.5820e-04\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 177ms/step - accuracy: 1.0000 - loss: 3.4896e-04 - val_accuracy: 0.9901 - val_loss: 0.0449 - learning_rate: 1.0000e-04\n",
      "Epoch 23/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 181ms/step - accuracy: 1.0000 - loss: 3.1597e-04 - val_accuracy: 0.9912 - val_loss: 0.0465 - learning_rate: 5.0000e-05\n",
      "Epoch 24/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 182ms/step - accuracy: 1.0000 - loss: 3.2259e-04 - val_accuracy: 0.9912 - val_loss: 0.0437 - learning_rate: 5.0000e-05\n",
      "Epoch 25/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 180ms/step - accuracy: 1.0000 - loss: 2.8790e-04 - val_accuracy: 0.9934 - val_loss: 0.0449 - learning_rate: 5.0000e-05\n",
      "Epoch 26/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 175ms/step - accuracy: 1.0000 - loss: 2.8459e-04 - val_accuracy: 0.9934 - val_loss: 0.0459 - learning_rate: 5.0000e-05\n",
      "Epoch 27/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 172ms/step - accuracy: 1.0000 - loss: 2.4003e-04\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 178ms/step - accuracy: 1.0000 - loss: 2.7903e-04 - val_accuracy: 0.9934 - val_loss: 0.0455 - learning_rate: 5.0000e-05\n",
      "Epoch 28/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 175ms/step - accuracy: 1.0000 - loss: 2.7007e-04 - val_accuracy: 0.9934 - val_loss: 0.0463 - learning_rate: 2.5000e-05\n",
      "Epoch 29/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 176ms/step - accuracy: 1.0000 - loss: 2.6408e-04 - val_accuracy: 0.9912 - val_loss: 0.0458 - learning_rate: 2.5000e-05\n",
      "Epoch 30/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 176ms/step - accuracy: 1.0000 - loss: 2.1905e-04 - val_accuracy: 0.9912 - val_loss: 0.0453 - learning_rate: 2.5000e-05\n",
      "Epoch 31/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 174ms/step - accuracy: 1.0000 - loss: 2.2081e-04 - val_accuracy: 0.9934 - val_loss: 0.0463 - learning_rate: 2.5000e-05\n",
      "Epoch 32/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 171ms/step - accuracy: 1.0000 - loss: 2.7642e-04\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 177ms/step - accuracy: 1.0000 - loss: 2.7986e-04 - val_accuracy: 0.9934 - val_loss: 0.0461 - learning_rate: 2.5000e-05\n",
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "   > Acurácia Final Fold 4: 99.01%\n",
      "--- Rodando Fold 5/6 ---\n",
      "Pesos das classes: {0: np.float64(4.46259842519685), 1: np.float64(94.45833333333334), 2: np.float64(0.5), 3: np.float64(1.7856017643352238)}\n",
      "Epoch 1/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m16s\u001B[0m 187ms/step - accuracy: 0.5234 - loss: 2.2159 - val_accuracy: 0.4371 - val_loss: 1.4634 - learning_rate: 1.0000e-04\n",
      "Epoch 2/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 186ms/step - accuracy: 0.8511 - loss: 0.4297 - val_accuracy: 0.6788 - val_loss: 0.7021 - learning_rate: 1.0000e-04\n",
      "Epoch 3/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 183ms/step - accuracy: 0.9550 - loss: 0.1383 - val_accuracy: 0.8576 - val_loss: 0.4347 - learning_rate: 1.0000e-04\n",
      "Epoch 4/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 177ms/step - accuracy: 0.9914 - loss: 0.0423 - val_accuracy: 0.8068 - val_loss: 0.4532 - learning_rate: 1.0000e-04\n",
      "Epoch 5/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 182ms/step - accuracy: 0.9963 - loss: 0.0217 - val_accuracy: 0.9834 - val_loss: 0.0916 - learning_rate: 1.0000e-04\n",
      "Epoch 6/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 175ms/step - accuracy: 0.9978 - loss: 0.0101 - val_accuracy: 0.6611 - val_loss: 0.9402 - learning_rate: 1.0000e-04\n",
      "Epoch 7/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 185ms/step - accuracy: 0.9991 - loss: 0.0071 - val_accuracy: 0.9845 - val_loss: 0.0392 - learning_rate: 1.0000e-04\n",
      "Epoch 8/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 179ms/step - accuracy: 0.9996 - loss: 0.0043 - val_accuracy: 0.9702 - val_loss: 0.0812 - learning_rate: 1.0000e-04\n",
      "Epoch 9/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 180ms/step - accuracy: 0.9993 - loss: 0.0052 - val_accuracy: 0.9857 - val_loss: 0.0403 - learning_rate: 1.0000e-04\n",
      "Epoch 10/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 181ms/step - accuracy: 1.0000 - loss: 0.0027 - val_accuracy: 0.9812 - val_loss: 0.0597 - learning_rate: 1.0000e-04\n",
      "Epoch 11/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 176ms/step - accuracy: 1.0000 - loss: 0.0028 - val_accuracy: 0.9857 - val_loss: 0.0395 - learning_rate: 1.0000e-04\n",
      "Epoch 12/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 187ms/step - accuracy: 1.0000 - loss: 0.0020 - val_accuracy: 0.9912 - val_loss: 0.0359 - learning_rate: 1.0000e-04\n",
      "Epoch 13/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 182ms/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 0.9912 - val_loss: 0.0319 - learning_rate: 1.0000e-04\n",
      "Epoch 14/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 184ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.9923 - val_loss: 0.0298 - learning_rate: 1.0000e-04\n",
      "Epoch 15/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 176ms/step - accuracy: 1.0000 - loss: 9.4258e-04 - val_accuracy: 0.9845 - val_loss: 0.0483 - learning_rate: 1.0000e-04\n",
      "Epoch 16/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 175ms/step - accuracy: 1.0000 - loss: 5.8434e-04 - val_accuracy: 0.9912 - val_loss: 0.0312 - learning_rate: 1.0000e-04\n",
      "Epoch 17/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 184ms/step - accuracy: 1.0000 - loss: 5.8679e-04 - val_accuracy: 0.9923 - val_loss: 0.0205 - learning_rate: 1.0000e-04\n",
      "Epoch 18/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 175ms/step - accuracy: 1.0000 - loss: 5.3249e-04 - val_accuracy: 0.9823 - val_loss: 0.0598 - learning_rate: 1.0000e-04\n",
      "Epoch 19/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 177ms/step - accuracy: 1.0000 - loss: 6.2961e-04 - val_accuracy: 0.9901 - val_loss: 0.0353 - learning_rate: 1.0000e-04\n",
      "Epoch 20/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 176ms/step - accuracy: 1.0000 - loss: 4.9284e-04 - val_accuracy: 0.9934 - val_loss: 0.0257 - learning_rate: 1.0000e-04\n",
      "Epoch 21/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 176ms/step - accuracy: 1.0000 - loss: 3.5416e-04 - val_accuracy: 0.9934 - val_loss: 0.0250 - learning_rate: 1.0000e-04\n",
      "Epoch 22/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 171ms/step - accuracy: 1.0000 - loss: 3.4802e-04\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 177ms/step - accuracy: 1.0000 - loss: 3.5131e-04 - val_accuracy: 0.9934 - val_loss: 0.0237 - learning_rate: 1.0000e-04\n",
      "Epoch 23/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 174ms/step - accuracy: 1.0000 - loss: 3.2329e-04 - val_accuracy: 0.9923 - val_loss: 0.0234 - learning_rate: 5.0000e-05\n",
      "Epoch 24/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 176ms/step - accuracy: 1.0000 - loss: 3.1178e-04 - val_accuracy: 0.9934 - val_loss: 0.0252 - learning_rate: 5.0000e-05\n",
      "Epoch 25/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 175ms/step - accuracy: 1.0000 - loss: 3.7108e-04 - val_accuracy: 0.9923 - val_loss: 0.0238 - learning_rate: 5.0000e-05\n",
      "Epoch 26/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 174ms/step - accuracy: 1.0000 - loss: 2.9492e-04 - val_accuracy: 0.9934 - val_loss: 0.0264 - learning_rate: 5.0000e-05\n",
      "Epoch 27/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 171ms/step - accuracy: 1.0000 - loss: 3.3220e-04\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 177ms/step - accuracy: 1.0000 - loss: 2.8058e-04 - val_accuracy: 0.9934 - val_loss: 0.0244 - learning_rate: 5.0000e-05\n",
      "Epoch 28/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 175ms/step - accuracy: 1.0000 - loss: 2.3995e-04 - val_accuracy: 0.9934 - val_loss: 0.0232 - learning_rate: 2.5000e-05\n",
      "Epoch 29/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 177ms/step - accuracy: 1.0000 - loss: 2.1197e-04 - val_accuracy: 0.9934 - val_loss: 0.0240 - learning_rate: 2.5000e-05\n",
      "Epoch 30/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 179ms/step - accuracy: 1.0000 - loss: 2.5475e-04 - val_accuracy: 0.9934 - val_loss: 0.0242 - learning_rate: 2.5000e-05\n",
      "Epoch 31/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 179ms/step - accuracy: 1.0000 - loss: 2.3058e-04 - val_accuracy: 0.9934 - val_loss: 0.0246 - learning_rate: 2.5000e-05\n",
      "Epoch 32/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 173ms/step - accuracy: 1.0000 - loss: 2.0917e-04\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 179ms/step - accuracy: 1.0000 - loss: 2.1228e-04 - val_accuracy: 0.9934 - val_loss: 0.0237 - learning_rate: 2.5000e-05\n",
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "   > Acurácia Final Fold 5: 99.23%\n",
      "--- Rodando Fold 6/6 ---\n",
      "Pesos das classes: {0: np.float64(4.46259842519685), 1: np.float64(94.45833333333334), 2: np.float64(0.5), 3: np.float64(1.7856017643352238)}\n",
      "Epoch 1/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m16s\u001B[0m 186ms/step - accuracy: 0.5505 - loss: 2.5160 - val_accuracy: 0.5088 - val_loss: 1.4054 - learning_rate: 1.0000e-04\n",
      "Epoch 2/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 187ms/step - accuracy: 0.8236 - loss: 0.4827 - val_accuracy: 0.6093 - val_loss: 0.8296 - learning_rate: 1.0000e-04\n",
      "Epoch 3/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 184ms/step - accuracy: 0.9486 - loss: 0.1349 - val_accuracy: 0.7042 - val_loss: 0.5915 - learning_rate: 1.0000e-04\n",
      "Epoch 4/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 184ms/step - accuracy: 0.9874 - loss: 0.0451 - val_accuracy: 0.8444 - val_loss: 0.3940 - learning_rate: 1.0000e-04\n",
      "Epoch 5/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 183ms/step - accuracy: 0.9958 - loss: 0.0206 - val_accuracy: 0.9658 - val_loss: 0.1572 - learning_rate: 1.0000e-04\n",
      "Epoch 6/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 182ms/step - accuracy: 0.9998 - loss: 0.0109 - val_accuracy: 0.9812 - val_loss: 0.0720 - learning_rate: 1.0000e-04\n",
      "Epoch 7/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 181ms/step - accuracy: 0.9998 - loss: 0.0047 - val_accuracy: 0.9801 - val_loss: 0.0793 - learning_rate: 1.0000e-04\n",
      "Epoch 8/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 186ms/step - accuracy: 1.0000 - loss: 0.0027 - val_accuracy: 0.9857 - val_loss: 0.0527 - learning_rate: 1.0000e-04\n",
      "Epoch 9/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 186ms/step - accuracy: 1.0000 - loss: 0.0018 - val_accuracy: 0.9901 - val_loss: 0.0447 - learning_rate: 1.0000e-04\n",
      "Epoch 10/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 176ms/step - accuracy: 0.9998 - loss: 0.0019 - val_accuracy: 0.9879 - val_loss: 0.0595 - learning_rate: 1.0000e-04\n",
      "Epoch 11/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 176ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 0.9845 - val_loss: 0.0492 - learning_rate: 1.0000e-04\n",
      "Epoch 12/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 186ms/step - accuracy: 1.0000 - loss: 0.0017 - val_accuracy: 0.9879 - val_loss: 0.0441 - learning_rate: 1.0000e-04\n",
      "Epoch 13/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 175ms/step - accuracy: 1.0000 - loss: 9.4567e-04 - val_accuracy: 0.9901 - val_loss: 0.0442 - learning_rate: 1.0000e-04\n",
      "Epoch 14/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 178ms/step - accuracy: 1.0000 - loss: 7.7430e-04 - val_accuracy: 0.9812 - val_loss: 0.0502 - learning_rate: 1.0000e-04\n",
      "Epoch 15/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 179ms/step - accuracy: 1.0000 - loss: 6.7526e-04 - val_accuracy: 0.9857 - val_loss: 0.0464 - learning_rate: 1.0000e-04\n",
      "Epoch 16/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 189ms/step - accuracy: 1.0000 - loss: 5.8705e-04 - val_accuracy: 0.9890 - val_loss: 0.0421 - learning_rate: 1.0000e-04\n",
      "Epoch 17/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 186ms/step - accuracy: 1.0000 - loss: 5.4999e-04 - val_accuracy: 0.9912 - val_loss: 0.0412 - learning_rate: 1.0000e-04\n",
      "Epoch 18/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 178ms/step - accuracy: 1.0000 - loss: 5.2558e-04 - val_accuracy: 0.9879 - val_loss: 0.0507 - learning_rate: 1.0000e-04\n",
      "Epoch 19/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 180ms/step - accuracy: 1.0000 - loss: 9.7409e-04 - val_accuracy: 0.9823 - val_loss: 0.0591 - learning_rate: 1.0000e-04\n",
      "Epoch 20/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 176ms/step - accuracy: 1.0000 - loss: 0.0043 - val_accuracy: 0.9879 - val_loss: 0.0540 - learning_rate: 1.0000e-04\n",
      "Epoch 21/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 178ms/step - accuracy: 1.0000 - loss: 0.0010 - val_accuracy: 0.9890 - val_loss: 0.0450 - learning_rate: 1.0000e-04\n",
      "Epoch 22/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 171ms/step - accuracy: 1.0000 - loss: 7.8473e-04\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 177ms/step - accuracy: 1.0000 - loss: 6.5199e-04 - val_accuracy: 0.9879 - val_loss: 0.0465 - learning_rate: 1.0000e-04\n",
      "Epoch 23/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 176ms/step - accuracy: 1.0000 - loss: 4.6769e-04 - val_accuracy: 0.9901 - val_loss: 0.0446 - learning_rate: 5.0000e-05\n",
      "Epoch 24/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 180ms/step - accuracy: 1.0000 - loss: 4.8758e-04 - val_accuracy: 0.9901 - val_loss: 0.0453 - learning_rate: 5.0000e-05\n",
      "Epoch 25/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 176ms/step - accuracy: 1.0000 - loss: 3.5993e-04 - val_accuracy: 0.9879 - val_loss: 0.0451 - learning_rate: 5.0000e-05\n",
      "Epoch 26/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 185ms/step - accuracy: 1.0000 - loss: 3.9014e-04 - val_accuracy: 0.9923 - val_loss: 0.0407 - learning_rate: 5.0000e-05\n",
      "Epoch 27/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 176ms/step - accuracy: 1.0000 - loss: 3.1759e-04 - val_accuracy: 0.9901 - val_loss: 0.0431 - learning_rate: 5.0000e-05\n",
      "Epoch 28/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 175ms/step - accuracy: 1.0000 - loss: 2.8032e-04 - val_accuracy: 0.9901 - val_loss: 0.0412 - learning_rate: 5.0000e-05\n",
      "Epoch 29/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 184ms/step - accuracy: 1.0000 - loss: 2.9455e-04 - val_accuracy: 0.9901 - val_loss: 0.0402 - learning_rate: 5.0000e-05\n",
      "Epoch 30/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 175ms/step - accuracy: 1.0000 - loss: 2.5051e-04 - val_accuracy: 0.9912 - val_loss: 0.0419 - learning_rate: 5.0000e-05\n",
      "Epoch 31/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 177ms/step - accuracy: 1.0000 - loss: 2.5363e-04 - val_accuracy: 0.9890 - val_loss: 0.0447 - learning_rate: 5.0000e-05\n",
      "Epoch 32/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 176ms/step - accuracy: 1.0000 - loss: 2.4393e-04 - val_accuracy: 0.9901 - val_loss: 0.0418 - learning_rate: 5.0000e-05\n",
      "Epoch 33/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 175ms/step - accuracy: 1.0000 - loss: 1.9629e-04 - val_accuracy: 0.9901 - val_loss: 0.0424 - learning_rate: 5.0000e-05\n",
      "Epoch 34/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 171ms/step - accuracy: 1.0000 - loss: 2.2819e-04\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 177ms/step - accuracy: 1.0000 - loss: 2.1986e-04 - val_accuracy: 0.9901 - val_loss: 0.0442 - learning_rate: 5.0000e-05\n",
      "Epoch 35/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 174ms/step - accuracy: 1.0000 - loss: 2.4051e-04 - val_accuracy: 0.9890 - val_loss: 0.0434 - learning_rate: 2.5000e-05\n",
      "Epoch 36/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 177ms/step - accuracy: 1.0000 - loss: 2.1850e-04 - val_accuracy: 0.9912 - val_loss: 0.0415 - learning_rate: 2.5000e-05\n",
      "Epoch 37/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 176ms/step - accuracy: 1.0000 - loss: 2.3008e-04 - val_accuracy: 0.9912 - val_loss: 0.0422 - learning_rate: 2.5000e-05\n",
      "Epoch 38/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 175ms/step - accuracy: 1.0000 - loss: 1.9787e-04 - val_accuracy: 0.9912 - val_loss: 0.0422 - learning_rate: 2.5000e-05\n",
      "Epoch 39/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 171ms/step - accuracy: 1.0000 - loss: 2.5647e-04\n",
      "Epoch 39: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 177ms/step - accuracy: 1.0000 - loss: 2.3188e-04 - val_accuracy: 0.9890 - val_loss: 0.0440 - learning_rate: 2.5000e-05\n",
      "Epoch 40/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 174ms/step - accuracy: 1.0000 - loss: 1.7752e-04 - val_accuracy: 0.9901 - val_loss: 0.0434 - learning_rate: 1.2500e-05\n",
      "Epoch 41/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 176ms/step - accuracy: 1.0000 - loss: 1.8638e-04 - val_accuracy: 0.9912 - val_loss: 0.0436 - learning_rate: 1.2500e-05\n",
      "Epoch 42/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 176ms/step - accuracy: 1.0000 - loss: 1.6909e-04 - val_accuracy: 0.9912 - val_loss: 0.0438 - learning_rate: 1.2500e-05\n",
      "Epoch 43/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 175ms/step - accuracy: 1.0000 - loss: 1.8139e-04 - val_accuracy: 0.9890 - val_loss: 0.0444 - learning_rate: 1.2500e-05\n",
      "Epoch 44/150\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 172ms/step - accuracy: 1.0000 - loss: 1.6168e-04\n",
      "Epoch 44: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 178ms/step - accuracy: 1.0000 - loss: 1.6565e-04 - val_accuracy: 0.9901 - val_loss: 0.0440 - learning_rate: 1.2500e-05\n",
      "Epoch 44: early stopping\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "   > Acurácia Final Fold 6: 99.01%\n",
      "\n",
      "==============================\n",
      "Média Final de Acurácia: 98.99%\n",
      "O melhor modelo de todos os folds já está salvo como 'melhor_modelo_kfold.keras'\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "id": "244066648064edf9",
   "metadata": {},
   "source": [
    "Métricas mais avançadas com sklearn"
   ]
  },
  {
   "cell_type": "code",
   "id": "d07ced0d0e92e238",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-23T01:56:20.156264Z",
     "start_time": "2025-11-23T01:56:05.710596Z"
    }
   },
   "source": [
    "print(\"\\n--- Iniciando Avaliação por Ensemble (Soft Voting) ---\")\n",
    "\n",
    "ds_teste_final = criar_dataset_fold(X_teste, y_teste, training=False)\n",
    "\n",
    "y_verdadeiro = []\n",
    "for _, rotulos in ds_teste_final:\n",
    "    y_verdadeiro.extend(rotulos.numpy())\n",
    "y_verdadeiro = np.array(y_verdadeiro)\n",
    "\n",
    "soma_previsoes = None\n",
    "\n",
    "for i in range(1, NUM_FOLDS + 1):\n",
    "    nome_arquivo = f'modelo_fold_{i}.keras'\n",
    "    caminho_modelo = os.path.join(PASTA_FOLDS, nome_arquivo)\n",
    "\n",
    "    print(f\"Carregando: {caminho_modelo}\")\n",
    "    modelo = load_model(caminho_modelo, safe_mode=False)\n",
    "\n",
    "    pred_fold = modelo.predict(ds_teste_final, verbose=0)\n",
    "\n",
    "    if soma_previsoes is None:\n",
    "        soma_previsoes = pred_fold\n",
    "    else:\n",
    "        soma_previsoes += pred_fold\n",
    "\n",
    "    tf.keras.backend.clear_session()\n",
    "    gc.collect()\n",
    "\n",
    "previsoes_ensemble = soma_previsoes / NUM_FOLDS\n",
    "y_pred_ensemble = np.argmax(previsoes_ensemble, axis=1)\n",
    "\n",
    "classes = ['Mild', 'Mod', 'Non', 'VMild']\n",
    "print(\"\\nRelatório de Classificação (Ensemble):\")\n",
    "print(classification_report(y_verdadeiro, y_pred_ensemble, target_names=classes))\n",
    "\n",
    "cm = confusion_matrix(y_verdadeiro, y_pred_ensemble)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=classes)\n",
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "disp.plot(xticks_rotation=45, cmap='Blues', ax=ax)\n",
    "plt.title(f\"Matriz de Confusão (Ensemble {NUM_FOLDS} Folds)\")\n",
    "plt.show()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Iniciando Avaliação por Ensemble (Soft Voting) ---\n",
      "Carregando: Folds/modelo_fold_1.keras\n",
      "Carregando: Folds/modelo_fold_2.keras\n",
      "Carregando: Folds/modelo_fold_3.keras\n",
      "Carregando: Folds/modelo_fold_4.keras\n",
      "Carregando: Folds/modelo_fold_5.keras\n",
      "Carregando: Folds/modelo_fold_6.keras\n",
      "\n",
      "Relatório de Classificação (Ensemble):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Mild       0.99      1.00      1.00       134\n",
      "         Mod       1.00      1.00      1.00        10\n",
      "         Non       1.00      1.00      1.00       480\n",
      "       VMild       1.00      1.00      1.00       336\n",
      "\n",
      "    accuracy                           1.00       960\n",
      "   macro avg       1.00      1.00      1.00       960\n",
      "weighted avg       1.00      1.00      1.00       960\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 600x600 with 2 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 11
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
