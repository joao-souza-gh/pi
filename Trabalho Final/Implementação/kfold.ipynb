{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34db769b46dc074b",
   "metadata": {},
   "source": [
    "Autores: Alexandre Liermann, Gustavo Guerreiro e João Martinho."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be2e6c6ff29c0f12",
   "metadata": {},
   "source": [
    "# Implementação de Classificação de Imagens de Ressonância Magnética para Diagnóstico de Alzheimer Usando CNN em TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac8cbbfcc8dab30",
   "metadata": {},
   "source": [
    "Importações das bibliotecas necessárias"
   ]
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-11-23T02:42:40.305342Z",
     "start_time": "2025-11-23T02:42:37.858772Z"
    }
   },
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'\n",
    "os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
    "os.environ['TF_CUDNN_DETERMINISTIC'] = '1'\n",
    "os.environ['TF_CUDNN_BENCHMARK'] = 'false'\n",
    "\n",
    "import gc\n",
    "import glob\n",
    "import pathlib\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from tensorflow.data import AUTOTUNE\n",
    "from sklearn.utils import class_weight\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from tensorflow.keras import models, layers, mixed_precision, optimizers\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report\n"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Definindo constantes a serem usadas",
   "id": "386f7e8f62842b3d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-23T02:42:40.312226Z",
     "start_time": "2025-11-23T02:42:40.310123Z"
    }
   },
   "cell_type": "code",
   "source": [
    "IMG_ALTURA    = 176\n",
    "IMG_LARGURA   = 208\n",
    "TAMANHO_BATCH = 64\n",
    "\n",
    "SEED = 2025"
   ],
   "id": "518d9f32ec72f2d9",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-23T02:42:40.376062Z",
     "start_time": "2025-11-23T02:42:40.372656Z"
    }
   },
   "cell_type": "code",
   "source": [
    "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "tf.config.experimental.enable_op_determinism()\n",
    "\n",
    "print('Seed global definida:', SEED)"
   ],
   "id": "85df67e52d94296e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed global definida: 2025\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-23T02:42:41.250182Z",
     "start_time": "2025-11-23T02:42:40.422261Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def configurar_gpu():\n",
    "    try:\n",
    "        gpus = tf.config.list_physical_devices('GPU')\n",
    "        if gpus:\n",
    "            for gpu in gpus:\n",
    "                tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(f\"Erro ao configurar GPU: {e}\")\n",
    "\n",
    "mixed_precision.set_global_policy('mixed_float16')\n",
    "configurar_gpu()"
   ],
   "id": "66a81025563811c4",
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "id": "600a10a0d0a5d882",
   "metadata": {},
   "source": [
    "Definindo os diretórios do dataset"
   ]
  },
  {
   "cell_type": "code",
   "id": "574b5f8cb5bbebda",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-23T02:42:41.381292Z",
     "start_time": "2025-11-23T02:42:41.366043Z"
    }
   },
   "source": [
    "dir_dados = pathlib.Path('dataset')\n",
    "\n",
    "caminhos_arquivos = []\n",
    "rotulos = []\n",
    "nomes_classes = sorted([item.name for item in dir_dados.glob('*') if item.is_dir()])\n",
    "dict_classes = {nome: i for i, nome in enumerate(nomes_classes)}\n",
    "\n",
    "for nome_classe in nomes_classes:\n",
    "    padrao = str(dir_dados / nome_classe / '*')\n",
    "    arquivos = glob.glob(padrao)\n",
    "    caminhos_arquivos.extend(arquivos)\n",
    "    rotulos.extend([dict_classes[nome_classe]] * len(arquivos))\n",
    "\n",
    "caminhos_arquivos = np.array(caminhos_arquivos)\n",
    "rotulos = np.array(rotulos)\n",
    "\n",
    "X_restante, X_teste, y_restante, y_teste = train_test_split(\n",
    "    caminhos_arquivos, rotulos, test_size=0.15, stratify=rotulos, random_state=SEED\n",
    ")\n",
    "\n",
    "print(f\"Total para K-Fold (Treino+Val): {len(X_restante)}\")\n",
    "print(f\"Reservado para Teste Final: {len(X_teste)}\")\n",
    "\n",
    "def processar_arquivo(caminho, rotulo):\n",
    "    arquivo = tf.io.read_file(caminho)\n",
    "    img = tf.io.decode_image(arquivo, channels=1, expand_animations=False)\n",
    "    img = tf.image.resize(img, [IMG_ALTURA, IMG_LARGURA])\n",
    "    img = tf.cast(img, tf.float32)\n",
    "    return img, rotulo\n",
    "\n",
    "def criar_dataset_fold(caminhos, labels_fold, training=True):\n",
    "    ds = tf.data.Dataset.from_tensor_slices((caminhos, labels_fold))\n",
    "    ds = ds.map(processar_arquivo, num_parallel_calls=AUTOTUNE)\n",
    "    if training:\n",
    "        ds = ds.shuffle(len(caminhos), seed=SEED)\n",
    "    ds = ds.batch(TAMANHO_BATCH)\n",
    "    ds = ds.prefetch(AUTOTUNE)\n",
    "    return ds"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total para K-Fold (Treino+Val): 5440\n",
      "Reservado para Teste Final: 960\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "id": "c10f856f8906ca88",
   "metadata": {},
   "source": [
    "Iniciando a configuração do modelo."
   ]
  },
  {
   "cell_type": "code",
   "id": "f5ccf6c7ee895123",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-23T02:42:41.426391Z",
     "start_time": "2025-11-23T02:42:41.422005Z"
    }
   },
   "source": [
    "@tf.keras.utils.register_keras_serializable()\n",
    "def converter_para_cinza_gpu(x):\n",
    "    return tf.image.rgb_to_grayscale(x)\n",
    "\n",
    "def construir_modelo():\n",
    "    tf.keras.backend.clear_session()\n",
    "    gc.collect()\n",
    "\n",
    "    modelo = models.Sequential([\n",
    "        layers.Input(shape=(IMG_ALTURA, IMG_LARGURA, 1)),\n",
    "\n",
    "        layers.Conv2D(32, (3, 3), padding='same', use_bias=False),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Activation('relu'),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "        layers.Conv2D(64, (3, 3), padding='same', use_bias=False),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Activation('relu'),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "        layers.Conv2D(128, (3, 3), padding='same', use_bias=False),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Activation('relu'),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "        layers.Conv2D(256, (3, 3), padding='same', use_bias=False),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Activation('relu'),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(512, use_bias=False),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Activation('relu'),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(4, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    opt = optimizers.Adam(learning_rate=1e-4, clipnorm=1.0)\n",
    "    modelo.compile(\n",
    "        optimizer=opt,\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return modelo"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "id": "65c22eef320f53",
   "metadata": {},
   "source": [
    "Definindo callback de EarlyStopping."
   ]
  },
  {
   "cell_type": "code",
   "id": "a3c2dcaa662703db",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-23T02:42:41.483154Z",
     "start_time": "2025-11-23T02:42:41.480502Z"
    }
   },
   "source": [
    "def obter_callbacks(caminho_modelo):\n",
    "    early_stop = EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=15,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    reduce_le = ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.5,\n",
    "        patience=3,\n",
    "        min_lr=1e-7,\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    checkpoint = ModelCheckpoint(\n",
    "        caminho_modelo,\n",
    "        monitor='val_loss',\n",
    "        save_best_only=True,\n",
    "        mode='min',\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    return [early_stop, reduce_le, checkpoint]"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Colocando pesos nas classes a fim de diminuir falsos negativos (melhorar Recall).",
   "id": "4eb1c1381c6dfde5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-23T02:42:41.544325Z",
     "start_time": "2025-11-23T02:42:41.541429Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def ajustar_pesos(rotulos_treino):\n",
    "    pesos_base = class_weight.compute_class_weight(\n",
    "        class_weight='balanced',\n",
    "        classes=np.unique(rotulos_treino),\n",
    "        y=rotulos_treino\n",
    "    )\n",
    "\n",
    "    pesos_dict = dict(enumerate(pesos_base))\n",
    "    fator_rigor = 2\n",
    "    indice_saudavel = 2\n",
    "    for classe, peso in pesos_dict.items():\n",
    "        if classe != indice_saudavel:\n",
    "            pesos_dict[classe] = peso * fator_rigor\n",
    "            if classe == 1:\n",
    "                 pesos_dict[classe] *= 1.5\n",
    "\n",
    "    print(\"Pesos das classes:\", pesos_dict)\n",
    "    return pesos_dict"
   ],
   "id": "93a46dcba63ffb05",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-23T02:42:41.599410Z",
     "start_time": "2025-11-23T02:42:41.596608Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def avaliar_fold(modelo, ds_val, melhor_acc_atual):\n",
    "    scores = modelo.evaluate(ds_val, verbose=0)\n",
    "    acuracia_fold = scores[1]\n",
    "    loss_fold = scores[0]\n",
    "    print(f\"   > Acurácia Validação: {acuracia_fold*100:.2f}% (Loss: {loss_fold:.4f})\")\n",
    "    nova_melhor_acc = melhor_acc_atual\n",
    "\n",
    "    if acuracia_fold > melhor_acc_atual:\n",
    "        nova_melhor_acc = acuracia_fold\n",
    "        print(f\"   > Novo recorde! (Anterior: {melhor_acc_atual*100:.2f}%) -> Salvando modelo...\")\n",
    "        modelo.save('melhor_modelo_kfold.keras')\n",
    "\n",
    "    return acuracia_fold, nova_melhor_acc"
   ],
   "id": "ac909483fa01608c",
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "id": "b33d08c37fe1c743",
   "metadata": {},
   "source": [
    "Treinando o modelo"
   ]
  },
  {
   "cell_type": "code",
   "id": "fc08b5bfb9113d51",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-23T03:28:27.624225Z",
     "start_time": "2025-11-23T02:42:41.658740Z"
    }
   },
   "source": [
    "PASTA_FOLDS = \"Folds\"\n",
    "os.makedirs(PASTA_FOLDS, exist_ok=True)\n",
    "\n",
    "NUM_FOLDS = 5\n",
    "skf = StratifiedKFold(n_splits=NUM_FOLDS, shuffle=True, random_state=SEED)\n",
    "resultados_acuracia = []\n",
    "\n",
    "print(f\"Iniciando Treinamento com {NUM_FOLDS} Folds...\\n\")\n",
    "\n",
    "fold_atual = 1\n",
    "for idx_treino, idx_val in skf.split(X_restante, y_restante):\n",
    "    print(f\"--- Rodando Fold {fold_atual}/{NUM_FOLDS} ---\")\n",
    "\n",
    "    X_treino_f, X_val_f = X_restante[idx_treino], X_restante[idx_val]\n",
    "    y_treino_f, y_val_f = y_restante[idx_treino], y_restante[idx_val]\n",
    "\n",
    "    ds_treino = criar_dataset_fold(X_treino_f, y_treino_f, training=True)\n",
    "    ds_val = criar_dataset_fold(X_val_f, y_val_f, training=False)\n",
    "\n",
    "    pesos = ajustar_pesos(y_treino_f)\n",
    "    modelo_fold = construir_modelo()\n",
    "\n",
    "    nome_arquivo = f'modelo_fold_{fold_atual}.keras'\n",
    "    caminho_modelo = os.path.join(PASTA_FOLDS, nome_arquivo)\n",
    "\n",
    "    callbacks_list = obter_callbacks(caminho_modelo)\n",
    "\n",
    "    history = modelo_fold.fit(\n",
    "        ds_treino,\n",
    "        validation_data=ds_val,\n",
    "        epochs=150,\n",
    "        callbacks=callbacks_list,\n",
    "        class_weight=pesos\n",
    "    )\n",
    "\n",
    "    modelo_fold.load_weights(caminho_modelo)\n",
    "    scores = modelo_fold.evaluate(ds_val, verbose=0)\n",
    "    print(f\"   > Acurácia Final Fold {fold_atual}: {scores[1]*100:.2f}%\")\n",
    "    resultados_acuracia.append(scores[1])\n",
    "\n",
    "    del ds_treino, ds_val, modelo_fold\n",
    "    tf.keras.backend.clear_session()\n",
    "    gc.collect()\n",
    "\n",
    "    fold_atual += 1\n",
    "\n",
    "print(\"\\n\" + \"=\"*30)\n",
    "print(f\"Média Final de Acurácia: {np.mean(resultados_acuracia)*100:.2f}%\")\n",
    "print(\"O melhor modelo de todos os folds já está salvo como 'melhor_modelo_kfold.keras'\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando Treinamento com 5 Folds...\n",
      "\n",
      "--- Rodando Fold 1/5 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1763865761.869969  349014 gpu_device.cc:2020] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5563 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pesos das classes: {0: np.float64(3.5730706075533663), 1: np.float64(74.18181818181819), 2: np.float64(0.5), 3: np.float64(1.4287590282337492)}\n",
      "Epoch 1/150\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m17s\u001B[0m 184ms/step - accuracy: 0.5538 - loss: 1.8427 - val_accuracy: 0.6158 - val_loss: 0.8845 - learning_rate: 1.0000e-04\n",
      "Epoch 2/150\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 175ms/step - accuracy: 0.8405 - loss: 0.3941 - val_accuracy: 0.5533 - val_loss: 0.8919 - learning_rate: 1.0000e-04\n",
      "Epoch 3/150\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 182ms/step - accuracy: 0.9563 - loss: 0.1232 - val_accuracy: 0.7849 - val_loss: 0.5133 - learning_rate: 1.0000e-04\n",
      "Epoch 4/150\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 173ms/step - accuracy: 0.9878 - loss: 0.0471 - val_accuracy: 0.6471 - val_loss: 1.0847 - learning_rate: 1.0000e-04\n",
      "Epoch 5/150\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 183ms/step - accuracy: 0.9968 - loss: 0.0208 - val_accuracy: 0.9715 - val_loss: 0.1105 - learning_rate: 1.0000e-04\n",
      "Epoch 6/150\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 175ms/step - accuracy: 0.9984 - loss: 0.0107 - val_accuracy: 0.9632 - val_loss: 0.1197 - learning_rate: 1.0000e-04\n",
      "Epoch 7/150\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 176ms/step - accuracy: 0.9995 - loss: 0.0067 - val_accuracy: 0.9642 - val_loss: 0.1353 - learning_rate: 1.0000e-04\n",
      "Epoch 8/150\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m21s\u001B[0m 180ms/step - accuracy: 0.9998 - loss: 0.0039 - val_accuracy: 0.9816 - val_loss: 0.0657 - learning_rate: 1.0000e-04\n",
      "Epoch 9/150\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 179ms/step - accuracy: 1.0000 - loss: 0.0029 - val_accuracy: 0.9825 - val_loss: 0.0652 - learning_rate: 1.0000e-04\n",
      "Epoch 10/150\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 184ms/step - accuracy: 1.0000 - loss: 0.0020 - val_accuracy: 0.9871 - val_loss: 0.0412 - learning_rate: 1.0000e-04\n",
      "Epoch 11/150\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 172ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 0.9835 - val_loss: 0.0456 - learning_rate: 1.0000e-04\n",
      "Epoch 12/150\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 175ms/step - accuracy: 1.0000 - loss: 0.0010 - val_accuracy: 0.9853 - val_loss: 0.0422 - learning_rate: 1.0000e-04\n",
      "Epoch 13/150\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 176ms/step - accuracy: 1.0000 - loss: 8.4032e-04 - val_accuracy: 0.9853 - val_loss: 0.0468 - learning_rate: 1.0000e-04\n",
      "Epoch 14/150\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 173ms/step - accuracy: 1.0000 - loss: 6.3098e-04 - val_accuracy: 0.9853 - val_loss: 0.0473 - learning_rate: 1.0000e-04\n",
      "Epoch 15/150\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 169ms/step - accuracy: 1.0000 - loss: 7.3578e-04\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 176ms/step - accuracy: 1.0000 - loss: 7.5296e-04 - val_accuracy: 0.9862 - val_loss: 0.0435 - learning_rate: 1.0000e-04\n",
      "Epoch 16/150\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 184ms/step - accuracy: 1.0000 - loss: 6.2708e-04 - val_accuracy: 0.9871 - val_loss: 0.0396 - learning_rate: 5.0000e-05\n",
      "Epoch 17/150\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 184ms/step - accuracy: 1.0000 - loss: 5.3930e-04 - val_accuracy: 0.9881 - val_loss: 0.0377 - learning_rate: 5.0000e-05\n",
      "Epoch 18/150\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 176ms/step - accuracy: 1.0000 - loss: 3.9904e-04 - val_accuracy: 0.9881 - val_loss: 0.0382 - learning_rate: 5.0000e-05\n",
      "Epoch 19/150\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 171ms/step - accuracy: 1.0000 - loss: 4.7038e-04 - val_accuracy: 0.9899 - val_loss: 0.0395 - learning_rate: 5.0000e-05\n",
      "Epoch 20/150\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 173ms/step - accuracy: 1.0000 - loss: 5.2097e-04 - val_accuracy: 0.9871 - val_loss: 0.0414 - learning_rate: 5.0000e-05\n",
      "Epoch 21/150\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 172ms/step - accuracy: 1.0000 - loss: 4.1305e-04 - val_accuracy: 0.9862 - val_loss: 0.0403 - learning_rate: 5.0000e-05\n",
      "Epoch 22/150\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 164ms/step - accuracy: 1.0000 - loss: 3.9888e-04\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 179ms/step - accuracy: 1.0000 - loss: 4.3726e-04 - val_accuracy: 0.9871 - val_loss: 0.0377 - learning_rate: 5.0000e-05\n",
      "Epoch 23/150\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 184ms/step - accuracy: 1.0000 - loss: 3.9701e-04 - val_accuracy: 0.9871 - val_loss: 0.0375 - learning_rate: 2.5000e-05\n",
      "Epoch 24/150\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 172ms/step - accuracy: 1.0000 - loss: 4.0878e-04 - val_accuracy: 0.9862 - val_loss: 0.0405 - learning_rate: 2.5000e-05\n",
      "Epoch 25/150\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 174ms/step - accuracy: 1.0000 - loss: 3.7788e-04 - val_accuracy: 0.9871 - val_loss: 0.0381 - learning_rate: 2.5000e-05\n",
      "Epoch 26/150\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 175ms/step - accuracy: 1.0000 - loss: 3.5993e-04 - val_accuracy: 0.9871 - val_loss: 0.0380 - learning_rate: 2.5000e-05\n",
      "Epoch 27/150\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 175ms/step - accuracy: 1.0000 - loss: 3.9985e-04 - val_accuracy: 0.9853 - val_loss: 0.0415 - learning_rate: 2.5000e-05\n",
      "Epoch 28/150\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 170ms/step - accuracy: 1.0000 - loss: 3.0719e-04\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 177ms/step - accuracy: 1.0000 - loss: 3.7035e-04 - val_accuracy: 0.9871 - val_loss: 0.0380 - learning_rate: 2.5000e-05\n",
      "Epoch 29/150\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 180ms/step - accuracy: 1.0000 - loss: 3.6692e-04 - val_accuracy: 0.9871 - val_loss: 0.0371 - learning_rate: 1.2500e-05\n",
      "Epoch 30/150\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 172ms/step - accuracy: 1.0000 - loss: 4.0100e-04 - val_accuracy: 0.9871 - val_loss: 0.0378 - learning_rate: 1.2500e-05\n",
      "Epoch 31/150\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 178ms/step - accuracy: 1.0000 - loss: 2.9575e-04 - val_accuracy: 0.9871 - val_loss: 0.0378 - learning_rate: 1.2500e-05\n",
      "Epoch 32/150\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 175ms/step - accuracy: 1.0000 - loss: 3.5987e-04 - val_accuracy: 0.9881 - val_loss: 0.0374 - learning_rate: 1.2500e-05\n",
      "Epoch 33/150\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 183ms/step - accuracy: 1.0000 - loss: 2.8115e-04 - val_accuracy: 0.9871 - val_loss: 0.0370 - learning_rate: 1.2500e-05\n",
      "Epoch 34/150\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 168ms/step - accuracy: 1.0000 - loss: 3.4818e-04\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 175ms/step - accuracy: 1.0000 - loss: 2.9976e-04 - val_accuracy: 0.9871 - val_loss: 0.0378 - learning_rate: 1.2500e-05\n",
      "Epoch 35/150\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 173ms/step - accuracy: 1.0000 - loss: 2.8253e-04 - val_accuracy: 0.9871 - val_loss: 0.0378 - learning_rate: 6.2500e-06\n",
      "Epoch 36/150\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 177ms/step - accuracy: 1.0000 - loss: 3.3129e-04 - val_accuracy: 0.9871 - val_loss: 0.0380 - learning_rate: 6.2500e-06\n",
      "Epoch 37/150\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 175ms/step - accuracy: 1.0000 - loss: 2.5878e-04 - val_accuracy: 0.9871 - val_loss: 0.0380 - learning_rate: 6.2500e-06\n",
      "Epoch 38/150\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 175ms/step - accuracy: 1.0000 - loss: 3.1819e-04 - val_accuracy: 0.9871 - val_loss: 0.0381 - learning_rate: 6.2500e-06\n",
      "Epoch 39/150\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 169ms/step - accuracy: 1.0000 - loss: 3.1105e-04\n",
      "Epoch 39: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 176ms/step - accuracy: 1.0000 - loss: 3.6139e-04 - val_accuracy: 0.9871 - val_loss: 0.0386 - learning_rate: 6.2500e-06\n",
      "Epoch 40/150\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 173ms/step - accuracy: 1.0000 - loss: 2.9952e-04 - val_accuracy: 0.9871 - val_loss: 0.0385 - learning_rate: 3.1250e-06\n",
      "Epoch 41/150\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 176ms/step - accuracy: 1.0000 - loss: 2.7098e-04 - val_accuracy: 0.9871 - val_loss: 0.0384 - learning_rate: 3.1250e-06\n",
      "Epoch 42/150\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 176ms/step - accuracy: 1.0000 - loss: 2.6893e-04 - val_accuracy: 0.9871 - val_loss: 0.0384 - learning_rate: 3.1250e-06\n",
      "Epoch 43/150\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 175ms/step - accuracy: 1.0000 - loss: 3.0343e-04 - val_accuracy: 0.9871 - val_loss: 0.0382 - learning_rate: 3.1250e-06\n",
      "Epoch 44/150\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 172ms/step - accuracy: 1.0000 - loss: 2.6698e-04\n",
      "Epoch 44: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 179ms/step - accuracy: 1.0000 - loss: 2.6509e-04 - val_accuracy: 0.9871 - val_loss: 0.0383 - learning_rate: 3.1250e-06\n",
      "Epoch 45/150\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 175ms/step - accuracy: 1.0000 - loss: 2.8623e-04 - val_accuracy: 0.9871 - val_loss: 0.0384 - learning_rate: 1.5625e-06\n",
      "Epoch 46/150\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 177ms/step - accuracy: 1.0000 - loss: 3.1212e-04 - val_accuracy: 0.9871 - val_loss: 0.0383 - learning_rate: 1.5625e-06\n",
      "Epoch 47/150\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 175ms/step - accuracy: 1.0000 - loss: 2.7745e-04 - val_accuracy: 0.9871 - val_loss: 0.0383 - learning_rate: 1.5625e-06\n",
      "Epoch 48/150\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 172ms/step - accuracy: 1.0000 - loss: 2.6827e-04 - val_accuracy: 0.9871 - val_loss: 0.0386 - learning_rate: 1.5625e-06\n",
      "Epoch 48: early stopping\n",
      "Restoring model weights from the end of the best epoch: 33.\n",
      "   > Acurácia Final Fold 1: 98.71%\n",
      "--- Rodando Fold 2/5 ---\n",
      "Pesos das classes: {0: np.float64(3.5672131147540984), 1: np.float64(75.90697674418604), 2: np.float64(0.5), 3: np.float64(1.4287590282337492)}\n",
      "Epoch 1/150\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m15s\u001B[0m 185ms/step - accuracy: 0.5432 - loss: 1.6869 - val_accuracy: 0.5294 - val_loss: 1.4116 - learning_rate: 1.0000e-04\n",
      "Epoch 2/150\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 183ms/step - accuracy: 0.8415 - loss: 0.3646 - val_accuracy: 0.5855 - val_loss: 0.7600 - learning_rate: 1.0000e-04\n",
      "Epoch 3/150\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 183ms/step - accuracy: 0.9648 - loss: 0.1025 - val_accuracy: 0.8704 - val_loss: 0.3798 - learning_rate: 1.0000e-04\n",
      "Epoch 4/150\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 186ms/step - accuracy: 0.9906 - loss: 0.0406 - val_accuracy: 0.9476 - val_loss: 0.1894 - learning_rate: 1.0000e-04\n",
      "Epoch 5/150\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 182ms/step - accuracy: 0.9982 - loss: 0.0169 - val_accuracy: 0.9669 - val_loss: 0.1215 - learning_rate: 1.0000e-04\n",
      "Epoch 6/150\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 184ms/step - accuracy: 0.9989 - loss: 0.0105 - val_accuracy: 0.9761 - val_loss: 0.0952 - learning_rate: 1.0000e-04\n",
      "Epoch 7/150\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 194ms/step - accuracy: 1.0000 - loss: 0.0054 - val_accuracy: 0.9807 - val_loss: 0.0550 - learning_rate: 1.0000e-04\n",
      "Epoch 8/150\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 174ms/step - accuracy: 0.9995 - loss: 0.0048 - val_accuracy: 0.9733 - val_loss: 0.0906 - learning_rate: 1.0000e-04\n",
      "Epoch 9/150\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 175ms/step - accuracy: 1.0000 - loss: 0.0034 - val_accuracy: 0.9017 - val_loss: 0.2300 - learning_rate: 1.0000e-04\n",
      "Epoch 10/150\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 179ms/step - accuracy: 1.0000 - loss: 0.0021 - val_accuracy: 0.9871 - val_loss: 0.0472 - learning_rate: 1.0000e-04\n",
      "Epoch 11/150\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 187ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 0.9871 - val_loss: 0.0401 - learning_rate: 1.0000e-04\n",
      "Epoch 12/150\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 173ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 0.9761 - val_loss: 0.0677 - learning_rate: 1.0000e-04\n",
      "Epoch 13/150\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 188ms/step - accuracy: 1.0000 - loss: 8.6803e-04 - val_accuracy: 0.9890 - val_loss: 0.0357 - learning_rate: 1.0000e-04\n",
      "Epoch 14/150\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 176ms/step - accuracy: 1.0000 - loss: 6.3636e-04 - val_accuracy: 0.9853 - val_loss: 0.0462 - learning_rate: 1.0000e-04\n",
      "Epoch 15/150\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 174ms/step - accuracy: 1.0000 - loss: 5.5725e-04 - val_accuracy: 0.9881 - val_loss: 0.0363 - learning_rate: 1.0000e-04\n",
      "Epoch 16/150\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 187ms/step - accuracy: 1.0000 - loss: 4.8327e-04 - val_accuracy: 0.9890 - val_loss: 0.0332 - learning_rate: 1.0000e-04\n",
      "Epoch 17/150\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 174ms/step - accuracy: 1.0000 - loss: 5.0556e-04 - val_accuracy: 0.9899 - val_loss: 0.0376 - learning_rate: 1.0000e-04\n",
      "Epoch 18/150\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 173ms/step - accuracy: 1.0000 - loss: 4.9058e-04 - val_accuracy: 0.9890 - val_loss: 0.0356 - learning_rate: 1.0000e-04\n",
      "Epoch 19/150\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m21s\u001B[0m 173ms/step - accuracy: 1.0000 - loss: 4.8278e-04 - val_accuracy: 0.9899 - val_loss: 0.0361 - learning_rate: 1.0000e-04\n",
      "Epoch 20/150\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 182ms/step - accuracy: 1.0000 - loss: 3.5333e-04 - val_accuracy: 0.9890 - val_loss: 0.0319 - learning_rate: 1.0000e-04\n",
      "Epoch 21/150\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 176ms/step - accuracy: 1.0000 - loss: 3.7436e-04 - val_accuracy: 0.9899 - val_loss: 0.0338 - learning_rate: 1.0000e-04\n",
      "Epoch 22/150\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 173ms/step - accuracy: 1.0000 - loss: 3.3037e-04 - val_accuracy: 0.9899 - val_loss: 0.0381 - learning_rate: 1.0000e-04\n",
      "Epoch 23/150\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 176ms/step - accuracy: 1.0000 - loss: 3.5171e-04 - val_accuracy: 0.9899 - val_loss: 0.0342 - learning_rate: 1.0000e-04\n",
      "Epoch 24/150\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 174ms/step - accuracy: 1.0000 - loss: 2.6367e-04 - val_accuracy: 0.9908 - val_loss: 0.0326 - learning_rate: 1.0000e-04\n",
      "Epoch 25/150\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 167ms/step - accuracy: 1.0000 - loss: 3.2410e-04\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 174ms/step - accuracy: 1.0000 - loss: 2.5879e-04 - val_accuracy: 0.9899 - val_loss: 0.0353 - learning_rate: 1.0000e-04\n",
      "Epoch 26/150\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 177ms/step - accuracy: 1.0000 - loss: 2.7209e-04 - val_accuracy: 0.9899 - val_loss: 0.0351 - learning_rate: 5.0000e-05\n",
      "Epoch 27/150\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 174ms/step - accuracy: 1.0000 - loss: 2.3368e-04 - val_accuracy: 0.9908 - val_loss: 0.0328 - learning_rate: 5.0000e-05\n",
      "Epoch 28/150\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 174ms/step - accuracy: 1.0000 - loss: 2.2312e-04 - val_accuracy: 0.9908 - val_loss: 0.0324 - learning_rate: 5.0000e-05\n",
      "Epoch 29/150\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 175ms/step - accuracy: 1.0000 - loss: 2.2538e-04 - val_accuracy: 0.9899 - val_loss: 0.0320 - learning_rate: 5.0000e-05\n",
      "Epoch 30/150\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 166ms/step - accuracy: 1.0000 - loss: 1.9539e-04\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 173ms/step - accuracy: 1.0000 - loss: 2.1130e-04 - val_accuracy: 0.9899 - val_loss: 0.0339 - learning_rate: 5.0000e-05\n",
      "Epoch 31/150\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 185ms/step - accuracy: 1.0000 - loss: 2.1167e-04 - val_accuracy: 0.9890 - val_loss: 0.0319 - learning_rate: 2.5000e-05\n",
      "Epoch 32/150\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 181ms/step - accuracy: 1.0000 - loss: 2.1343e-04 - val_accuracy: 0.9899 - val_loss: 0.0317 - learning_rate: 2.5000e-05\n",
      "Epoch 33/150\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 182ms/step - accuracy: 1.0000 - loss: 1.9050e-04 - val_accuracy: 0.9899 - val_loss: 0.0315 - learning_rate: 2.5000e-05\n",
      "Epoch 34/150\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 186ms/step - accuracy: 1.0000 - loss: 1.8625e-04 - val_accuracy: 0.9899 - val_loss: 0.0314 - learning_rate: 2.5000e-05\n",
      "Epoch 35/150\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 183ms/step - accuracy: 1.0000 - loss: 1.7732e-04 - val_accuracy: 0.9890 - val_loss: 0.0308 - learning_rate: 2.5000e-05\n",
      "Epoch 36/150\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 187ms/step - accuracy: 1.0000 - loss: 2.1787e-04 - val_accuracy: 0.9899 - val_loss: 0.0297 - learning_rate: 2.5000e-05\n",
      "Epoch 37/150\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 175ms/step - accuracy: 1.0000 - loss: 1.6777e-04 - val_accuracy: 0.9908 - val_loss: 0.0299 - learning_rate: 2.5000e-05\n",
      "Epoch 38/150\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 175ms/step - accuracy: 1.0000 - loss: 1.8905e-04 - val_accuracy: 0.9899 - val_loss: 0.0312 - learning_rate: 2.5000e-05\n",
      "Epoch 39/150\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 181ms/step - accuracy: 1.0000 - loss: 1.7389e-04 - val_accuracy: 0.9899 - val_loss: 0.0314 - learning_rate: 2.5000e-05\n",
      "Epoch 40/150\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 175ms/step - accuracy: 1.0000 - loss: 1.6380e-04 - val_accuracy: 0.9899 - val_loss: 0.0320 - learning_rate: 2.5000e-05\n",
      "Epoch 41/150\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 167ms/step - accuracy: 1.0000 - loss: 2.0439e-04\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 175ms/step - accuracy: 1.0000 - loss: 1.7506e-04 - val_accuracy: 0.9899 - val_loss: 0.0307 - learning_rate: 2.5000e-05\n",
      "Epoch 42/150\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 175ms/step - accuracy: 1.0000 - loss: 1.8056e-04 - val_accuracy: 0.9899 - val_loss: 0.0303 - learning_rate: 1.2500e-05\n",
      "Epoch 43/150\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 172ms/step - accuracy: 1.0000 - loss: 1.7069e-04 - val_accuracy: 0.9908 - val_loss: 0.0302 - learning_rate: 1.2500e-05\n",
      "Epoch 44/150\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 190ms/step - accuracy: 1.0000 - loss: 1.7913e-04 - val_accuracy: 0.9908 - val_loss: 0.0297 - learning_rate: 1.2500e-05\n",
      "Epoch 45/150\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 174ms/step - accuracy: 1.0000 - loss: 1.3484e-04 - val_accuracy: 0.9908 - val_loss: 0.0303 - learning_rate: 1.2500e-05\n",
      "Epoch 46/150\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 167ms/step - accuracy: 1.0000 - loss: 1.4795e-04\n",
      "Epoch 46: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 174ms/step - accuracy: 1.0000 - loss: 1.5987e-04 - val_accuracy: 0.9899 - val_loss: 0.0300 - learning_rate: 1.2500e-05\n",
      "Epoch 47/150\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 180ms/step - accuracy: 1.0000 - loss: 1.4328e-04 - val_accuracy: 0.9899 - val_loss: 0.0302 - learning_rate: 6.2500e-06\n",
      "Epoch 48/150\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 175ms/step - accuracy: 1.0000 - loss: 1.9174e-04 - val_accuracy: 0.9899 - val_loss: 0.0299 - learning_rate: 6.2500e-06\n",
      "Epoch 49/150\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 175ms/step - accuracy: 1.0000 - loss: 1.8087e-04 - val_accuracy: 0.9899 - val_loss: 0.0304 - learning_rate: 6.2500e-06\n",
      "Epoch 50/150\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 176ms/step - accuracy: 1.0000 - loss: 1.6346e-04 - val_accuracy: 0.9908 - val_loss: 0.0308 - learning_rate: 6.2500e-06\n",
      "Epoch 51/150\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 171ms/step - accuracy: 1.0000 - loss: 1.6299e-04\n",
      "Epoch 51: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 178ms/step - accuracy: 1.0000 - loss: 1.5467e-04 - val_accuracy: 0.9899 - val_loss: 0.0302 - learning_rate: 6.2500e-06\n",
      "Epoch 52/150\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 183ms/step - accuracy: 1.0000 - loss: 1.6772e-04 - val_accuracy: 0.9899 - val_loss: 0.0298 - learning_rate: 3.1250e-06\n",
      "Epoch 53/150\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 175ms/step - accuracy: 1.0000 - loss: 1.3520e-04 - val_accuracy: 0.9899 - val_loss: 0.0298 - learning_rate: 3.1250e-06\n",
      "Epoch 54/150\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 175ms/step - accuracy: 1.0000 - loss: 1.4419e-04 - val_accuracy: 0.9899 - val_loss: 0.0300 - learning_rate: 3.1250e-06\n",
      "Epoch 55/150\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 176ms/step - accuracy: 1.0000 - loss: 1.7165e-04 - val_accuracy: 0.9899 - val_loss: 0.0301 - learning_rate: 3.1250e-06\n",
      "Epoch 56/150\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 166ms/step - accuracy: 1.0000 - loss: 1.5908e-04\n",
      "Epoch 56: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 173ms/step - accuracy: 1.0000 - loss: 1.5650e-04 - val_accuracy: 0.9899 - val_loss: 0.0300 - learning_rate: 3.1250e-06\n",
      "Epoch 57/150\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 176ms/step - accuracy: 1.0000 - loss: 1.6537e-04 - val_accuracy: 0.9899 - val_loss: 0.0301 - learning_rate: 1.5625e-06\n",
      "Epoch 58/150\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 174ms/step - accuracy: 1.0000 - loss: 1.3627e-04 - val_accuracy: 0.9899 - val_loss: 0.0301 - learning_rate: 1.5625e-06\n",
      "Epoch 59/150\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 172ms/step - accuracy: 1.0000 - loss: 1.4546e-04 - val_accuracy: 0.9899 - val_loss: 0.0301 - learning_rate: 1.5625e-06\n",
      "Epoch 59: early stopping\n",
      "Restoring model weights from the end of the best epoch: 44.\n",
      "   > Acurácia Final Fold 2: 99.08%\n",
      "--- Rodando Fold 3/5 ---\n",
      "Pesos das classes: {0: np.float64(3.5672131147540984), 1: np.float64(75.90697674418604), 2: np.float64(0.5), 3: np.float64(1.4287590282337492)}\n",
      "Epoch 1/150\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m15s\u001B[0m 187ms/step - accuracy: 0.5101 - loss: 2.0691 - val_accuracy: 0.3070 - val_loss: 1.6899 - learning_rate: 1.0000e-04\n",
      "Epoch 2/150\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 181ms/step - accuracy: 0.8557 - loss: 0.3716 - val_accuracy: 0.5312 - val_loss: 1.0705 - learning_rate: 1.0000e-04\n",
      "Epoch 3/150\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 183ms/step - accuracy: 0.9637 - loss: 0.1081 - val_accuracy: 0.8603 - val_loss: 0.3654 - learning_rate: 1.0000e-04\n",
      "Epoch 4/150\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 180ms/step - accuracy: 0.9892 - loss: 0.0415 - val_accuracy: 0.9127 - val_loss: 0.2610 - learning_rate: 1.0000e-04\n",
      "Epoch 5/150\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m21s\u001B[0m 184ms/step - accuracy: 0.9975 - loss: 0.0187 - val_accuracy: 0.9338 - val_loss: 0.1613 - learning_rate: 1.0000e-04\n",
      "Epoch 6/150\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 181ms/step - accuracy: 0.9995 - loss: 0.0079 - val_accuracy: 0.9779 - val_loss: 0.0809 - learning_rate: 1.0000e-04\n",
      "Epoch 7/150\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 175ms/step - accuracy: 0.9998 - loss: 0.0042 - val_accuracy: 0.9375 - val_loss: 0.1758 - learning_rate: 1.0000e-04\n",
      "Epoch 8/150\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 181ms/step - accuracy: 1.0000 - loss: 0.0024 - val_accuracy: 0.9862 - val_loss: 0.0624 - learning_rate: 1.0000e-04\n",
      "Epoch 9/150\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 182ms/step - accuracy: 1.0000 - loss: 0.0021 - val_accuracy: 0.9899 - val_loss: 0.0418 - learning_rate: 1.0000e-04\n",
      "Epoch 10/150\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 177ms/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 0.9881 - val_loss: 0.0418 - learning_rate: 1.0000e-04\n",
      "Epoch 11/150\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 173ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.9899 - val_loss: 0.0434 - learning_rate: 1.0000e-04\n",
      "Epoch 12/150\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 181ms/step - accuracy: 1.0000 - loss: 9.0305e-04 - val_accuracy: 0.9908 - val_loss: 0.0377 - learning_rate: 1.0000e-04\n",
      "Epoch 13/150\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 185ms/step - accuracy: 1.0000 - loss: 7.3380e-04 - val_accuracy: 0.9908 - val_loss: 0.0364 - learning_rate: 1.0000e-04\n",
      "Epoch 14/150\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 173ms/step - accuracy: 1.0000 - loss: 8.1202e-04 - val_accuracy: 0.9908 - val_loss: 0.0387 - learning_rate: 1.0000e-04\n",
      "Epoch 15/150\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 176ms/step - accuracy: 1.0000 - loss: 7.6994e-04 - val_accuracy: 0.9890 - val_loss: 0.0375 - learning_rate: 1.0000e-04\n",
      "Epoch 16/150\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 174ms/step - accuracy: 1.0000 - loss: 6.4637e-04 - val_accuracy: 0.9899 - val_loss: 0.0366 - learning_rate: 1.0000e-04\n",
      "Epoch 17/150\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 172ms/step - accuracy: 1.0000 - loss: 6.4410e-04 - val_accuracy: 0.9908 - val_loss: 0.0411 - learning_rate: 1.0000e-04\n",
      "Epoch 18/150\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 169ms/step - accuracy: 1.0000 - loss: 5.4538e-04\n",
      "Epoch 18: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 176ms/step - accuracy: 1.0000 - loss: 5.1708e-04 - val_accuracy: 0.9917 - val_loss: 0.0397 - learning_rate: 1.0000e-04\n",
      "Epoch 19/150\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m21s\u001B[0m 181ms/step - accuracy: 1.0000 - loss: 3.9452e-04 - val_accuracy: 0.9908 - val_loss: 0.0345 - learning_rate: 5.0000e-05\n",
      "Epoch 20/150\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 178ms/step - accuracy: 1.0000 - loss: 4.2361e-04 - val_accuracy: 0.9899 - val_loss: 0.0364 - learning_rate: 5.0000e-05\n",
      "Epoch 21/150\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 173ms/step - accuracy: 1.0000 - loss: 3.5544e-04 - val_accuracy: 0.9908 - val_loss: 0.0352 - learning_rate: 5.0000e-05\n",
      "Epoch 22/150\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 187ms/step - accuracy: 1.0000 - loss: 4.0229e-04 - val_accuracy: 0.9926 - val_loss: 0.0335 - learning_rate: 5.0000e-05\n",
      "Epoch 23/150\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 174ms/step - accuracy: 1.0000 - loss: 3.3339e-04 - val_accuracy: 0.9908 - val_loss: 0.0343 - learning_rate: 5.0000e-05\n",
      "Epoch 24/150\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 173ms/step - accuracy: 1.0000 - loss: 3.1994e-04 - val_accuracy: 0.9908 - val_loss: 0.0345 - learning_rate: 5.0000e-05\n",
      "Epoch 25/150\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m21s\u001B[0m 174ms/step - accuracy: 1.0000 - loss: 3.1537e-04 - val_accuracy: 0.9908 - val_loss: 0.0399 - learning_rate: 5.0000e-05\n",
      "Epoch 26/150\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 172ms/step - accuracy: 1.0000 - loss: 2.8343e-04 - val_accuracy: 0.9908 - val_loss: 0.0385 - learning_rate: 5.0000e-05\n",
      "Epoch 27/150\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 169ms/step - accuracy: 1.0000 - loss: 3.0284e-04\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 176ms/step - accuracy: 1.0000 - loss: 2.9574e-04 - val_accuracy: 0.9899 - val_loss: 0.0363 - learning_rate: 5.0000e-05\n",
      "Epoch 28/150\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 174ms/step - accuracy: 1.0000 - loss: 3.0950e-04 - val_accuracy: 0.9899 - val_loss: 0.0356 - learning_rate: 2.5000e-05\n",
      "Epoch 29/150\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 175ms/step - accuracy: 1.0000 - loss: 2.9841e-04 - val_accuracy: 0.9899 - val_loss: 0.0349 - learning_rate: 2.5000e-05\n",
      "Epoch 30/150\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 176ms/step - accuracy: 1.0000 - loss: 2.6928e-04 - val_accuracy: 0.9908 - val_loss: 0.0358 - learning_rate: 2.5000e-05\n",
      "Epoch 31/150\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 173ms/step - accuracy: 1.0000 - loss: 2.6350e-04 - val_accuracy: 0.9899 - val_loss: 0.0367 - learning_rate: 2.5000e-05\n",
      "Epoch 32/150\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 169ms/step - accuracy: 1.0000 - loss: 2.7921e-04\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 176ms/step - accuracy: 1.0000 - loss: 2.6805e-04 - val_accuracy: 0.9908 - val_loss: 0.0357 - learning_rate: 2.5000e-05\n",
      "Epoch 33/150\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 174ms/step - accuracy: 1.0000 - loss: 3.0588e-04 - val_accuracy: 0.9908 - val_loss: 0.0348 - learning_rate: 1.2500e-05\n",
      "Epoch 34/150\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 173ms/step - accuracy: 1.0000 - loss: 2.7304e-04 - val_accuracy: 0.9908 - val_loss: 0.0370 - learning_rate: 1.2500e-05\n",
      "Epoch 35/150\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 176ms/step - accuracy: 1.0000 - loss: 2.2692e-04 - val_accuracy: 0.9908 - val_loss: 0.0353 - learning_rate: 1.2500e-05\n",
      "Epoch 36/150\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 173ms/step - accuracy: 1.0000 - loss: 2.2978e-04 - val_accuracy: 0.9899 - val_loss: 0.0351 - learning_rate: 1.2500e-05\n",
      "Epoch 37/150\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 167ms/step - accuracy: 1.0000 - loss: 2.1631e-04\n",
      "Epoch 37: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 174ms/step - accuracy: 1.0000 - loss: 2.2449e-04 - val_accuracy: 0.9908 - val_loss: 0.0348 - learning_rate: 1.2500e-05\n",
      "Epoch 37: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "   > Acurácia Final Fold 3: 99.26%\n",
      "--- Rodando Fold 4/5 ---\n",
      "Pesos das classes: {0: np.float64(3.5672131147540984), 1: np.float64(75.90697674418604), 2: np.float64(0.5), 3: np.float64(1.4287590282337492)}\n",
      "Epoch 1/150\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m15s\u001B[0m 184ms/step - accuracy: 0.5565 - loss: 1.8142 - val_accuracy: 0.5487 - val_loss: 1.2008 - learning_rate: 1.0000e-04\n",
      "Epoch 2/150\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 173ms/step - accuracy: 0.8394 - loss: 0.4029 - val_accuracy: 0.3952 - val_loss: 1.3789 - learning_rate: 1.0000e-04\n",
      "Epoch 3/150\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m21s\u001B[0m 182ms/step - accuracy: 0.9607 - loss: 0.1202 - val_accuracy: 0.8796 - val_loss: 0.4033 - learning_rate: 1.0000e-04\n",
      "Epoch 4/150\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 181ms/step - accuracy: 0.9892 - loss: 0.0452 - val_accuracy: 0.9357 - val_loss: 0.2286 - learning_rate: 1.0000e-04\n",
      "Epoch 5/150\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 183ms/step - accuracy: 0.9977 - loss: 0.0261 - val_accuracy: 0.9825 - val_loss: 0.0836 - learning_rate: 1.0000e-04\n",
      "Epoch 6/150\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 174ms/step - accuracy: 0.9984 - loss: 0.0131 - val_accuracy: 0.9706 - val_loss: 0.0885 - learning_rate: 1.0000e-04\n",
      "Epoch 7/150\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 182ms/step - accuracy: 0.9998 - loss: 0.0065 - val_accuracy: 0.9862 - val_loss: 0.0497 - learning_rate: 1.0000e-04\n",
      "Epoch 8/150\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 191ms/step - accuracy: 0.9998 - loss: 0.0036 - val_accuracy: 0.9890 - val_loss: 0.0427 - learning_rate: 1.0000e-04\n",
      "Epoch 9/150\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m20s\u001B[0m 177ms/step - accuracy: 1.0000 - loss: 0.0035 - val_accuracy: 0.9660 - val_loss: 0.1020 - learning_rate: 1.0000e-04\n",
      "Epoch 10/150\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 186ms/step - accuracy: 0.9998 - loss: 0.0021 - val_accuracy: 0.9945 - val_loss: 0.0279 - learning_rate: 1.0000e-04\n",
      "Epoch 11/150\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 174ms/step - accuracy: 0.9998 - loss: 0.0037 - val_accuracy: 0.8235 - val_loss: 0.4375 - learning_rate: 1.0000e-04\n",
      "Epoch 12/150\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 178ms/step - accuracy: 1.0000 - loss: 0.0021 - val_accuracy: 0.9926 - val_loss: 0.0405 - learning_rate: 1.0000e-04\n",
      "Epoch 13/150\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 174ms/step - accuracy: 1.0000 - loss: 0.0015 - val_accuracy: 0.9936 - val_loss: 0.0330 - learning_rate: 1.0000e-04\n",
      "Epoch 14/150\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 176ms/step - accuracy: 1.0000 - loss: 9.4729e-04 - val_accuracy: 0.9890 - val_loss: 0.0405 - learning_rate: 1.0000e-04\n",
      "Epoch 15/150\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 168ms/step - accuracy: 1.0000 - loss: 8.1656e-04\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 175ms/step - accuracy: 1.0000 - loss: 7.9133e-04 - val_accuracy: 0.9917 - val_loss: 0.0305 - learning_rate: 1.0000e-04\n",
      "Epoch 16/150\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 176ms/step - accuracy: 1.0000 - loss: 6.4123e-04 - val_accuracy: 0.9908 - val_loss: 0.0336 - learning_rate: 5.0000e-05\n",
      "Epoch 17/150\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 178ms/step - accuracy: 1.0000 - loss: 5.9468e-04 - val_accuracy: 0.9926 - val_loss: 0.0307 - learning_rate: 5.0000e-05\n",
      "Epoch 18/150\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 175ms/step - accuracy: 1.0000 - loss: 4.9651e-04 - val_accuracy: 0.9926 - val_loss: 0.0287 - learning_rate: 5.0000e-05\n",
      "Epoch 19/150\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 184ms/step - accuracy: 1.0000 - loss: 5.1228e-04 - val_accuracy: 0.9926 - val_loss: 0.0266 - learning_rate: 5.0000e-05\n",
      "Epoch 20/150\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 180ms/step - accuracy: 1.0000 - loss: 4.4965e-04 - val_accuracy: 0.9926 - val_loss: 0.0268 - learning_rate: 5.0000e-05\n",
      "Epoch 21/150\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 183ms/step - accuracy: 1.0000 - loss: 4.2590e-04 - val_accuracy: 0.9936 - val_loss: 0.0265 - learning_rate: 5.0000e-05\n",
      "Epoch 22/150\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 180ms/step - accuracy: 1.0000 - loss: 3.7799e-04 - val_accuracy: 0.9926 - val_loss: 0.0268 - learning_rate: 5.0000e-05\n",
      "Epoch 23/150\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 177ms/step - accuracy: 1.0000 - loss: 5.0407e-04 - val_accuracy: 0.9899 - val_loss: 0.0370 - learning_rate: 5.0000e-05\n",
      "Epoch 24/150\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 166ms/step - accuracy: 1.0000 - loss: 3.1412e-04\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 173ms/step - accuracy: 1.0000 - loss: 3.6239e-04 - val_accuracy: 0.9936 - val_loss: 0.0296 - learning_rate: 5.0000e-05\n",
      "Epoch 25/150\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 176ms/step - accuracy: 1.0000 - loss: 3.7184e-04 - val_accuracy: 0.9936 - val_loss: 0.0277 - learning_rate: 2.5000e-05\n",
      "Epoch 26/150\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 172ms/step - accuracy: 1.0000 - loss: 4.1076e-04 - val_accuracy: 0.9926 - val_loss: 0.0284 - learning_rate: 2.5000e-05\n",
      "Epoch 27/150\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 177ms/step - accuracy: 1.0000 - loss: 4.0396e-04 - val_accuracy: 0.9926 - val_loss: 0.0267 - learning_rate: 2.5000e-05\n",
      "Epoch 28/150\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 179ms/step - accuracy: 1.0000 - loss: 3.1995e-04 - val_accuracy: 0.9936 - val_loss: 0.0253 - learning_rate: 2.5000e-05\n",
      "Epoch 29/150\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 183ms/step - accuracy: 1.0000 - loss: 3.2751e-04 - val_accuracy: 0.9926 - val_loss: 0.0245 - learning_rate: 2.5000e-05\n",
      "Epoch 30/150\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 176ms/step - accuracy: 1.0000 - loss: 3.5072e-04 - val_accuracy: 0.9926 - val_loss: 0.0248 - learning_rate: 2.5000e-05\n",
      "Epoch 31/150\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 180ms/step - accuracy: 1.0000 - loss: 3.0694e-04 - val_accuracy: 0.9926 - val_loss: 0.0245 - learning_rate: 2.5000e-05\n",
      "Epoch 32/150\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 181ms/step - accuracy: 1.0000 - loss: 3.7841e-04 - val_accuracy: 0.9926 - val_loss: 0.0239 - learning_rate: 2.5000e-05\n",
      "Epoch 33/150\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 175ms/step - accuracy: 1.0000 - loss: 3.4229e-04 - val_accuracy: 0.9926 - val_loss: 0.0259 - learning_rate: 2.5000e-05\n",
      "Epoch 34/150\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 173ms/step - accuracy: 1.0000 - loss: 2.6944e-04 - val_accuracy: 0.9936 - val_loss: 0.0255 - learning_rate: 2.5000e-05\n",
      "Epoch 35/150\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 175ms/step - accuracy: 1.0000 - loss: 2.5799e-04 - val_accuracy: 0.9926 - val_loss: 0.0246 - learning_rate: 2.5000e-05\n",
      "Epoch 36/150\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 173ms/step - accuracy: 1.0000 - loss: 2.9356e-04 - val_accuracy: 0.9926 - val_loss: 0.0242 - learning_rate: 2.5000e-05\n",
      "Epoch 37/150\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 165ms/step - accuracy: 1.0000 - loss: 2.5824e-04\n",
      "Epoch 37: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 172ms/step - accuracy: 1.0000 - loss: 2.5584e-04 - val_accuracy: 0.9926 - val_loss: 0.0249 - learning_rate: 2.5000e-05\n",
      "Epoch 38/150\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 178ms/step - accuracy: 1.0000 - loss: 2.7914e-04 - val_accuracy: 0.9926 - val_loss: 0.0251 - learning_rate: 1.2500e-05\n",
      "Epoch 39/150\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 172ms/step - accuracy: 1.0000 - loss: 2.5637e-04 - val_accuracy: 0.9926 - val_loss: 0.0252 - learning_rate: 1.2500e-05\n",
      "Epoch 40/150\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 173ms/step - accuracy: 1.0000 - loss: 2.4029e-04 - val_accuracy: 0.9926 - val_loss: 0.0254 - learning_rate: 1.2500e-05\n",
      "Epoch 41/150\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 175ms/step - accuracy: 1.0000 - loss: 2.7052e-04 - val_accuracy: 0.9926 - val_loss: 0.0254 - learning_rate: 1.2500e-05\n",
      "Epoch 42/150\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 166ms/step - accuracy: 1.0000 - loss: 2.4167e-04\n",
      "Epoch 42: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 173ms/step - accuracy: 1.0000 - loss: 2.4988e-04 - val_accuracy: 0.9926 - val_loss: 0.0255 - learning_rate: 1.2500e-05\n",
      "Epoch 43/150\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 175ms/step - accuracy: 1.0000 - loss: 2.3187e-04 - val_accuracy: 0.9926 - val_loss: 0.0254 - learning_rate: 6.2500e-06\n",
      "Epoch 44/150\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 174ms/step - accuracy: 1.0000 - loss: 2.5415e-04 - val_accuracy: 0.9926 - val_loss: 0.0251 - learning_rate: 6.2500e-06\n",
      "Epoch 45/150\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 172ms/step - accuracy: 1.0000 - loss: 2.0604e-04 - val_accuracy: 0.9926 - val_loss: 0.0252 - learning_rate: 6.2500e-06\n",
      "Epoch 46/150\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 176ms/step - accuracy: 1.0000 - loss: 1.9714e-04 - val_accuracy: 0.9926 - val_loss: 0.0253 - learning_rate: 6.2500e-06\n",
      "Epoch 47/150\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 166ms/step - accuracy: 1.0000 - loss: 2.8075e-04\n",
      "Epoch 47: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 173ms/step - accuracy: 1.0000 - loss: 2.5454e-04 - val_accuracy: 0.9926 - val_loss: 0.0253 - learning_rate: 6.2500e-06\n",
      "Epoch 47: early stopping\n",
      "Restoring model weights from the end of the best epoch: 32.\n",
      "   > Acurácia Final Fold 4: 99.26%\n",
      "--- Rodando Fold 5/5 ---\n",
      "Pesos das classes: {0: np.float64(3.5730706075533663), 1: np.float64(75.90697674418604), 2: np.float64(0.5), 3: np.float64(1.4278215223097113)}\n",
      "Epoch 1/150\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m15s\u001B[0m 186ms/step - accuracy: 0.4713 - loss: 2.0377 - val_accuracy: 0.5046 - val_loss: 1.8451 - learning_rate: 1.0000e-04\n",
      "Epoch 2/150\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 181ms/step - accuracy: 0.8575 - loss: 0.3861 - val_accuracy: 0.7454 - val_loss: 0.9757 - learning_rate: 1.0000e-04\n",
      "Epoch 3/150\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 185ms/step - accuracy: 0.9674 - loss: 0.1093 - val_accuracy: 0.6057 - val_loss: 0.8167 - learning_rate: 1.0000e-04\n",
      "Epoch 4/150\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m20s\u001B[0m 178ms/step - accuracy: 0.9906 - loss: 0.0421 - val_accuracy: 0.9081 - val_loss: 0.2629 - learning_rate: 1.0000e-04\n",
      "Epoch 5/150\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 186ms/step - accuracy: 0.9963 - loss: 0.0185 - val_accuracy: 0.9660 - val_loss: 0.1347 - learning_rate: 1.0000e-04\n",
      "Epoch 6/150\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 170ms/step - accuracy: 0.9995 - loss: 0.0084 - val_accuracy: 0.9614 - val_loss: 0.1364 - learning_rate: 1.0000e-04\n",
      "Epoch 7/150\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 170ms/step - accuracy: 1.0000 - loss: 0.0048 - val_accuracy: 0.9338 - val_loss: 0.1999 - learning_rate: 1.0000e-04\n",
      "Epoch 8/150\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 186ms/step - accuracy: 0.9998 - loss: 0.0039 - val_accuracy: 0.9789 - val_loss: 0.0818 - learning_rate: 1.0000e-04\n",
      "Epoch 9/150\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 175ms/step - accuracy: 1.0000 - loss: 0.0021 - val_accuracy: 0.9835 - val_loss: 0.0612 - learning_rate: 1.0000e-04\n",
      "Epoch 10/150\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 172ms/step - accuracy: 1.0000 - loss: 0.0018 - val_accuracy: 0.9798 - val_loss: 0.0764 - learning_rate: 1.0000e-04\n",
      "Epoch 11/150\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 181ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.9798 - val_loss: 0.0658 - learning_rate: 1.0000e-04\n",
      "Epoch 12/150\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 169ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.9779 - val_loss: 0.0768 - learning_rate: 1.0000e-04\n",
      "Epoch 13/150\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 179ms/step - accuracy: 1.0000 - loss: 8.9163e-04 - val_accuracy: 0.9825 - val_loss: 0.0679 - learning_rate: 1.0000e-04\n",
      "Epoch 14/150\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 164ms/step - accuracy: 1.0000 - loss: 8.3950e-04\n",
      "Epoch 14: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 171ms/step - accuracy: 1.0000 - loss: 9.3235e-04 - val_accuracy: 0.9789 - val_loss: 0.0778 - learning_rate: 1.0000e-04\n",
      "Epoch 15/150\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 172ms/step - accuracy: 1.0000 - loss: 8.3685e-04 - val_accuracy: 0.9816 - val_loss: 0.0739 - learning_rate: 5.0000e-05\n",
      "Epoch 16/150\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 180ms/step - accuracy: 1.0000 - loss: 6.1390e-04 - val_accuracy: 0.9825 - val_loss: 0.0656 - learning_rate: 5.0000e-05\n",
      "Epoch 17/150\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 169ms/step - accuracy: 1.0000 - loss: 4.7369e-04 - val_accuracy: 0.9789 - val_loss: 0.0722 - learning_rate: 5.0000e-05\n",
      "Epoch 18/150\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 171ms/step - accuracy: 1.0000 - loss: 4.9966e-04 - val_accuracy: 0.9816 - val_loss: 0.0692 - learning_rate: 5.0000e-05\n",
      "Epoch 19/150\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 173ms/step - accuracy: 1.0000 - loss: 5.0822e-04\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 181ms/step - accuracy: 1.0000 - loss: 5.8762e-04 - val_accuracy: 0.9844 - val_loss: 0.0633 - learning_rate: 5.0000e-05\n",
      "Epoch 20/150\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 169ms/step - accuracy: 1.0000 - loss: 4.8592e-04 - val_accuracy: 0.9816 - val_loss: 0.0655 - learning_rate: 2.5000e-05\n",
      "Epoch 21/150\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 171ms/step - accuracy: 1.0000 - loss: 4.8458e-04 - val_accuracy: 0.9816 - val_loss: 0.0694 - learning_rate: 2.5000e-05\n",
      "Epoch 22/150\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 180ms/step - accuracy: 1.0000 - loss: 4.2323e-04 - val_accuracy: 0.9807 - val_loss: 0.0693 - learning_rate: 2.5000e-05\n",
      "Epoch 23/150\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 170ms/step - accuracy: 1.0000 - loss: 3.7886e-04 - val_accuracy: 0.9807 - val_loss: 0.0697 - learning_rate: 2.5000e-05\n",
      "Epoch 24/150\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 172ms/step - accuracy: 1.0000 - loss: 4.0767e-04\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "\u001B[1m68/68\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 179ms/step - accuracy: 1.0000 - loss: 3.5761e-04 - val_accuracy: 0.9807 - val_loss: 0.0703 - learning_rate: 2.5000e-05\n",
      "Epoch 24: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "   > Acurácia Final Fold 5: 98.35%\n",
      "\n",
      "==============================\n",
      "Média Final de Acurácia: 98.93%\n",
      "O melhor modelo de todos os folds já está salvo como 'melhor_modelo_kfold.keras'\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "id": "244066648064edf9",
   "metadata": {},
   "source": [
    "Métricas mais avançadas com sklearn"
   ]
  },
  {
   "cell_type": "code",
   "id": "d07ced0d0e92e238",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-23T03:28:35.544059Z",
     "start_time": "2025-11-23T03:28:27.726678Z"
    }
   },
   "source": [
    "print(\"\\n--- Iniciando Avaliação por Ensemble (Soft Voting) ---\")\n",
    "\n",
    "ds_teste_final = criar_dataset_fold(X_teste, y_teste, training=False)\n",
    "\n",
    "y_verdadeiro = []\n",
    "for _, rotulos in ds_teste_final:\n",
    "    y_verdadeiro.extend(rotulos.numpy())\n",
    "y_verdadeiro = np.array(y_verdadeiro)\n",
    "\n",
    "soma_previsoes = None\n",
    "\n",
    "for i in range(1, NUM_FOLDS + 1):\n",
    "    nome_arquivo = f'modelo_fold_{i}.keras'\n",
    "    caminho_modelo = os.path.join(PASTA_FOLDS, nome_arquivo)\n",
    "\n",
    "    print(f\"Carregando: {caminho_modelo}\")\n",
    "    modelo = load_model(caminho_modelo, safe_mode=False)\n",
    "\n",
    "    pred_fold = modelo.predict(ds_teste_final, verbose=0)\n",
    "\n",
    "    if soma_previsoes is None:\n",
    "        soma_previsoes = pred_fold\n",
    "    else:\n",
    "        soma_previsoes += pred_fold\n",
    "\n",
    "    tf.keras.backend.clear_session()\n",
    "    gc.collect()\n",
    "\n",
    "previsoes_ensemble = soma_previsoes / NUM_FOLDS\n",
    "y_pred_ensemble = np.argmax(previsoes_ensemble, axis=1)\n",
    "\n",
    "classes = ['Mild', 'Mod', 'Non', 'VMild']\n",
    "print(\"\\nRelatório de Classificação (Ensemble):\")\n",
    "print(classification_report(y_verdadeiro, y_pred_ensemble, target_names=classes))\n",
    "\n",
    "cm = confusion_matrix(y_verdadeiro, y_pred_ensemble)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=classes)\n",
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "disp.plot(xticks_rotation=45, cmap='Blues', ax=ax)\n",
    "plt.title(f\"Matriz de Confusão (Ensemble {NUM_FOLDS} Folds)\")\n",
    "plt.show()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Iniciando Avaliação por Ensemble (Soft Voting) ---\n",
      "Carregando: Folds/modelo_fold_1.keras\n",
      "Carregando: Folds/modelo_fold_2.keras\n",
      "Carregando: Folds/modelo_fold_3.keras\n",
      "Carregando: Folds/modelo_fold_4.keras\n",
      "Carregando: Folds/modelo_fold_5.keras\n",
      "\n",
      "Relatório de Classificação (Ensemble):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Mild       0.99      1.00      1.00       134\n",
      "         Mod       1.00      1.00      1.00        10\n",
      "         Non       1.00      1.00      1.00       480\n",
      "       VMild       1.00      1.00      1.00       336\n",
      "\n",
      "    accuracy                           1.00       960\n",
      "   macro avg       1.00      1.00      1.00       960\n",
      "weighted avg       1.00      1.00      1.00       960\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 600x600 with 2 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 11
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
